<!DOCTYPE HTML>
<html lang="Html">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="文本摘要项目, 小龙播客">
    <meta name="description" content="家里蹲大学">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>文本摘要项目 | 小龙播客</title>
    <link rel="icon" type="image/png" href="/favicon.png">

    <link rel="stylesheet" type="text/css" href="/libs/awesome/css/all.css">
    <link rel="stylesheet" type="text/css" href="/libs/materialize/materialize.min.css">
    <link rel="stylesheet" type="text/css" href="/libs/aos/aos.css">
    <link rel="stylesheet" type="text/css" href="/libs/animate/animate.min.css">
    <link rel="stylesheet" type="text/css" href="/libs/lightGallery/css/lightgallery.min.css">
    <link rel="stylesheet" type="text/css" href="/css/matery.css">
    <link rel="stylesheet" type="text/css" href="/css/my.css">

    <script src="/libs/jquery/jquery.min.js"></script>

<meta name="generator" content="Hexo 5.4.0"><link rel="alternate" href="/atom.xml" title="小龙播客" type="application/atom+xml">
<link rel="stylesheet" href="/css/prism-tomorrow.css" type="text/css"></head>




<body>
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/" class="waves-effect waves-light">
                    
                    <img src="/medias/logo.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">小龙播客</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>Index</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>Tags</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>Categories</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>Archives</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/about" class="waves-effect waves-light">
      
      <i class="fas fa-user-circle" style="zoom: 0.6;"></i>
      
      <span>About</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/contact" class="waves-effect waves-light">
      
      <i class="fas fa-comments" style="zoom: 0.6;"></i>
      
      <span>Contact</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/friends" class="waves-effect waves-light">
      
      <i class="fas fa-address-book" style="zoom: 0.6;"></i>
      
      <span>Friends</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="Search" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/medias/logo.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">小龙播客</div>
        <div class="logo-desc">
            
            家里蹲大学
            
        </div>
    </div>

    

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			Index
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			Tags
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			Categories
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			Archives
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/about" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-user-circle"></i>
			
			About
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/contact" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-comments"></i>
			
			Contact
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/friends" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-address-book"></i>
			
			Friends
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('/medias/featureimages/3.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">文本摘要项目</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <link rel="stylesheet" href="/libs/tocbot/tocbot.css">
<style>
    #articleContent h1::before,
    #articleContent h2::before,
    #articleContent h3::before,
    #articleContent h4::before,
    #articleContent h5::before,
    #articleContent h6::before {
        display: block;
        content: " ";
        height: 100px;
        margin-top: -100px;
        visibility: hidden;
    }

    #articleContent :focus {
        outline: none;
    }

    .toc-fixed {
        position: fixed;
        top: 64px;
    }

    .toc-widget {
        width: 345px;
        padding-left: 20px;
    }

    .toc-widget .toc-title {
        padding: 35px 0 15px 17px;
        font-size: 1.5rem;
        font-weight: bold;
        line-height: 1.5rem;
    }

    .toc-widget ol {
        padding: 0;
        list-style: none;
    }

    #toc-content {
        padding-bottom: 30px;
        overflow: auto;
    }

    #toc-content ol {
        padding-left: 10px;
    }

    #toc-content ol li {
        padding-left: 10px;
    }

    #toc-content .toc-link:hover {
        color: #42b983;
        font-weight: 700;
        text-decoration: underline;
    }

    #toc-content .toc-link::before {
        background-color: transparent;
        max-height: 25px;

        position: absolute;
        right: 23.5vw;
        display: block;
    }

    #toc-content .is-active-link {
        color: #42b983;
    }

    #floating-toc-btn {
        position: fixed;
        right: 15px;
        bottom: 76px;
        padding-top: 15px;
        margin-bottom: 0;
        z-index: 998;
    }

    #floating-toc-btn .btn-floating {
        width: 48px;
        height: 48px;
    }

    #floating-toc-btn .btn-floating i {
        line-height: 48px;
        font-size: 1.4rem;
    }
</style>
<div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/tags/%E6%96%87%E6%9C%AC%E6%91%98%E8%A6%81/">
                                <span class="chip bg-color">文本摘要</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/categories/NLP/" class="post-category">
                                NLP
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>Publish Date:&nbsp;&nbsp;
                    2020-02-10
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>Update Date:&nbsp;&nbsp;
                    2021-06-28
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>Word Count:&nbsp;&nbsp;
                    16.8k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>Read Times:&nbsp;&nbsp;
                    70 Min
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>Read Count:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <h2 id="1：文本摘要项目理论"><a href="#1：文本摘要项目理论" class="headerlink" title="1：文本摘要项目理论"></a><strong>1：文本摘要项目理论</strong></h2><h4 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h4><p><strong>文本摘要思想</strong>：就是一个长文本把重要的摘要出来</p>
<h5 id="1：NLP角度来看文本摘要任务，主流的概括两大方法："><a href="#1：NLP角度来看文本摘要任务，主流的概括两大方法：" class="headerlink" title="1：NLP角度来看文本摘要任务，主流的概括两大方法："></a>1：NLP角度来看文本摘要任务，主流的概括两大方法：</h5><ul>
<li><p>抽取式摘要：Extraction-based（从文本中抽取）：直接从原文中选择若干条重要的句子, 并对它们进行排序和重组, 以形成摘要的方法.</p>
<ul>
<li><strong>无监督抽取</strong>：不需要平行语料, 节省了人工标记的成本. 大体上有如下几种:<ul>
<li>Lead</li>
<li>Centroid</li>
<li>ClusterCMRW</li>
<li>TextRank：最经典</li>
</ul>
</li>
<li><strong>有监督抽取：</strong>将文本摘要抽象成二分类问题, 通过神经网络来学习句子及其标签之间的对应关系. 需要平行语料, 需要人工标记的成本. 常见方法有如下几种<ul>
<li>R2N2</li>
<li>NeuralSum</li>
<li>SummaRuNNer</li>
<li><strong>BertSum</strong>：原本用来计算网页之间的关联性，后来被应用在句子上，句子之间反复传播，选出最关键的语句进行排序。因为文章总有中心句，而textrank就试图找出这个中心句。</li>
</ul>
</li>
<li>取式<strong>缺点</strong>：主要考虑单词词频，没有过多的语义信息，所以无法建立段落中的完整语义信息</li>
</ul>
</li>
<li><p><strong>生成式摘要: Abstraction-based：</strong>需要通过<strong>转述、同义替换、句子缩写</strong>等生成。</p>
<ul>
<li>生成式神经网络模型的基本结构主要由<strong>编码器（encoder）和解码器（decoder）</strong>组成，编码和解码都由神经网络实现。<ul>
<li><strong>编码器</strong>负责将输入的原文本编码成一个<strong>向量C（context），</strong></li>
<li><strong>而解码器</strong>负责从这个<strong>向量C</strong>提取<strong>重要信息、加工剪辑，生成文本摘要。</strong></li>
<li><strong>Sequence-to-Sequence</strong>（以下简称Seq2Seq），被广泛应用于存在输入序列和输出序列的场景，比如机器翻译（一种语言序列到另一种语言序列）、image captioning（图片像素序列到语言序列）、对话机器人（如问题到回答）等</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="2：数据的处理："><a href="#2：数据的处理：" class="headerlink" title="2：数据的处理："></a>2：数据的处理：</h4><p>一般来说, 在任何项目中, 面对原始数据都要进行接下来的几点工作:</p>
<ul>
<li>删除空值.</li>
<li>删除”脏”数据.<ul>
<li>在这个数据集中的脏数据为：<ul>
<li>有很多的技师说和，车主说</li>
<li>文本中有很多的图片字样和语音字样</li>
<li>有很多进口，车型，还有一些符号</li>
</ul>
</li>
</ul>
</li>
<li>删除特定字符的集合.</li>
<li>分词.</li>
<li>完成字符到id的映射.</li>
<li>完成padding, cutting的工作.</li>
</ul>
<pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd

train_path <span class="token operator">=</span> <span class="token string">'train.csv'</span>
test_path <span class="token operator">=</span> <span class="token string">'test.csv'</span>

df <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span>train_path<span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span>
df<span class="token punctuation">.</span>info<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'**********************'</span><span class="token punctuation">)</span>

df <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span>test_path<span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span>
df<span class="token punctuation">.</span>info<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre>
<h4 id="打印："><a href="#打印：" class="headerlink" title="打印："></a>打印：</h4><pre class=" language-python"><code class="language-python"><span class="token operator">&lt;</span><span class="token keyword">class</span> <span class="token string">'pandas.core.frame.DataFrame'</span><span class="token operator">></span>
RangeIndex<span class="token punctuation">:</span> <span class="token number">82943</span> entries<span class="token punctuation">,</span> <span class="token number">0</span> to <span class="token number">82942</span>
Data columns <span class="token punctuation">(</span>total <span class="token number">6</span> columns<span class="token punctuation">)</span><span class="token punctuation">:</span>
 <span class="token comment" spellcheck="true">#   Column    Non-Null Count  Dtype </span>

 <span class="token number">0</span>   QID       <span class="token number">82943</span> non<span class="token operator">-</span>null  object
 <span class="token number">1</span>   Brand     <span class="token number">81642</span> non<span class="token operator">-</span>null  object
 <span class="token number">2</span>   Model     <span class="token number">81642</span> non<span class="token operator">-</span>null  object
 <span class="token number">3</span>   Question  <span class="token number">82943</span> non<span class="token operator">-</span>null  object
 <span class="token number">4</span>   Dialogue  <span class="token number">82941</span> non<span class="token operator">-</span>null  object
 <span class="token number">5</span>   Report    <span class="token number">82873</span> non<span class="token operator">-</span>null  object
dtypes<span class="token punctuation">:</span> object<span class="token punctuation">(</span><span class="token number">6</span><span class="token punctuation">)</span>
memory usage<span class="token punctuation">:</span> <span class="token number">3.8</span><span class="token operator">+</span> MB

<span class="token operator">&lt;</span><span class="token keyword">class</span> <span class="token string">'pandas.core.frame.DataFrame'</span><span class="token operator">></span>
RangeIndex<span class="token punctuation">:</span> <span class="token number">20000</span> entries<span class="token punctuation">,</span> <span class="token number">0</span> to <span class="token number">19999</span>
Data columns <span class="token punctuation">(</span>total <span class="token number">5</span> columns<span class="token punctuation">)</span><span class="token punctuation">:</span>
 <span class="token comment" spellcheck="true">#   Column    Non-Null Count  Dtype </span>

 <span class="token number">0</span>   QID       <span class="token number">20000</span> non<span class="token operator">-</span>null  object
 <span class="token number">1</span>   Brand     <span class="token number">19987</span> non<span class="token operator">-</span>null  object
 <span class="token number">2</span>   Model     <span class="token number">19987</span> non<span class="token operator">-</span>null  object
 <span class="token number">3</span>   Question  <span class="token number">20000</span> non<span class="token operator">-</span>null  object
 <span class="token number">4</span>   Dialogue  <span class="token number">20000</span> non<span class="token operator">-</span>null  object
dtypes<span class="token punctuation">:</span> object<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span>
memory usage<span class="token punctuation">:</span> <span class="token number">781.4</span><span class="token operator">+</span> KB
</code></pre>
<h4 id="3：TextRank：算法理论基础"><a href="#3：TextRank：算法理论基础" class="headerlink" title="3：TextRank：算法理论基础"></a>3：TextRank：算法理论基础</h4><p>对比于衡量网页重要性的PageRank算法, TextRank算法用于衡量哪些单词是关键词, 类比之下的算法思想也就很好理解了:</p>
<ul>
<li>如果一个单词出现在很多单词的后面, 就是它和很多单词有关联, 那么说明这个单词比较重要.</li>
<li>如果一个TextRank值很高的单词后面跟着另一个单词, 那么后面这个单词的TextRank值也会相应的被提高.</li>
</ul>
<h4 id="3-1：TextRank算法代码实践"><a href="#3-1：TextRank算法代码实践" class="headerlink" title="3.1：TextRank算法代码实践"></a>3.1：TextRank算法代码实践</h4><ul>
<li>在本小节中, 我们仅以示例代码跑通几段小程序, 让同学们掌握如何具体在代码层面用TextRank.<ul>
<li>关键词抽取(keyword extraction)：是指从文本中确定一些能够描述文档含义的关键术语的过程<ul>
<li>对关键词抽取而言, 用于构建顶点集的文本单元可以使句子中的一个或多个字. 根据这些字之间的关系构建边.</li>
<li>根据任务的需要, 可以使用语法过滤器(syntactic filters)对顶点集进行优化. 语法过滤器的主要作用是将某一类或者某几类词性的字过滤出来作为顶点集.</li>
</ul>
</li>
<li>关键短语抽取(keyphrase extraction)</li>
<li>关键句抽取(sentence extraction)</li>
</ul>
</li>
</ul>
<pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># coding=utf-8</span>
<span class="token comment" spellcheck="true"># 导入textrank4zh的相关工具包</span>
<span class="token keyword">from</span> textrank4zh <span class="token keyword">import</span> TextRank4Keyword<span class="token punctuation">,</span> TextRank4Sentence
<span class="token keyword">import</span> os
<span class="token keyword">import</span> sys
<span class="token comment" spellcheck="true"># 导入常用工具包</span>
<span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np

<span class="token comment" spellcheck="true">#关键词抽取</span>
<span class="token keyword">def</span> <span class="token function">keywords_extraction</span><span class="token punctuation">(</span>text<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment" spellcheck="true"># allow_speech_tags : 词性列表, 用于过滤某些词性的词</span>
    tr4w <span class="token operator">=</span> TextRank4Keyword<span class="token punctuation">(</span>allow_speech_tags<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'n'</span><span class="token punctuation">,</span> <span class="token string">'nr'</span><span class="token punctuation">,</span> <span class="token string">'nrfg'</span><span class="token punctuation">,</span> <span class="token string">'ns'</span><span class="token punctuation">,</span> <span class="token string">'nt'</span><span class="token punctuation">,</span> <span class="token string">'nz'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true"># text: 文本内容, 字符串</span>
    <span class="token comment" spellcheck="true"># window: 窗口大小, int, 用来构造单词之间的边, 默认值为2</span>
    <span class="token comment" spellcheck="true"># lower: 是否将英文文本转换为小写, 默认值为False</span>
    <span class="token comment" spellcheck="true"># vertex_source: 选择使用words_no_filter, words_no_stop_words, words_all_filters中的>哪一个来构造pagerank对应的图中的节点</span>
    <span class="token comment" spellcheck="true">#默认值为'all_filters', 可选值为'no_filter', 'no_stop_words', 'all_filters'</span>
    <span class="token comment" spellcheck="true"># edge_source: 选择使用words_no_filter, words_no_stop_words, words_all_filters中的哪>一个来构造pagerank对应的图中的节点之间的边</span>
    <span class="token comment" spellcheck="true">#默认值为'no_stop_words', 可选值为'no_filter', 'no_stop_words', 'all_filters', 边的构造要结合window参数</span>
    <span class="token comment" spellcheck="true"># pagerank_config: pagerank算法参数配置, 阻尼系数为0.85</span>

    tr4w<span class="token punctuation">.</span>analyze<span class="token punctuation">(</span>text<span class="token operator">=</span>text<span class="token punctuation">,</span> window<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> lower<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> vertex_source<span class="token operator">=</span><span class="token string">'all_filters'</span><span class="token punctuation">,</span>
                 edge_source<span class="token operator">=</span><span class="token string">'no_stop_words'</span><span class="token punctuation">,</span> pagerank_config<span class="token operator">=</span><span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;'alpha': 0.85, &amp;#125;)</span>

    <span class="token comment" spellcheck="true"># num: 返回关键词数量</span>
    <span class="token comment" spellcheck="true"># word_min_len: 词的最小长度, 默认值为1    </span>
    keywords <span class="token operator">=</span> tr4w<span class="token punctuation">.</span>get_keywords<span class="token punctuation">(</span>num<span class="token operator">=</span><span class="token number">6</span><span class="token punctuation">,</span> word_min_len<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>
    
    
 <span class="token comment" spellcheck="true">#提取重要关键短句</span>
    <span class="token comment" spellcheck="true"># keywords_num: 抽取的关键词数量</span>
    <span class="token comment" spellcheck="true"># min_occur_num: 关键短语在文中的最少出现次数</span>
    <span class="token comment" spellcheck="true">#keyphrases = tr4w.get_keyphrases(keywords_num=6, min_occur_num=1)</span>
    
    
<span class="token comment" spellcheck="true">#提取关键句</span>
    <span class="token comment" spellcheck="true">#tr4s = TextRank4Sentence()</span>
        <span class="token comment" spellcheck="true"># text: 文本内容, 字符串</span>
    <span class="token comment" spellcheck="true"># lower: 是否将英文文本转换为小写, 默认值为False</span>
    <span class="token comment" spellcheck="true"># source: 选择使用words_no_filter, words_no_stop_words, words_all_filters中的哪一个来                生成句子之间的相似度</span>
    <span class="token comment" spellcheck="true">#默认值为'all_filters', 可选值为'no_filter', 'no_stop_words', 'all_filters'</span>
    <span class="token comment" spellcheck="true">#tr4s.analyze(text, lower=True, source='all_filters')</span>
    <span class="token comment" spellcheck="true"># 获取最重要的num个长度大于等于sentence_min_len的句子用来生成摘要</span>
    <span class="token comment" spellcheck="true">#keysentences = tr4s.get_key_sentences(num=3, sentence_min_len=6)</span>
    
    
    

    <span class="token comment" spellcheck="true"># 返回关键词</span>
    <span class="token keyword">return</span> keywords
<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">"__main__"</span><span class="token punctuation">:</span>
    text <span class="token operator">=</span> <span class="token string">"来源：中国科学报本报讯（记者肖洁）又有一位中国科学家喜获小行星命名殊荣！4月19日下午，中国科学院国家天文台在京举行“周又元星”颁授仪式，"</span> \
           <span class="token string">"我国天文学家、中国科学院院士周又元的弟子与后辈在欢声笑语中济济一堂。国家天文台党委书记、"</span> \
           <span class="token string">"副台长赵刚在致辞一开始更是送上白居易的诗句：“令公桃李满天下，何须堂前更种花。”"</span> \
           <span class="token string">"据介绍，这颗小行星由国家天文台施密特CCD小行星项目组于1997年9月26日发现于兴隆观测站，"</span> \
           <span class="token string">"获得国际永久编号第120730号。2018年9月25日，经国家天文台申报，"</span> \
           <span class="token string">"国际天文学联合会小天体联合会小天体命名委员会批准，国际天文学联合会《小行星通报》通知国际社会，"</span> \
           <span class="token string">"正式将该小行星命名为“周又元星”。"</span>

    <span class="token comment" spellcheck="true">#关键词抽取</span>
    keywords<span class="token operator">=</span>keywords_extraction<span class="token punctuation">(</span>text<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>keywords<span class="token punctuation">)</span>
</code></pre>
<h5 id="打印：-1"><a href="#打印：-1" class="headerlink" title="打印："></a>打印：</h5><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">#关键词抽取</span>
<span class="token punctuation">[</span><span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;'word': '小行星', 'weight': 0.05808441467341854&amp;#125;,</span>
<span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;'word': '天文台', 'weight': 0.05721653775742513&amp;#125;, </span>
<span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;'word': '命名', 'weight': 0.0485177005159723&amp;#125;,</span>
<span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;'word': '中国', 'weight': 0.045716478124251815&amp;#125;, </span>
<span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;'word': '中国科学院', 'weight': 0.037818937836996636&amp;#125;, </span>
<span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;'word': '国家', 'weight': 0.03438059254484016&amp;#125;]</span>


<span class="token comment" spellcheck="true">#提取重要关键短句</span>
<span class="token punctuation">[</span><span class="token string">'小行星命名'</span><span class="token punctuation">]</span>



<span class="token comment" spellcheck="true">#提取关键句</span>
<span class="token punctuation">[</span><span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;'index': 4, 'sentence': '2018年9月25日，经国家天文台申报，国际天文学联合会小天体联合会小天体命名委员会批准，国际天文学联合会《小行星通报》通知国际社会，正式将该小行星命名为“周又元星”', 'weight': 0.2281040325096452&amp;#125;,</span>
 <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;'index': 3, 'sentence': '”据介绍，这颗小行星由国家天文台施密特CCD小行星项目组于1997年9月26日发现于兴隆观测站，获得国际永久编号第120730号', 'weight': 0.2106246105971721&amp;#125;,</span>
 <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;'index': 1, 'sentence': '4月19日下午，中国科学院国家天文台在京举行“周又元星”颁授仪式，我国天文学家、中国科学院院士周又元的弟子与后辈在欢声笑语中济济一堂', 'weight': 0.2020923401661083&amp;#125;]</span>
</code></pre>
<h4 id="3-2：基于jieba的TextRank算法"><a href="#3-2：基于jieba的TextRank算法" class="headerlink" title="3.2：基于jieba的TextRank算法"></a>3.2：基于jieba的TextRank算法</h4><ul>
<li>jieba工具不仅仅可以用来分词, 进行词性分析. 也可以用来完成TextRank.</li>
</ul>
<pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> jieba<span class="token punctuation">.</span>analyse

<span class="token keyword">def</span> <span class="token function">jieba_keywords_textrank</span><span class="token punctuation">(</span>text<span class="token punctuation">)</span><span class="token punctuation">:</span>
    keywords <span class="token operator">=</span> jieba<span class="token punctuation">.</span>analyse<span class="token punctuation">.</span>textrank<span class="token punctuation">(</span>text<span class="token punctuation">,</span> topK<span class="token operator">=</span><span class="token number">6</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> keywords
<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">"__main__"</span><span class="token punctuation">:</span>
    text <span class="token operator">=</span> <span class="token string">"来源：中国科学报本报讯（记者肖洁）又有一位中国科学家喜获小行星命名殊荣！4月19日下午，中国科学院国家天文台在京举行“周又元星”颁授仪式，"</span> \
           <span class="token string">"我国天文学家、中国科学院院士周又元的弟子与后辈在欢声笑语中济济一堂。国家天文台党委书记、"</span> \
           <span class="token string">"副台长赵刚在致辞一开始更是送上白居易的诗句：“令公桃李满天下，何须堂前更种花。”"</span> \
           <span class="token string">"据介绍，这颗小行星由国家天文台施密特CCD小行星项目组于1997年9月26日发现于兴隆观测站，"</span> \
           <span class="token string">"获得国际永久编号第120730号。2018年9月25日，经国家天文台申报，"</span> \
           <span class="token string">"国际天文学联合会小天体联合会小天体命名委员会批准，国际天文学联合会《小行星通报》通知国际社会，"</span> \
           <span class="token string">"正式将该小行星命名为“周又元星”。"</span>

    <span class="token comment" spellcheck="true"># 基于jieba的textrank算法实现</span>
    keywords <span class="token operator">=</span> jieba_keywords_textrank<span class="token punctuation">(</span>text<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>keywords<span class="token punctuation">)</span>
</code></pre>
<ul>
<li><h6 id="输出结果"><a href="#输出结果" class="headerlink" title="输出结果:"></a>输出结果:</h6></li>
</ul>
<pre class=" language-python"><code class="language-python"><span class="token punctuation">[</span><span class="token string">'小行星'</span><span class="token punctuation">,</span> <span class="token string">'命名'</span><span class="token punctuation">,</span> <span class="token string">'国际'</span><span class="token punctuation">,</span> <span class="token string">'中国'</span><span class="token punctuation">,</span> <span class="token string">'国家'</span><span class="token punctuation">,</span> <span class="token string">'天文学家'</span><span class="token punctuation">]</span>
</code></pre>
<h2 id="2：-TextRank实现baseline-0模型"><a href="#2：-TextRank实现baseline-0模型" class="headerlink" title="2： TextRank实现baseline-0模型"></a><strong>2： TextRank实现baseline-0模型</strong></h2><h4 id="数据预处理："><a href="#数据预处理：" class="headerlink" title="数据预处理："></a>数据预处理：</h4><ul>
<li><p>我们在第一章的1.2小节曾经讨论过原始数据存在的各种问题, 这些问题都需要在数据预处理的这个环节一一解决. 接下来按照如下步骤进行处理:</p>
<ul>
<li><p>第一步: 提取特定的文本.</p>
</li>
<li><p>第二步: 删除”脏”数据.</p>
</li>
<li><p>第三步: 删除特定的字符集合.</p>
</li>
<li><p>第四步: 删除特殊位置的特定字符.</p>
</li>
</ul>
</li>
</ul>
<h4 id="第一步-提取特定的文本"><a href="#第一步-提取特定的文本" class="headerlink" title="第一步: 提取特定的文本."></a>第一步: 提取特定的文本.</h4><p>面对原始语料, 并不是说我们必须要全部纳入模型中, 可以根据业务需求, 或者程序员的项目经验, 或许出于尝试的态度, 只选取一部分出来作为我们后续模型的输入数据.</p>
<pre class=" language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">clean_sentence</span><span class="token punctuation">(</span>sentence<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment" spellcheck="true"># 1. 将sentence按照'|'分句，并只提取技师的话</span>
    sub_jishi <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    <span class="token comment" spellcheck="true"># 按照'|'字符将车主和用户的对话分离</span>
    sub <span class="token operator">=</span> sentence<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">'|'</span><span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true"># 遍历每个子句</span>
    <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span>len<span class="token punctuation">(</span>sub<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment" spellcheck="true"># 如果不是以句号结尾, 增加一个句号</span>
        <span class="token keyword">if</span> <span class="token operator">not</span> sub<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">.</span>endswith<span class="token punctuation">(</span><span class="token string">'。'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            sub<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">+=</span> <span class="token string">'。'</span>
        <span class="token comment" spellcheck="true"># 只使用技师说的句子</span>
        <span class="token keyword">if</span> sub<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">.</span>startswith<span class="token punctuation">(</span><span class="token string">'技师'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            sub_jishi<span class="token punctuation">.</span>append<span class="token punctuation">(</span>sub<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true"># 拼接成字符串并返回</span>
    sentence <span class="token operator">=</span> <span class="token string">''</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>sub_jishi<span class="token punctuation">)</span>

    <span class="token keyword">return</span> sentence
<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">'__main__'</span><span class="token punctuation">:</span>
    <span class="token comment" spellcheck="true"># 读取数据, 并指定编码格式为'utf-8'</span>
    df <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">'train.csv'</span><span class="token punctuation">,</span> engine<span class="token operator">=</span><span class="token string">'python'</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span>
    texts <span class="token operator">=</span> df<span class="token punctuation">[</span><span class="token string">'Dialogue'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>tolist<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'预处理前的第一条句子：'</span><span class="token punctuation">,</span> texts<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'********************************'</span><span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true"># 数据预处理</span>
    res <span class="token operator">=</span> clean_sentence<span class="token punctuation">(</span>texts<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'预处理后的第一条句子: '</span><span class="token punctuation">,</span> res<span class="token punctuation">)</span>
</code></pre>
<ul>
<li><h6 id="输出结果-1"><a href="#输出结果-1" class="headerlink" title="输出结果:"></a>输出结果:</h6></li>
</ul>
<pre class=" language-python"><code class="language-python">预处理前的第一条句子： 技师说：<span class="token punctuation">[</span>语音<span class="token punctuation">]</span><span class="token operator">|</span>车主说：新的都换了<span class="token operator">|</span>车主说：助力泵，方向机<span class="token operator">|</span>技师说：<span class="token punctuation">[</span>语音<span class="token punctuation">]</span><span class="token operator">|</span>车主说：换了方向机带的有<span class="token operator">|</span>车主说：<span class="token punctuation">[</span>图片<span class="token punctuation">]</span><span class="token operator">|</span>技师说：<span class="token punctuation">[</span>语音<span class="token punctuation">]</span><span class="token operator">|</span>车主说：有助力就是重，这车要匹配吧<span class="token operator">|</span>技师说：不需要<span class="token operator">|</span>技师说：你这是更换的部件有问题<span class="token operator">|</span>车主说：跑快了还好点，就倒车重的很。<span class="token operator">|</span>技师说：是非常重吗<span class="token operator">|</span>车主说：是的，累人<span class="token operator">|</span>技师说：<span class="token punctuation">[</span>语音<span class="token punctuation">]</span><span class="token operator">|</span>车主说：我觉得也是，可是车主是以前没这么重，选吧助理泵换了不行，又把放向机换了，现在还这样就不知道咋和车主解释。<span class="token operator">|</span>技师说：<span class="token punctuation">[</span>语音<span class="token punctuation">]</span><span class="token operator">|</span>技师说：<span class="token punctuation">[</span>语音<span class="token punctuation">]</span>

预处理后的第一条句子<span class="token punctuation">:</span>  技师说：<span class="token punctuation">[</span>语音<span class="token punctuation">]</span>。技师说：<span class="token punctuation">[</span>语音<span class="token punctuation">]</span>。技师说：<span class="token punctuation">[</span>语音<span class="token punctuation">]</span>。技师说：不需要。技师说：你这是更换的部件有问题。技师说：是非常重吗。技师说：<span class="token punctuation">[</span>语音<span class="token punctuation">]</span>。技师说：<span class="token punctuation">[</span>语音<span class="token punctuation">]</span>。技师说：<span class="token punctuation">[</span>语音<span class="token punctuation">]</span>。
</code></pre>
<ul>
<li><h5 id="数据进行分割形成小型数据"><a href="#数据进行分割形成小型数据" class="headerlink" title="数据进行分割形成小型数据"></a>数据进行分割形成小型数据</h5></li>
</ul>
<pre class=" language-python"><code class="language-python">nf <span class="token operator">=</span> df<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">5000</span><span class="token punctuation">]</span>
nf<span class="token punctuation">.</span>to_csv<span class="token punctuation">(</span><span class="token string">"dev.csv"</span><span class="token punctuation">,</span>mode<span class="token operator">=</span><span class="token string">'w'</span><span class="token punctuation">)</span>
dfa  <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">"dev.csv"</span><span class="token punctuation">,</span>encoding<span class="token operator">=</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span>
dfa<span class="token punctuation">.</span>head<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre>
<p>打印结果</p>
<h4 id="第二步-删除”脏”数据"><a href="#第二步-删除”脏”数据" class="headerlink" title="第二步: 删除”脏”数据."></a>第二步: 删除”脏”数据.</h4><ul>
<li>关于什么是”脏”数据是个千人千面的问题, 我们在第一章中也讨论过. 这一步也仅仅处理一个baseline的级别.</li>
</ul>
<pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 导入正则表达式工具包, 用来删除特定模式的数据</span>
<span class="token keyword">import</span> re

<span class="token keyword">def</span> <span class="token function">clean_sentence</span><span class="token punctuation">(</span>sentence<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment" spellcheck="true"># 1. 将sentence按照'|'分句，并只提取技师的话</span>
    sub_jishi <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    <span class="token comment" spellcheck="true"># 按照'|'字符将车主和用户的对话分离</span>
    sub <span class="token operator">=</span> sentence<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">'|'</span><span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true"># 遍历每个子句</span>
    <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span>len<span class="token punctuation">(</span>sub<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment" spellcheck="true"># 如果不是以句号结尾, 增加一个句号</span>
        <span class="token keyword">if</span> <span class="token operator">not</span> sub<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">.</span>endswith<span class="token punctuation">(</span><span class="token string">'。'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            sub<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">+=</span> <span class="token string">'。'</span>
        <span class="token comment" spellcheck="true"># 只使用技师说的句子</span>
        <span class="token keyword">if</span> sub<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">.</span>startswith<span class="token punctuation">(</span><span class="token string">'技师'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            sub_jishi<span class="token punctuation">.</span>append<span class="token punctuation">(</span>sub<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true"># 拼接成字符串并返回</span>
    sentence <span class="token operator">=</span> <span class="token string">''</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>sub_jishi<span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true"># 第二步中添加的两个处理, 利用正则表达式re工具</span>
    <span class="token comment" spellcheck="true"># 2. 删除1. 2. 3. 这些标题</span>
    r <span class="token operator">=</span> re<span class="token punctuation">.</span>compile<span class="token punctuation">(</span><span class="token string">"\D(\d\.)\D"</span><span class="token punctuation">)</span>
    sentence <span class="token operator">=</span> r<span class="token punctuation">.</span>sub<span class="token punctuation">(</span><span class="token string">""</span><span class="token punctuation">,</span> sentence<span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true"># 3. 删除一些无关紧要的词以及语气助词</span>
    r <span class="token operator">=</span> re<span class="token punctuation">.</span>compile<span class="token punctuation">(</span>r<span class="token string">"车主说|技师说|语音|图片|呢|吧|哈|啊|啦"</span><span class="token punctuation">)</span>
    sentence <span class="token operator">=</span> r<span class="token punctuation">.</span>sub<span class="token punctuation">(</span><span class="token string">""</span><span class="token punctuation">,</span> sentence<span class="token punctuation">)</span>

    <span class="token keyword">return</span> sentence

<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">'__main__'</span><span class="token punctuation">:</span>
    <span class="token comment" spellcheck="true"># 读取数据, 并指定编码格式为'utf-8'</span>
    df <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">'dev.csv'</span><span class="token punctuation">,</span> engine<span class="token operator">=</span><span class="token string">'python'</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span>
    texts <span class="token operator">=</span> df<span class="token punctuation">[</span><span class="token string">'Dialogue'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>tolist<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'预处理前的第一条句子：'</span><span class="token punctuation">,</span> texts<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'********************************'</span><span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true"># 数据预处理</span>
    res <span class="token operator">=</span> clean_sentence<span class="token punctuation">(</span>texts<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'预处理后的第一条句子: '</span><span class="token punctuation">,</span> res<span class="token punctuation">)</span>
</code></pre>
<ul>
<li><h5 id="处理后的数据"><a href="#处理后的数据" class="headerlink" title="处理后的数据"></a>处理后的数据</h5></li>
</ul>
<pre><code>预处理前的第一条句子： 技师说：[语音]|车主说：新的都换了|车主说：助力泵，方向机|技师说：[语音]|车主说：换了方向机带的有|车主说：[图片]|技师说：[语音]|车主说：有助力就是重，这车要匹配吧|技师说：不需要|技师说：你这是更换的部件有问题|车主说：跑快了还好点，就倒车重的很。|技师说：是非常重吗|车主说：是的，累人|技师说：[语音]|车主说：我觉得也是，可是车主是以前没这么重，选吧助理泵换了不行，又把放向机换了，现在还这样就不知道咋和车主解释。|技师说：[语音]|技师说：[语音]

预处理后的第一条句子:  ：[]。：[]。：[]。：不需要。：你这是更换的部件有问题。：是非常重吗。：[]。：[]。：[]
</code></pre>
<h4 id="第三步-删除特定的字符集合"><a href="#第三步-删除特定的字符集合" class="headerlink" title="第三步: 删除特定的字符集合."></a>第三步: 删除特定的字符集合.</h4><ul>
<li>1: 我们发现原始数据文件中有若干的”进口”, “海外”字样, 可认为是需要删除的特定字符.</li>
<li>2: 为了后续处理文本容易, 除了汉字还有数字, 英文字母, 特定的几个标点符号, 其他都删除.</li>
<li>3: 将标点符号的半角格式, 转变成全角格式.</li>
<li>4: 将问号, 感叹号, 转变成句号.</li>
</ul>
<pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 导入正则表达式工具包, 用来删除特定模式的数据</span>
<span class="token keyword">import</span> re

<span class="token keyword">def</span> <span class="token function">clean_sentence</span><span class="token punctuation">(</span>sentence<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment" spellcheck="true"># 第一步要处理的代码</span>
    <span class="token comment" spellcheck="true"># 1. 将sentence按照'|'分句，并只提取技师的话</span>
    sub_jishi <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    <span class="token comment" spellcheck="true"># 按照'|'字符将车主和用户的对话分离</span>
    sub <span class="token operator">=</span> sentence<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">'|'</span><span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true"># 遍历每个子句</span>
    <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span>len<span class="token punctuation">(</span>sub<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment" spellcheck="true"># 如果不是以句号结尾, 增加一个句号</span>
        <span class="token keyword">if</span> <span class="token operator">not</span> sub<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">.</span>endswith<span class="token punctuation">(</span><span class="token string">'。'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            sub<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">+=</span> <span class="token string">'。'</span>
        <span class="token comment" spellcheck="true"># 只使用技师说的句子</span>
        <span class="token keyword">if</span> sub<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">.</span>startswith<span class="token punctuation">(</span><span class="token string">'技师'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            sub_jishi<span class="token punctuation">.</span>append<span class="token punctuation">(</span>sub<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true"># 拼接成字符串并返回</span>
    sentence <span class="token operator">=</span> <span class="token string">''</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>sub_jishi<span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true"># 第二步中添加的两个处理, 利用正则表达式re工具</span>
    <span class="token comment" spellcheck="true"># 2. 删除1. 2. 3. 这些标题</span>
    r <span class="token operator">=</span> re<span class="token punctuation">.</span>compile<span class="token punctuation">(</span><span class="token string">"\D(\d\.)\D"</span><span class="token punctuation">)</span>
    sentence <span class="token operator">=</span> r<span class="token punctuation">.</span>sub<span class="token punctuation">(</span><span class="token string">""</span><span class="token punctuation">,</span> sentence<span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true"># 3. 删除一些无关紧要的词以及语气助词</span>
    r <span class="token operator">=</span> re<span class="token punctuation">.</span>compile<span class="token punctuation">(</span>r<span class="token string">"车主说|技师说|语音|图片|呢|吧|哈|啊|啦"</span><span class="token punctuation">)</span>
    sentence <span class="token operator">=</span> r<span class="token punctuation">.</span>sub<span class="token punctuation">(</span><span class="token string">""</span><span class="token punctuation">,</span> sentence<span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true"># 第三步中添加的4个处理</span>
    <span class="token comment" spellcheck="true"># 4. 删除带括号的 进口 海外</span>
    r <span class="token operator">=</span> re<span class="token punctuation">.</span>compile<span class="token punctuation">(</span>r<span class="token string">"[(（]进口[)）]|\(海外\)"</span><span class="token punctuation">)</span>
    sentence <span class="token operator">=</span> r<span class="token punctuation">.</span>sub<span class="token punctuation">(</span><span class="token string">""</span><span class="token punctuation">,</span> sentence<span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true"># 5. 删除除了汉字数字字母和，！？。.- 以外的字符</span>
    r <span class="token operator">=</span> re<span class="token punctuation">.</span>compile<span class="token punctuation">(</span><span class="token string">"[^，！？。\.\-\u4e00-\u9fa5_a-zA-Z0-9]"</span><span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true"># 6. 半角变为全角</span>
    sentence <span class="token operator">=</span> sentence<span class="token punctuation">.</span>replace<span class="token punctuation">(</span><span class="token string">","</span><span class="token punctuation">,</span> <span class="token string">"，"</span><span class="token punctuation">)</span>
    sentence <span class="token operator">=</span> sentence<span class="token punctuation">.</span>replace<span class="token punctuation">(</span><span class="token string">"!"</span><span class="token punctuation">,</span> <span class="token string">"！"</span><span class="token punctuation">)</span>
    sentence <span class="token operator">=</span> sentence<span class="token punctuation">.</span>replace<span class="token punctuation">(</span><span class="token string">"?"</span><span class="token punctuation">,</span> <span class="token string">"？"</span><span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true"># 7. 问号叹号变为句号</span>
    sentence <span class="token operator">=</span> sentence<span class="token punctuation">.</span>replace<span class="token punctuation">(</span><span class="token string">"？"</span><span class="token punctuation">,</span> <span class="token string">"。"</span><span class="token punctuation">)</span>
    sentence <span class="token operator">=</span> sentence<span class="token punctuation">.</span>replace<span class="token punctuation">(</span><span class="token string">"！"</span><span class="token punctuation">,</span> <span class="token string">"。"</span><span class="token punctuation">)</span>
    sentence <span class="token operator">=</span> r<span class="token punctuation">.</span>sub<span class="token punctuation">(</span><span class="token string">""</span><span class="token punctuation">,</span> sentence<span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true"># 第四步添加的删除特定位置的特定字符</span>
    <span class="token comment" spellcheck="true"># 8. 删除句子开头的逗号</span>
    <span class="token keyword">if</span> sentence<span class="token punctuation">.</span>startswith<span class="token punctuation">(</span><span class="token string">'，'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        sentence <span class="token operator">=</span> sentence<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">]</span>

    <span class="token keyword">return</span> sentence
<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">'__main__'</span><span class="token punctuation">:</span>
    <span class="token comment" spellcheck="true"># 读取数据, 并指定编码格式为'utf-8'</span>
    df <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">'dev.csv'</span><span class="token punctuation">,</span> engine<span class="token operator">=</span><span class="token string">'python'</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span>
    texts <span class="token operator">=</span> df<span class="token punctuation">[</span><span class="token string">'Dialogue'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>tolist<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'预处理前的第一条句子：'</span><span class="token punctuation">,</span> texts<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'********************************'</span><span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true"># 数据预处理</span>
    res <span class="token operator">=</span> clean_sentence<span class="token punctuation">(</span>texts<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'预处理后的第一条句子: '</span><span class="token punctuation">,</span> res<span class="token punctuation">)</span>
</code></pre>
<h5 id="打印操作"><a href="#打印操作" class="headerlink" title="打印操作"></a>打印操作</h5><pre class=" language-python"><code class="language-python">预处理前的第一条句子： 技师说：<span class="token punctuation">[</span>语音<span class="token punctuation">]</span><span class="token operator">|</span>车主说：新的都换了<span class="token operator">|</span>车主说：助力泵，方向机<span class="token operator">|</span>技师说：<span class="token punctuation">[</span>语音<span class="token punctuation">]</span><span class="token operator">|</span>车主说：换了方向机带的有<span class="token operator">|</span>车主说：<span class="token punctuation">[</span>图片<span class="token punctuation">]</span><span class="token operator">|</span>技师说：<span class="token punctuation">[</span>语音<span class="token punctuation">]</span><span class="token operator">|</span>车主说：有助力就是重，这车要匹配吧<span class="token operator">|</span>技师说：不需要<span class="token operator">|</span>技师说：你这是更换的部件有问题<span class="token operator">|</span>车主说：跑快了还好点，就倒车重的很。<span class="token operator">|</span>技师说：是非常重吗<span class="token operator">|</span>车主说：是的，累人<span class="token operator">|</span>技师说：<span class="token punctuation">[</span>语音<span class="token punctuation">]</span><span class="token operator">|</span>车主说：我觉得也是，可是车主是以前没这么重，选吧助理泵换了不行，又把放向机换了，现在还这样就不知道咋和车主解释。<span class="token operator">|</span>技师说：<span class="token punctuation">[</span>语音<span class="token punctuation">]</span><span class="token operator">|</span>技师说：<span class="token punctuation">[</span>语音<span class="token punctuation">]</span>

预处理后的第一条句子<span class="token punctuation">:</span>  。。。不需要。你这是更换的部件有问题。是非常重吗。。。。
</code></pre>
<h3 id="2-1：TextRank模型代码实现：进行数数的机器学习模型"><a href="#2-1：TextRank模型代码实现：进行数数的机器学习模型" class="headerlink" title="2.1：TextRank模型代码实现：进行数数的机器学习模型"></a>2.1：TextRank模型代码实现：进行数数的机器学习模型</h3><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 导入正则表达式工具包, 用来删除特定模式的数据</span>
<span class="token keyword">import</span> re
<span class="token keyword">def</span> <span class="token function">clean_sentence</span><span class="token punctuation">(</span>sentence<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment" spellcheck="true"># 第一步要处理的代码</span>
    <span class="token comment" spellcheck="true"># 1. 将sentence按照'|'分句，并只提取技师的话</span>
    sub_jishi <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    <span class="token comment" spellcheck="true"># 按照'|'字符将车主和用户的对话分离</span>
    sub <span class="token operator">=</span> sentence<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">'|'</span><span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true"># 遍历每个子句</span>
    <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span>len<span class="token punctuation">(</span>sub<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment" spellcheck="true"># 如果不是以句号结尾, 增加一个句号</span>
        <span class="token keyword">if</span> <span class="token operator">not</span> sub<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">.</span>endswith<span class="token punctuation">(</span><span class="token string">'。'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            sub<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">+=</span> <span class="token string">'。'</span>
        <span class="token comment" spellcheck="true"># 只使用技师说的句子</span>
        <span class="token keyword">if</span> sub<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">.</span>startswith<span class="token punctuation">(</span><span class="token string">'技师'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            sub_jishi<span class="token punctuation">.</span>append<span class="token punctuation">(</span>sub<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span>
    <span class="token comment" spellcheck="true"># 拼接成字符串并返回</span>
    sentence <span class="token operator">=</span> <span class="token string">''</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>sub_jishi<span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true"># 第二步中添加的两个处理, 利用正则表达式re工具</span>
    <span class="token comment" spellcheck="true"># 2. 删除1. 2. 3. 这些标题</span>
    r <span class="token operator">=</span> re<span class="token punctuation">.</span>compile<span class="token punctuation">(</span><span class="token string">"\D(\d\.)\D"</span><span class="token punctuation">)</span>
    sentence <span class="token operator">=</span> r<span class="token punctuation">.</span>sub<span class="token punctuation">(</span><span class="token string">""</span><span class="token punctuation">,</span> sentence<span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true"># 3. 删除一些无关紧要的词以及语气助词</span>
    r <span class="token operator">=</span> re<span class="token punctuation">.</span>compile<span class="token punctuation">(</span>r<span class="token string">"车主说|技师说|语音|图片|呢|吧|哈|啊|啦"</span><span class="token punctuation">)</span>
    sentence <span class="token operator">=</span> r<span class="token punctuation">.</span>sub<span class="token punctuation">(</span><span class="token string">""</span><span class="token punctuation">,</span> sentence<span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true"># 第三步中添加的4个处理</span>
    <span class="token comment" spellcheck="true"># 4. 删除带括号的 进口 海外</span>
    r <span class="token operator">=</span> re<span class="token punctuation">.</span>compile<span class="token punctuation">(</span>r<span class="token string">"[(（]进口[)）]|\(海外\)"</span><span class="token punctuation">)</span>
    sentence <span class="token operator">=</span> r<span class="token punctuation">.</span>sub<span class="token punctuation">(</span><span class="token string">""</span><span class="token punctuation">,</span> sentence<span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true"># 5. 删除除了汉字数字字母和，！？。.- 以外的字符</span>
    r <span class="token operator">=</span> re<span class="token punctuation">.</span>compile<span class="token punctuation">(</span><span class="token string">"[^，！？。\.\-\u4e00-\u9fa5_a-zA-Z0-9]"</span><span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true"># 6. 半角变为全角</span>
    sentence <span class="token operator">=</span> sentence<span class="token punctuation">.</span>replace<span class="token punctuation">(</span><span class="token string">","</span><span class="token punctuation">,</span> <span class="token string">"，"</span><span class="token punctuation">)</span>
    sentence <span class="token operator">=</span> sentence<span class="token punctuation">.</span>replace<span class="token punctuation">(</span><span class="token string">"!"</span><span class="token punctuation">,</span> <span class="token string">"！"</span><span class="token punctuation">)</span>
    sentence <span class="token operator">=</span> sentence<span class="token punctuation">.</span>replace<span class="token punctuation">(</span><span class="token string">"?"</span><span class="token punctuation">,</span> <span class="token string">"？"</span><span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true"># 7. 问号叹号变为句号</span>
    sentence <span class="token operator">=</span> sentence<span class="token punctuation">.</span>replace<span class="token punctuation">(</span><span class="token string">"？"</span><span class="token punctuation">,</span> <span class="token string">"。"</span><span class="token punctuation">)</span>
    sentence <span class="token operator">=</span> sentence<span class="token punctuation">.</span>replace<span class="token punctuation">(</span><span class="token string">"！"</span><span class="token punctuation">,</span> <span class="token string">"。"</span><span class="token punctuation">)</span>
    sentence <span class="token operator">=</span> r<span class="token punctuation">.</span>sub<span class="token punctuation">(</span><span class="token string">""</span><span class="token punctuation">,</span> sentence<span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true"># 第四步添加的删除特定位置的特定字符</span>
    <span class="token comment" spellcheck="true"># 8. 删除句子开头的逗号</span>
    <span class="token keyword">if</span> sentence<span class="token punctuation">.</span>startswith<span class="token punctuation">(</span><span class="token string">'，'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        sentence <span class="token operator">=</span> sentence<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">]</span>

    <span class="token keyword">return</span> sentence
<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">'__main__'</span><span class="token punctuation">:</span>
    <span class="token comment" spellcheck="true"># 读取数据, 并指定编码格式为'utf-8'</span>
    df <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">'dev.csv'</span><span class="token punctuation">,</span> engine<span class="token operator">=</span><span class="token string">'python'</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span>
    texts <span class="token operator">=</span> df<span class="token punctuation">[</span><span class="token string">'Dialogue'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>tolist<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span>len<span class="token punctuation">(</span>texts<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        texts<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">=</span> clean_sentence<span class="token punctuation">(</span>texts<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span>
        <span class="token keyword">if</span> i <span class="token operator">%</span> <span class="token number">500</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"i="</span><span class="token punctuation">,</span>i<span class="token punctuation">)</span>
        <span class="token comment" spellcheck="true"># 初始化结果存放的列表</span>
    results <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    <span class="token comment" spellcheck="true"># 初始化textrank4zh类对象</span>
    tr4s <span class="token operator">=</span> TextRank4Sentence<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span>len<span class="token punctuation">(</span>texts<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        text <span class="token operator">=</span> texts<span class="token punctuation">[</span>i<span class="token punctuation">]</span>
        tr4s<span class="token punctuation">.</span>analyze<span class="token punctuation">(</span>text <span class="token operator">=</span> text<span class="token punctuation">,</span>lower <span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">,</span>source <span class="token operator">=</span> <span class="token string">"all_filters"</span><span class="token punctuation">)</span>
        result <span class="token operator">=</span> <span class="token string">""</span>
        <span class="token comment" spellcheck="true"># 直接调用函数获取关键语句</span>
        <span class="token comment" spellcheck="true"># num=3: 获取重要性最高的3个句子.</span>
        <span class="token comment" spellcheck="true"># sentence_min_len=2: 句子的长度最小等于2.</span>
        <span class="token keyword">for</span> item <span class="token keyword">in</span> tr4s<span class="token punctuation">.</span>get_key_sentences<span class="token punctuation">(</span>num<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> sentence_min_len<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            result <span class="token operator">+=</span> item<span class="token punctuation">.</span>sentence
            result <span class="token operator">+=</span> <span class="token string">'。'</span>
        results<span class="token punctuation">.</span>append<span class="token punctuation">(</span>result<span class="token punctuation">)</span>
        <span class="token comment" spellcheck="true"># 间隔100次打印结果</span>
        <span class="token keyword">if</span> <span class="token punctuation">(</span>i <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">%</span> <span class="token number">100</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
            <span class="token keyword">print</span><span class="token punctuation">(</span>i <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">,</span> result<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'result length: '</span><span class="token punctuation">,</span> len<span class="token punctuation">(</span>results<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token comment" spellcheck="true"># 保存结果</span>
    df<span class="token punctuation">[</span><span class="token string">'Prediction'</span><span class="token punctuation">]</span> <span class="token operator">=</span> results

    <span class="token comment" spellcheck="true"># 提取ID, Report, 和预测结果这3列</span>
    df <span class="token operator">=</span> df<span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token string">'QID'</span><span class="token punctuation">,</span> <span class="token string">'Report'</span><span class="token punctuation">,</span> <span class="token string">'Prediction'</span><span class="token punctuation">]</span><span class="token punctuation">]</span>

    <span class="token comment" spellcheck="true"># 保存结果，这里自动生成一个结果名</span>
    df<span class="token punctuation">.</span>to_csv<span class="token punctuation">(</span><span class="token string">'textrank_result_.csv'</span><span class="token punctuation">,</span> index<span class="token operator">=</span>None<span class="token punctuation">,</span> sep<span class="token operator">=</span><span class="token string">','</span><span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true"># 将空行置换为随时联系, 文件保存格式指定为utf-8</span>
    df <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">'textrank_result_.csv'</span><span class="token punctuation">,</span> engine<span class="token operator">=</span><span class="token string">'python'</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span>
    df <span class="token operator">=</span> df<span class="token punctuation">.</span>fillna<span class="token punctuation">(</span><span class="token string">'随时联系。'</span><span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true"># 将处理后的文件保存起来</span>
    df<span class="token punctuation">.</span>to_csv<span class="token punctuation">(</span><span class="token string">'textrank_result_final_.csv'</span><span class="token punctuation">,</span> index<span class="token operator">=</span>None<span class="token punctuation">,</span> sep<span class="token operator">=</span><span class="token string">','</span><span class="token punctuation">)</span>
</code></pre>
<p><strong>打印结果</strong></p>
<pre class=" language-python"><code class="language-python">i<span class="token operator">=</span> <span class="token number">0</span>
i<span class="token operator">=</span> <span class="token number">500</span>
i<span class="token operator">=</span> <span class="token number">1000</span>
i<span class="token operator">=</span> <span class="token number">1500</span>
i<span class="token operator">=</span> <span class="token number">2000</span>
i<span class="token operator">=</span> <span class="token number">2500</span>
i<span class="token operator">=</span> <span class="token number">3000</span>
i<span class="token operator">=</span> <span class="token number">3500</span>
i<span class="token operator">=</span> <span class="token number">4000</span>
i<span class="token operator">=</span> <span class="token number">4500</span>
<span class="token number">100</span> 这个故障一般是转向系统的故障，需要重点检查一下车辆的转向灯泡，是否有不亮的。换了就可以解决问题。你好，车辆故障信息代码标识。
<span class="token number">200</span> 主要是找到发动机和变速器连接部位的支架以及底盘上的各个胶套，是否存在松旷，造成硬性的接触共振。你好，这种情况主要考虑检查底盘是否存在共振区域。这个需要全面检查，如果之前没有这种问题，可以试驾其他同款车辆，确认是否都有这种问题。
<span class="token number">300</span> 您好出厂的时候变速箱油是正常的，在刻度线以内，流出半升之后还是在刻度线以内，所以不用加，亲。加不进去了。顶进去的。
<span class="token number">400</span> 那就要去检查一下皮带轮了。如果高于<span class="token number">1200</span>还有，就要检查一下皮带轮。这款发动机在<span class="token number">900</span><span class="token operator">-</span><span class="token number">1100</span>转时确实有一点嗡嗡声。
<span class="token number">500</span> 这种单边积水的情况基本上不是泡水的原因，而是有地方密封不严，下雨漏水进去，这个一般是门边密封条老化，或者是防风玻璃漏水，需要关上车门，在车外冲水，在车内慢慢找漏水的地方。海绵积水可以用洗车的泡沫海绵放在上面挤压，能把大部的水吸出来，然后大太阳的时候打开车门得晒一个星期左右，差不多就会干了，主要还是得找出进水的原因，不然弄干水了，下次又进水了，时间长了，海绵会发霉发臭的。我知道是地板上积水，空调管堵塞也是会造成这种情况的，也是需要检查的。
<span class="token number">600</span> 您好，需要更换加油管和碳罐，加油时气体排不出去导致跳枪。估计外面找不到改款配件。加油管是改款双管的，原车是单管的。
<span class="token number">700</span> 找领导处理，更换新件并赔偿。送保养次数。投诉厂家，欺骗消费者。
<span class="token number">800</span> 用T10170和百分表，转曲轴看百分表指针，指针转到顺时针的最顶端是一缸上止点。把曲轴转到一缸上止点，然后挂链条就可以了。直接量一缸的上止点不就可以了，不用管其他缸。
</code></pre>
<h1 id="3：-seq2seq实现baseline-1模型：文本摘要"><a href="#3：-seq2seq实现baseline-1模型：文本摘要" class="headerlink" title="3： seq2seq实现baseline-1模型：文本摘要"></a>3： seq2seq实现baseline-1模型：文本摘要</h1><h3 id="seq2seq实现文本摘要的架构"><a href="#seq2seq实现文本摘要的架构" class="headerlink" title="seq2seq实现文本摘要的架构"></a>seq2seq实现文本摘要的架构</h3><ul>
<li>首选回顾一下在英译法任务中的经典seq2seq架构图</li>
</ul>
<blockquote>
<ul>
<li>编码器端负责将输入数据进行编码, 得到中间语义张量.</li>
<li>解码器端负责一次次的循环解析中间语义张量, 得到最终的结果语句.</li>
<li>一般来说, 我们将注意力机制添加在解码器端.</li>
</ul>
</blockquote>
<h4 id="对比于英译法任务-我们再来看文本摘要任务下的seq2seq架构图"><a href="#对比于英译法任务-我们再来看文本摘要任务下的seq2seq架构图" class="headerlink" title="对比于英译法任务, 我们再来看文本摘要任务下的seq2seq架构图:"></a>对比于英译法任务, 我们再来看文本摘要任务下的seq2seq架构图:</h4><blockquote>
<ul>
<li>编码器端负责进行原始文本的编码.</li>
<li>注意力层结合编码张量和解码器端的当前输入, 得到总体上的内容张量.</li>
<li>最后在注意力机制的指导下, 解码器端得到完整的单词分布, 解码出当前时间步的单词.</li>
</ul>
</blockquote>
<h3 id="seq2seq实现文本摘要的架构代码实践"><a href="#seq2seq实现文本摘要的架构代码实践" class="headerlink" title="seq2seq实现文本摘要的架构代码实践"></a>seq2seq实现文本摘要的架构代码实践</h3><h4 id="若干工具函数的实现"><a href="#若干工具函数的实现" class="headerlink" title="若干工具函数的实现"></a>若干工具函数的实现</h4><ul>
<li><p>在这一部分中我们要实现如下几个工具函数:</p>
<ul>
<li>第一步: 实现配置函数config.py</li>
<li>第二步: 实现多核并行处理的函数multi_proc_utils.py</li>
<li>第三步: 实现参数配置函数params_utils.py</li>
<li>第四步: 实现保存字典的函数word2vec_utils.py</li>
<li>第五步: 实现数据加载的函数data_loader.py</li>
</ul>
</li>
<li><h4 id="第一步-实现配置函数config-py"><a href="#第一步-实现配置函数config-py" class="headerlink" title="第一步: 实现配置函数config.py"></a>第一步: 实现配置函数config.py</h4><ul>
<li>代码文件路径: /home/ec2-user/text_summary/seq2seq/utils/config.py</li>
</ul>
</li>
</ul>
<pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 导入os工具包</span>
<span class="token keyword">import</span> os
<span class="token keyword">import</span> sys

<span class="token comment" spellcheck="true"># 设置项目代码库的root路径, 为后续所有的包导入提供便利</span>
root_path <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>dirname<span class="token punctuation">(</span>os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>dirname<span class="token punctuation">(</span>os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>abspath<span class="token punctuation">(</span>__file__<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
sys<span class="token punctuation">.</span>path<span class="token punctuation">.</span>append<span class="token punctuation">(</span>root_path<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>root_path<span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># 设置原始数据文件的路径, 通过以项目root路径为基础, 逐级添加到文件路径</span>
train_raw_data_path <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>root_path<span class="token punctuation">,</span> <span class="token string">'data'</span><span class="token punctuation">,</span> <span class="token string">'train.csv'</span><span class="token punctuation">)</span>
test_raw_data_path <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>root_path<span class="token punctuation">,</span> <span class="token string">'data'</span><span class="token punctuation">,</span> <span class="token string">'test.csv'</span><span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># 停用词路径和jieba分词用户自定义字典路径</span>
stop_words_path <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>root_path<span class="token punctuation">,</span> <span class="token string">'data'</span><span class="token punctuation">,</span> <span class="token string">'stopwords.txt'</span><span class="token punctuation">)</span>
user_dict_path <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>root_path<span class="token punctuation">,</span> <span class="token string">'data'</span><span class="token punctuation">,</span> <span class="token string">'user_dict.txt'</span><span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># 预处理+切分后的训练测试数据路径</span>
train_seg_path <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>root_path<span class="token punctuation">,</span> <span class="token string">'data'</span><span class="token punctuation">,</span> <span class="token string">'train_seg_data.csv'</span><span class="token punctuation">)</span>
test_seg_path <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>root_path<span class="token punctuation">,</span> <span class="token string">'data'</span><span class="token punctuation">,</span> <span class="token string">'test_seg_data.csv'</span><span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># 将训练集和测试机数据混合后的文件路径</span>
merged_seg_path <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>root_path<span class="token punctuation">,</span> <span class="token string">'data'</span><span class="token punctuation">,</span> <span class="token string">'merged_seg_data.csv'</span><span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># 样本与标签分离，并经过pad处理后的数据路径</span>
train_x_pad_path <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>root_path<span class="token punctuation">,</span> <span class="token string">'data'</span><span class="token punctuation">,</span> <span class="token string">'train_X_pad_data.csv'</span><span class="token punctuation">)</span>
train_y_pad_path <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>root_path<span class="token punctuation">,</span> <span class="token string">'data'</span><span class="token punctuation">,</span> <span class="token string">'train_Y_pad_data.csv'</span><span class="token punctuation">)</span>
test_x_pad_path <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>root_path<span class="token punctuation">,</span> <span class="token string">'data'</span><span class="token punctuation">,</span> <span class="token string">'test_X_pad_data.csv'</span><span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># numpy转换为数字后最终使用的的数据路径</span>
train_x_path <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>root_path<span class="token punctuation">,</span> <span class="token string">'data'</span><span class="token punctuation">,</span> <span class="token string">'train_X.npy'</span><span class="token punctuation">)</span>
train_y_path <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>root_path<span class="token punctuation">,</span> <span class="token string">'data'</span><span class="token punctuation">,</span> <span class="token string">'train_Y.npy'</span><span class="token punctuation">)</span>
test_x_path <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>root_path<span class="token punctuation">,</span> <span class="token string">'data'</span><span class="token punctuation">,</span> <span class="token string">'test_X.npy'</span><span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># 正向词典和反向词典路径</span>
vocab_path <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>root_path<span class="token punctuation">,</span> <span class="token string">'data'</span><span class="token punctuation">,</span> <span class="token string">'wv'</span><span class="token punctuation">,</span> <span class="token string">'vocab.txt'</span><span class="token punctuation">)</span>
reverse_vocab_path <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>root_path<span class="token punctuation">,</span> <span class="token string">'data'</span><span class="token punctuation">,</span> <span class="token string">'wv'</span><span class="token punctuation">,</span> <span class="token string">'reverse_vocab.txt'</span><span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># 测试集结果保存路径</span>
result_save_path <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>root_path<span class="token punctuation">,</span> <span class="token string">'data'</span><span class="token punctuation">,</span> <span class="token string">'result'</span><span class="token punctuation">)</span>
</code></pre>
<ul>
<li>输出结果:</li>
</ul>
<pre class=" language-python"><code class="language-python"><span class="token operator">/</span>home<span class="token operator">/</span>ec2<span class="token operator">-</span>user<span class="token operator">/</span>text_summary<span class="token operator">/</span>seq2seq
</code></pre>
<h4 id="第二步-实现多核并行处理的函数multi-proc-utils-py"><a href="#第二步-实现多核并行处理的函数multi-proc-utils-py" class="headerlink" title="第二步: 实现多核并行处理的函数multi_proc_utils.py"></a>第二步: 实现多核并行处理的函数multi_proc_utils.py</h4><ul>
<li>代码文件路径: /home/ec2-user/text_summary/seq2seq/utils/multi_proc_utils.py</li>
</ul>
<pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">from</span> multiprocessing <span class="token keyword">import</span> cpu_count<span class="token punctuation">,</span> Pool

<span class="token comment" spellcheck="true"># 计算当前服务器CPU的数量</span>
cores <span class="token operator">=</span> cpu_count<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token comment" spellcheck="true"># 将分块个数设置为CPU的数量</span>
partitions <span class="token operator">=</span> cores
<span class="token keyword">print</span><span class="token punctuation">(</span>cores<span class="token punctuation">)</span>

<span class="token keyword">def</span> <span class="token function">parallelize</span><span class="token punctuation">(</span>df<span class="token punctuation">,</span> func<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment" spellcheck="true"># 数据切分</span>
    data_split <span class="token operator">=</span> np<span class="token punctuation">.</span>array_split<span class="token punctuation">(</span>df<span class="token punctuation">,</span> partitions<span class="token punctuation">)</span>
    <span class="token comment" spellcheck="true"># 初始化线程池</span>
    pool <span class="token operator">=</span> Pool<span class="token punctuation">(</span>cores<span class="token punctuation">)</span>
    <span class="token comment" spellcheck="true"># 数据分发, 处理, 再合并</span>
    data <span class="token operator">=</span> pd<span class="token punctuation">.</span>concat<span class="token punctuation">(</span>pool<span class="token punctuation">.</span>map<span class="token punctuation">(</span>func<span class="token punctuation">,</span> data_split<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token comment" spellcheck="true"># 关闭线程池</span>
    pool<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token comment" spellcheck="true"># 执行完close后不会有新的进程加入到pool, join函数等待所有子进程结束</span>
    pool<span class="token punctuation">.</span>join<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token comment" spellcheck="true"># 返回处理后的数据</span>
    <span class="token keyword">return</span> data
</code></pre>
<ul>
<li>输出结果:</li>
</ul>
<pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 当前服务器是一个8核CPU, 32GB内存的机器</span>
<span class="token number">8</span>
</code></pre>
<h4 id="第三步-实现参数配置函数params-utils-py"><a href="#第三步-实现参数配置函数params-utils-py" class="headerlink" title="第三步: 实现参数配置函数params_utils.py"></a>第三步: 实现参数配置函数params_utils.py</h4><ul>
<li>代码文件路径: /home/ec2-user/text_summary/seq2seq/utils/params_utils.py</li>
</ul>
<pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> argparse

<span class="token keyword">def</span> <span class="token function">get_params</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    parser <span class="token operator">=</span> argparse<span class="token punctuation">.</span>ArgumentParser<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token comment" spellcheck="true"># 编码器和解码器的最大序列长度</span>
    parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">"--max_enc_len"</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token number">300</span><span class="token punctuation">,</span> help<span class="token operator">=</span><span class="token string">"Encoder input max sequence length"</span><span class="token punctuation">,</span> type<span class="token operator">=</span>int<span class="token punctuation">)</span>
    parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">"--max_dec_len"</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token number">50</span><span class="token punctuation">,</span> help<span class="token operator">=</span><span class="token string">"Decoder input max sequence length"</span><span class="token punctuation">,</span> type<span class="token operator">=</span>int<span class="token punctuation">)</span>
    <span class="token comment" spellcheck="true"># 一个训练批次的大小</span>
    parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">"--batch_size"</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">,</span> help<span class="token operator">=</span><span class="token string">"Batch size"</span><span class="token punctuation">,</span> type<span class="token operator">=</span>int<span class="token punctuation">)</span>
    <span class="token comment" spellcheck="true"># seq2seq训练轮数</span>
    parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">"--seq2seq_train_epochs"</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token number">20</span><span class="token punctuation">,</span> help<span class="token operator">=</span><span class="token string">"Seq2seq model training epochs"</span><span class="token punctuation">,</span> type<span class="token operator">=</span>int<span class="token punctuation">)</span>
    <span class="token comment" spellcheck="true"># 词嵌入大小</span>
    parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">"--embed_size"</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token number">500</span><span class="token punctuation">,</span> help<span class="token operator">=</span><span class="token string">"Words embeddings dimension"</span><span class="token punctuation">,</span> type<span class="token operator">=</span>int<span class="token punctuation">)</span>
    <span class="token comment" spellcheck="true"># 编码器、解码器以及attention的隐含层单元数</span>
    parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">"--enc_units"</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token number">512</span><span class="token punctuation">,</span> help<span class="token operator">=</span><span class="token string">"Encoder GRU cell units number"</span><span class="token punctuation">,</span> type<span class="token operator">=</span>int<span class="token punctuation">)</span>
    parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">"--dec_units"</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token number">512</span><span class="token punctuation">,</span> help<span class="token operator">=</span><span class="token string">"Decoder GRU cell units number"</span><span class="token punctuation">,</span> type<span class="token operator">=</span>int<span class="token punctuation">)</span>
    parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">"--attn_units"</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token number">20</span><span class="token punctuation">,</span> help<span class="token operator">=</span><span class="token string">"Used to compute the attention weights"</span><span class="token punctuation">,</span> type<span class="token operator">=</span>int<span class="token punctuation">)</span>
    <span class="token comment" spellcheck="true"># 学习率</span>
    parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">"--learning_rate"</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token number">0.001</span><span class="token punctuation">,</span> help<span class="token operator">=</span><span class="token string">"Learning rate"</span><span class="token punctuation">,</span> type<span class="token operator">=</span>float<span class="token punctuation">)</span>
    args <span class="token operator">=</span> parser<span class="token punctuation">.</span>parse_args<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true"># param是一个字典类型的变量，键为参数名，值为参数值</span>
    params <span class="token operator">=</span> vars<span class="token punctuation">(</span>args<span class="token punctuation">)</span>
    <span class="token keyword">return</span> params
<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">'__main__'</span><span class="token punctuation">:</span>
    res <span class="token operator">=</span> get_params<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>res<span class="token punctuation">)</span>
</code></pre>
<ul>
<li>输出结果:</li>
</ul>
<pre class=" language-python"><code class="language-python"><span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;'max_enc_len': 300, 'max_dec_len': 50, 'batch_size': 64, 'seq2seq_train_epochs': </span>
</code></pre>
<h4 id="第四步-实现保存字典的函数word2vec-utils-py"><a href="#第四步-实现保存字典的函数word2vec-utils-py" class="headerlink" title="第四步: 实现保存字典的函数word2vec_utils.py"></a>第四步: 实现保存字典的函数word2vec_utils.py</h4><ul>
<li>代码文件路径: /home/ec2-user/text_summary/seq2seq/utils/word2vec_utils.py</li>
</ul>
<pre class=" language-python"><code class="language-python"><span class="token keyword">from</span> gensim<span class="token punctuation">.</span>models<span class="token punctuation">.</span>word2vec <span class="token keyword">import</span> Word2Vec


<span class="token keyword">def</span> <span class="token function">load_embedding_matrix_from_model</span><span class="token punctuation">(</span>wv_model_path<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment" spellcheck="true"># 从word2vec模型中获取词向量矩阵</span>
    <span class="token comment" spellcheck="true"># wv_model_path: word2vec模型的路径</span>
    wv_model <span class="token operator">=</span> Word2Vec<span class="token punctuation">.</span>load<span class="token punctuation">(</span>wv_model_path<span class="token punctuation">)</span>
    <span class="token comment" spellcheck="true"># wv_model.wv.vectors包含词向量矩阵</span>
    embedding_matrix <span class="token operator">=</span> wv_model<span class="token punctuation">.</span>wv<span class="token punctuation">.</span>vectors
    <span class="token keyword">return</span> embedding_matrix


<span class="token keyword">def</span> <span class="token function">get_vocab_from_model</span><span class="token punctuation">(</span>wv_model_path<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment" spellcheck="true"># 从word2vec模型中获取正向和反向词典</span>
    <span class="token comment" spellcheck="true"># wv_model_path: word2vec模型的路径</span>
    wv_model <span class="token operator">=</span> Word2Vec<span class="token punctuation">.</span>load<span class="token punctuation">(</span>wv_model_path<span class="token punctuation">)</span>
    id_to_word <span class="token operator">=</span> <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;index: word for index, word in enumerate(wv_model.wv.index2word)&amp;#125;</span>
    word_to_id <span class="token operator">=</span> <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;word: index for index, word in enumerate(wv_model.wv.index2word)&amp;#125;</span>
    <span class="token keyword">return</span> word_to_id<span class="token punctuation">,</span> id_to_word


<span class="token keyword">def</span> <span class="token function">save_vocab_as_txt</span><span class="token punctuation">(</span>filename<span class="token punctuation">,</span> word_to_id<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment" spellcheck="true"># 保存字典</span>
    <span class="token comment" spellcheck="true"># filename: 目标txt文件路径</span>
    <span class="token comment" spellcheck="true"># word_to_id: 要保存的字典</span>
    <span class="token keyword">with</span> open<span class="token punctuation">(</span>filename<span class="token punctuation">,</span> <span class="token string">'w'</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>
        <span class="token keyword">for</span> k<span class="token punctuation">,</span> v <span class="token keyword">in</span> word_to_id<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            f<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token string">"&amp;#123;&amp;#125;\t&amp;#123;&amp;#125;\n"</span><span class="token punctuation">.</span>format<span class="token punctuation">(</span>k<span class="token punctuation">,</span> v<span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre>
<h4 id="第五步-实现数据加载的函数data-loader-py"><a href="#第五步-实现数据加载的函数data-loader-py" class="headerlink" title="第五步: 实现数据加载的函数data_loader.py"></a>第五步: 实现数据加载的函数data_loader.py</h4><ul>
<li>代码文件路径: /home/ec2-user/text_summary/seq2seq/utils/data_loader.py<ul>
<li>1: 获取最大长度的函数.</li>
<li>2: 完成文本语句单词到id的数字映射函数.</li>
<li>3: 填充特殊标识符的函数.</li>
<li>4: 加载停用词表的函数.</li>
<li>5: 清洗文本的函数.</li>
<li>6: 过滤停用词的函数.</li>
<li>7: 语句处理的函数.</li>
<li>8: 加载构建好的训练集和测试集的函数.</li>
<li>9: 完成本步骤总体逻辑的函数build_dataset()函数.</li>
</ul>
</li>
</ul>
<h5 id="1-获取最大长度的函数"><a href="#1-获取最大长度的函数" class="headerlink" title="1: 获取最大长度的函数"></a>1: 获取最大长度的函数</h5><pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">import</span> os
<span class="token keyword">import</span> sys
<span class="token keyword">import</span> re
<span class="token keyword">import</span> jieba
<span class="token comment" spellcheck="true"># 配置模块</span>
<span class="token keyword">from</span> utils<span class="token punctuation">.</span>config <span class="token keyword">import</span> <span class="token operator">*</span>

root_path <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>dirname<span class="token punctuation">(</span>os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>dirname<span class="token punctuation">(</span>os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>abspath<span class="token punctuation">(</span>__file__<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
sys<span class="token punctuation">.</span>path<span class="token punctuation">.</span>append<span class="token punctuation">(</span>root_path<span class="token punctuation">)</span>

<span class="token keyword">def</span> <span class="token function">get_max_len</span><span class="token punctuation">(</span>data<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment" spellcheck="true"># 获得合适的最大长度值(被build_dataset调用)</span>
    <span class="token comment" spellcheck="true"># data: 待统计的数据train_df['Question']</span>
    <span class="token comment" spellcheck="true"># 句子最大长度为空格数+1</span>
    max_lens <span class="token operator">=</span> data<span class="token punctuation">.</span>apply<span class="token punctuation">(</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span> x<span class="token punctuation">.</span>count<span class="token punctuation">(</span><span class="token string">' '</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span>
    <span class="token comment" spellcheck="true"># 平均值+2倍方差的方式</span>
    <span class="token keyword">return</span> int<span class="token punctuation">(</span>np<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>max_lens<span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token number">2</span> <span class="token operator">*</span> np<span class="token punctuation">.</span>std<span class="token punctuation">(</span>max_lens<span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre>
<h5 id="2-完成文本语句单词到id的数字映射函数"><a href="#2-完成文本语句单词到id的数字映射函数" class="headerlink" title="2: 完成文本语句单词到id的数字映射函数"></a>2: 完成文本语句单词到id的数字映射函数</h5><pre class=" language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">transform_data</span><span class="token punctuation">(</span>sentence<span class="token punctuation">,</span> word_to_id<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment" spellcheck="true"># 句子转换为index序列(被build_dataset调用)</span>
    <span class="token comment" spellcheck="true"># sentence: 'word1 word2 word3 ...'  ->  [index1, index2, index3 ...]</span>
    <span class="token comment" spellcheck="true"># word_to_id: 映射字典</span>

    <span class="token comment" spellcheck="true"># 字符串切分成词</span>
    words <span class="token operator">=</span> sentence<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">' '</span><span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true"># 按照word_to_id的id进行转换, 到未知词就填充unk的索引</span>
    ids <span class="token operator">=</span> <span class="token punctuation">[</span>word_to_id<span class="token punctuation">[</span>w<span class="token punctuation">]</span> <span class="token keyword">if</span> w <span class="token keyword">in</span> word_to_id <span class="token keyword">else</span> word_to_id<span class="token punctuation">[</span><span class="token string">'&lt;UNK>'</span><span class="token punctuation">]</span> <span class="token keyword">for</span> w <span class="token keyword">in</span> words<span class="token punctuation">]</span>

    <span class="token comment" spellcheck="true"># 返回映射后的文本id值列表</span>
    <span class="token keyword">return</span> ids
</code></pre>
<h5 id="3-填充特殊标识符的函数"><a href="#3-填充特殊标识符的函数" class="headerlink" title="3: 填充特殊标识符的函数"></a>3: 填充特殊标识符的函数</h5><pre class=" language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">pad_proc</span><span class="token punctuation">(</span>sentence<span class="token punctuation">,</span> max_len<span class="token punctuation">,</span> word_to_id<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment" spellcheck="true"># 根据max_len和vocab填充&lt;START> &lt;STOP> &lt;PAD> &lt;UNK></span>

    <span class="token comment" spellcheck="true"># 0. 按空格统计切分出词</span>
    words <span class="token operator">=</span> sentence<span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">' '</span><span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true"># 1. 截取规定长度的词数</span>
    words <span class="token operator">=</span> words<span class="token punctuation">[</span><span class="token punctuation">:</span>max_len<span class="token punctuation">]</span>

    <span class="token comment" spellcheck="true"># 2. 填充&lt;UNK></span>
    sentence <span class="token operator">=</span> <span class="token punctuation">[</span>w <span class="token keyword">if</span> w <span class="token keyword">in</span> word_to_id <span class="token keyword">else</span> <span class="token string">'&lt;UNK>'</span> <span class="token keyword">for</span> w <span class="token keyword">in</span> words<span class="token punctuation">]</span>

    <span class="token comment" spellcheck="true"># 3. 填充&lt;START> &lt;END></span>
    sentence <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'&lt;START>'</span><span class="token punctuation">]</span> <span class="token operator">+</span> sentence <span class="token operator">+</span> <span class="token punctuation">[</span><span class="token string">'&lt;STOP>'</span><span class="token punctuation">]</span>

    <span class="token comment" spellcheck="true"># 4. 判断长度，填充&lt;PAD></span>
    sentence <span class="token operator">=</span> sentence <span class="token operator">+</span> <span class="token punctuation">[</span><span class="token string">'&lt;PAD>'</span><span class="token punctuation">]</span> <span class="token operator">*</span> <span class="token punctuation">(</span>max_len <span class="token operator">-</span> len<span class="token punctuation">(</span>words<span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true"># 以空格连接列表, 返回结果字符串</span>
    <span class="token keyword">return</span> <span class="token string">' '</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>sentence<span class="token punctuation">)</span>
</code></pre>
<h5 id="4-加载停用词表的函数"><a href="#4-加载停用词表的函数" class="headerlink" title="4: 加载停用词表的函数"></a>4: 加载停用词表的函数</h5><pre class=" language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">load_stop_words</span><span class="token punctuation">(</span>stop_word_path<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment" spellcheck="true"># 加载停用词(程序调用)</span>
    <span class="token comment" spellcheck="true"># stop_word_path: 停用词路径</span>

    <span class="token comment" spellcheck="true"># 打开停用词文件</span>
    f <span class="token operator">=</span> open<span class="token punctuation">(</span>stop_word_path<span class="token punctuation">,</span> <span class="token string">'r'</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span>
    <span class="token comment" spellcheck="true"># 读取所有行</span>
    stop_words <span class="token operator">=</span> f<span class="token punctuation">.</span>readlines<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true"># 去除每一个停用词前后 空格 换行符</span>
    stop_words <span class="token operator">=</span> <span class="token punctuation">[</span>stop_word<span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">for</span> stop_word <span class="token keyword">in</span> stop_words<span class="token punctuation">]</span>
    <span class="token keyword">return</span> stop_words
<span class="token comment" spellcheck="true"># 加载停用词, 这里面的stop_words_path是早已在config.py文件中配置好的</span>
stop_words <span class="token operator">=</span> load_stop_words<span class="token punctuation">(</span>stop_words_path<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'stop_words: '</span><span class="token punctuation">,</span> stop_words<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">20</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre>
<h5 id="打印"><a href="#打印" class="headerlink" title="打印"></a>打印</h5><pre class=" language-python"><code class="language-python">stop_words<span class="token punctuation">:</span>  <span class="token punctuation">[</span><span class="token string">':'</span><span class="token punctuation">,</span> <span class="token string">'：'</span><span class="token punctuation">,</span> <span class="token string">'———'</span><span class="token punctuation">,</span> <span class="token string">'》），'</span><span class="token punctuation">,</span> <span class="token string">'）÷（１－'</span><span class="token punctuation">,</span> <span class="token string">'”，'</span><span class="token punctuation">,</span> <span class="token string">'）、'</span><span class="token punctuation">,</span> <span class="token string">'＝（'</span><span class="token punctuation">,</span> <span class="token string">'→'</span><span class="token punctuation">,</span> <span class="token string">'℃'</span><span class="token punctuation">,</span> <span class="token string">'&amp;'</span><span class="token punctuation">,</span> <span class="token string">'*'</span><span class="token punctuation">,</span> <span class="token string">'一一'</span><span class="token punctuation">,</span> <span class="token string">'~~~~'</span><span class="token punctuation">,</span> <span class="token string">'『'</span><span class="token punctuation">,</span> <span class="token string">'.一'</span><span class="token punctuation">,</span> <span class="token string">'./'</span><span class="token punctuation">,</span> <span class="token string">'--'</span><span class="token punctuation">,</span> <span class="token string">'』'</span><span class="token punctuation">,</span> <span class="token string">'＝″'</span><span class="token punctuation">]</span>
</code></pre>
<h5 id="5-清洗文本的函数"><a href="#5-清洗文本的函数" class="headerlink" title="5: 清洗文本的函数"></a>5: 清洗文本的函数</h5><pre class=" language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">clean_sentence</span><span class="token punctuation">(</span>sentence<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment" spellcheck="true"># 特殊符号去除(被sentence_proc调用)</span>
    <span class="token comment" spellcheck="true"># sentence: 待处理的字符串</span>
    <span class="token keyword">if</span> isinstance<span class="token punctuation">(</span>sentence<span class="token punctuation">,</span> str<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment" spellcheck="true"># 删除1. 2. 3. 这些标题</span>
        r <span class="token operator">=</span> re<span class="token punctuation">.</span>compile<span class="token punctuation">(</span><span class="token string">"\D(\d\.)\D"</span><span class="token punctuation">)</span>
        sentence <span class="token operator">=</span> r<span class="token punctuation">.</span>sub<span class="token punctuation">(</span><span class="token string">""</span><span class="token punctuation">,</span> sentence<span class="token punctuation">)</span>

        <span class="token comment" spellcheck="true"># 删除带括号的 进口 海外</span>
        r <span class="token operator">=</span> re<span class="token punctuation">.</span>compile<span class="token punctuation">(</span>r<span class="token string">"[(（]进口[)）]|\(海外\)"</span><span class="token punctuation">)</span>
        sentence <span class="token operator">=</span> r<span class="token punctuation">.</span>sub<span class="token punctuation">(</span><span class="token string">""</span><span class="token punctuation">,</span> sentence<span class="token punctuation">)</span>
        <span class="token comment" spellcheck="true"># 删除除了汉字数字字母和，！？。.- 以外的字符</span>
        r <span class="token operator">=</span> re<span class="token punctuation">.</span>compile<span class="token punctuation">(</span><span class="token string">"[^，！？。\.\-\u4e00-\u9fa5_a-zA-Z0-9]"</span><span class="token punctuation">)</span>
        <span class="token comment" spellcheck="true"># 用中文输入法下的，！？来替换英文输入法下的,!?</span>
        sentence <span class="token operator">=</span> sentence<span class="token punctuation">.</span>replace<span class="token punctuation">(</span><span class="token string">","</span><span class="token punctuation">,</span> <span class="token string">"，"</span><span class="token punctuation">)</span>
        sentence <span class="token operator">=</span> sentence<span class="token punctuation">.</span>replace<span class="token punctuation">(</span><span class="token string">"!"</span><span class="token punctuation">,</span> <span class="token string">"！"</span><span class="token punctuation">)</span>
        sentence <span class="token operator">=</span> sentence<span class="token punctuation">.</span>replace<span class="token punctuation">(</span><span class="token string">"?"</span><span class="token punctuation">,</span> <span class="token string">"？"</span><span class="token punctuation">)</span>
        sentence <span class="token operator">=</span> r<span class="token punctuation">.</span>sub<span class="token punctuation">(</span><span class="token string">""</span><span class="token punctuation">,</span> sentence<span class="token punctuation">)</span>

        <span class="token comment" spellcheck="true"># 删除 车主说 技师说 语音 图片 你好 您好</span>
        r <span class="token operator">=</span> re<span class="token punctuation">.</span>compile<span class="token punctuation">(</span>r<span class="token string">"车主说|技师说|语音|图片|你好|您好"</span><span class="token punctuation">)</span>
        sentence <span class="token operator">=</span> r<span class="token punctuation">.</span>sub<span class="token punctuation">(</span><span class="token string">""</span><span class="token punctuation">,</span> sentence<span class="token punctuation">)</span>
        <span class="token keyword">return</span> sentence
    <span class="token keyword">else</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> <span class="token string">''</span>
    
sentence <span class="token operator">=</span> <span class="token string">'技师说：你好！以前也出现过该故障吗？|技师说：缸压多少有没有测量一下?|车主说：没有过|车主说：没测缸压|技师说：测量一下缸压 看一四缸缸压是否偏低|车主说：用电脑测，只是14缸缺火|车主说：[语音]|车主说：[语音]|技师说：点火线圈  火花塞 喷油嘴不用干活  直接和二三缸对倒一下  跑一段在测量一下故障码进行排除|车主说：[语音]|车主>说：[语音]|车主说：[语音]|车主说：[语音]|车主说：师傅还在吗|技师说：调一下喷油嘴  测一下缸压  都正常则为发动机电脑板问题|车主说：[语音]|车主说：[语音]|车主说：[语音]|技师说：这个影响不大的|技师说：缸压八个以上正常|车主说：[语音]|技师说：所以说让你测量缸压  只要缸压正常则没有问题|车主说：[语音]|车主说：[语音]|技师说：可以点击头像关注我  有什么问题随时询问  一定真诚用心为你解决|车主说：师傅，谢谢了|技师说：不用客气'</span>

res <span class="token operator">=</span> clean_sentence<span class="token punctuation">(</span>sentence<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'res='</span><span class="token punctuation">,</span> res<span class="token punctuation">)</span>
</code></pre>
<h5 id="打印：-2"><a href="#打印：-2" class="headerlink" title="打印："></a>打印：</h5><pre class=" language-python"><code class="language-python">res<span class="token operator">=</span> ！以前也出现过该故障吗？缸压多少有没有测量一下？没有过没测缸压测量一下缸压看一四缸缸压是否偏低用电脑测，只是<span class="token number">14</span>缸缺火点火线圈火花塞喷油嘴不用干活直接和二三缸对倒一下跑一段在测量一下故障码进行排除师傅还在吗调一下喷油嘴测一下缸压都正常则为发动机电脑板问题这个影响不大的缸压八个以上正常所以说让你测量缸压只要缸压正常则没有问题可以点击头像关注我有什么问题随时询问一定真诚用心为你解决师傅，谢谢了不用客气
</code></pre>
<h5 id="6：-过滤停用词的函数"><a href="#6：-过滤停用词的函数" class="headerlink" title="6：#过滤停用词的函数"></a>6：#过滤停用词的函数</h5><pre class=" language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">filter_stopwords</span><span class="token punctuation">(</span>seg_list<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment" spellcheck="true"># 过滤一句切好词的话中的停用词(被sentence_proc调用)</span>
    <span class="token comment" spellcheck="true"># seg_list: 切好词的列表 [word1 ,word2 .......]</span>
    <span class="token comment" spellcheck="true"># 首先去掉多余空字符</span>
    words <span class="token operator">=</span> <span class="token punctuation">[</span>word <span class="token keyword">for</span> word <span class="token keyword">in</span> seg_list <span class="token keyword">if</span> word<span class="token punctuation">]</span>
    <span class="token comment" spellcheck="true"># 去掉停用词</span>
    <span class="token keyword">return</span> <span class="token punctuation">[</span>word <span class="token keyword">for</span> word <span class="token keyword">in</span> words <span class="token keyword">if</span> word <span class="token operator">not</span> <span class="token keyword">in</span> stop_words<span class="token punctuation">]</span>

<span class="token comment" spellcheck="true"># 第一步: 先将原始文本执行清洗操作</span>
res <span class="token operator">=</span> clean_sentence<span class="token punctuation">(</span>sentence<span class="token punctuation">)</span>
<span class="token comment" spellcheck="true"># print('res=', res)</span>
<span class="token comment" spellcheck="true"># 第二步: 对清洗结果进行分词, 默认是精确模式, 当设置cut_all=True时, 采用全模式</span>
words <span class="token operator">=</span> jieba<span class="token punctuation">.</span>cut<span class="token punctuation">(</span>res<span class="token punctuation">)</span>
<span class="token comment" spellcheck="true"># 第三步: 将分词的结果传入过滤停用词函数中, 并打印结果</span>
result <span class="token operator">=</span> filter_stopwords<span class="token punctuation">(</span>words<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>result<span class="token punctuation">)</span>
</code></pre>
<h5 id="打印-1"><a href="#打印-1" class="headerlink" title="打印"></a>打印</h5><pre class=" language-python"><code class="language-python"><span class="token punctuation">[</span><span class="token string">'！'</span><span class="token punctuation">,</span> <span class="token string">'以前'</span><span class="token punctuation">,</span> <span class="token string">'出现'</span><span class="token punctuation">,</span> <span class="token string">'过该'</span><span class="token punctuation">,</span> <span class="token string">'故障'</span><span class="token punctuation">,</span> <span class="token string">'？'</span><span class="token punctuation">,</span> <span class="token string">'缸'</span><span class="token punctuation">,</span> <span class="token string">'压'</span><span class="token punctuation">,</span> <span class="token string">'有没有'</span><span class="token punctuation">,</span> <span class="token string">'测量'</span><span class="token punctuation">,</span> <span class="token string">'一下'</span><span class="token punctuation">,</span> <span class="token string">'？'</span><span class="token punctuation">,</span> <span class="token string">'没有'</span><span class="token punctuation">,</span> <span class="token string">'没测'</span><span class="token punctuation">,</span> <span class="token string">'缸'</span><span class="token punctuation">,</span> <span class="token string">'压'</span><span class="token punctuation">,</span> <span class="token string">'测量'</span><span class="token punctuation">,</span> <span class="token string">'一下'</span><span class="token punctuation">,</span> <span class="token string">'缸'</span><span class="token punctuation">,</span> <span class="token string">'压'</span><span class="token punctuation">,</span> <span class="token string">'看'</span><span class="token punctuation">,</span> <span class="token string">'一四缸'</span><span class="token punctuation">,</span> <span class="token string">'缸'</span><span class="token punctuation">,</span> <span class="token string">'压'</span><span class="token punctuation">,</span> <span class="token string">'是否'</span><span class="token punctuation">,</span> <span class="token string">'偏低'</span><span class="token punctuation">,</span> <span class="token string">'电脑'</span><span class="token punctuation">,</span> <span class="token string">'测'</span><span class="token punctuation">,</span> <span class="token string">'，'</span><span class="token punctuation">,</span> <span class="token string">'14'</span><span class="token punctuation">,</span> <span class="token string">'缸'</span><span class="token punctuation">,</span> <span class="token string">'缺火'</span><span class="token punctuation">,</span> <span class="token string">'点火'</span><span class="token punctuation">,</span> <span class="token string">'线圈'</span><span class="token punctuation">,</span> <span class="token string">'火花塞'</span><span class="token punctuation">,</span> <span class="token string">'喷油嘴'</span><span class="token punctuation">,</span> <span class="token string">'不用'</span><span class="token punctuation">,</span> <span class="token string">'干活'</span><span class="token punctuation">,</span> <span class="token string">'直接'</span><span class="token punctuation">,</span> <span class="token string">'二三'</span><span class="token punctuation">,</span> <span class="token string">'缸'</span><span class="token punctuation">,</span> <span class="token string">'倒'</span><span class="token punctuation">,</span> <span class="token string">'一下'</span><span class="token punctuation">,</span> <span class="token string">'跑'</span><span class="token punctuation">,</span> <span class="token string">'一段'</span><span class="token punctuation">,</span> <span class="token string">'测量'</span><span class="token punctuation">,</span> <span class="token string">'一下'</span><span class="token punctuation">,</span> <span class="token string">'故障'</span><span class="token punctuation">,</span> <span class="token string">'码'</span><span class="token punctuation">,</span> <span class="token string">'进行'</span><span class="token punctuation">,</span> <span class="token string">'排除'</span><span class="token punctuation">,</span> <span class="token string">'师傅'</span><span class="token punctuation">,</span> <span class="token string">'还'</span><span class="token punctuation">,</span> <span class="token string">'调'</span><span class="token punctuation">,</span> <span class="token string">'一下'</span><span class="token punctuation">,</span> <span class="token string">'喷油嘴'</span><span class="token punctuation">,</span> <span class="token string">'测'</span><span class="token punctuation">,</span> <span class="token string">'一下'</span><span class="token punctuation">,</span> <span class="token string">'缸'</span><span class="token punctuation">,</span> <span class="token string">'压'</span><span class="token punctuation">,</span> <span class="token string">'都'</span><span class="token punctuation">,</span> <span class="token string">'正常'</span><span class="token punctuation">,</span> <span class="token string">'发动机'</span><span class="token punctuation">,</span> <span class="token string">'电脑板'</span><span class="token punctuation">,</span> <span class="token string">'问题'</span><span class="token punctuation">,</span> <span class="token string">'影响'</span><span class="token punctuation">,</span> <span class="token string">'不大'</span><span class="token punctuation">,</span> <span class="token string">'缸'</span><span class="token punctuation">,</span> <span class="token string">'压'</span><span class="token punctuation">,</span> <span class="token string">'八个'</span><span class="token punctuation">,</span> <span class="token string">'以上'</span><span class="token punctuation">,</span> <span class="token string">'正常'</span><span class="token punctuation">,</span> <span class="token string">'说'</span><span class="token punctuation">,</span> <span class="token string">'测量'</span><span class="token punctuation">,</span> <span class="token string">'缸'</span><span class="token punctuation">,</span> <span class="token string">'压'</span><span class="token punctuation">,</span> <span class="token string">'缸'</span><span class="token punctuation">,</span> <span class="token string">'压'</span><span class="token punctuation">,</span> <span class="token string">'正常'</span><span class="token punctuation">,</span> <span class="token string">'没有'</span><span class="token punctuation">,</span> <span class="token string">'问题'</span><span class="token punctuation">,</span> <span class="token string">'点击'</span><span class="token punctuation">,</span> <span class="token string">'头像'</span><span class="token punctuation">,</span> <span class="token string">'关注'</span><span class="token punctuation">,</span> <span class="token string">'问题'</span><span class="token punctuation">,</span> <span class="token string">'随时'</span><span class="token punctuation">,</span> <span class="token string">'询问'</span><span class="token punctuation">,</span> <span class="token string">'一定'</span><span class="token punctuation">,</span> <span class="token string">'真诚'</span><span class="token punctuation">,</span> <span class="token string">'用心'</span><span class="token punctuation">,</span> <span class="token string">'解决'</span><span class="token punctuation">,</span> <span class="token string">'师傅'</span><span class="token punctuation">,</span> <span class="token string">'，'</span><span class="token punctuation">,</span> <span class="token string">'谢谢'</span><span class="token punctuation">,</span> <span class="token string">'不用'</span><span class="token punctuation">,</span> <span class="token string">'客气'</span><span class="token punctuation">]</span>
</code></pre>
<h5 id="7：句子的处理"><a href="#7：句子的处理" class="headerlink" title="7：句子的处理"></a>7：句子的处理</h5><pre class=" language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">sentence_proc</span><span class="token punctuation">(</span>sentence<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment" spellcheck="true"># 预处理模块(处理一条句子, 被sentences_proc调用)</span>
    <span class="token comment" spellcheck="true"># sentence: 待处理字符串</span>

    <span class="token comment" spellcheck="true"># 第一步: 执行清洗原始文本的操作</span>
    sentence <span class="token operator">=</span> clean_sentence<span class="token punctuation">(</span>sentence<span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true"># 第二步: 执行分词操作, 默认精确模式, 全模式cut参数cut_all=True</span>
    words <span class="token operator">=</span> jieba<span class="token punctuation">.</span>cut<span class="token punctuation">(</span>sentence<span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true"># 第三步: 将分词结果输入过滤停用词函数中</span>
    words <span class="token operator">=</span> filter_stopwords<span class="token punctuation">(</span>words<span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true"># 返回字符串结果, 按空格分隔, 将过滤停用词后的列表拼接</span>
    <span class="token keyword">return</span> <span class="token string">' '</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>words<span class="token punctuation">)</span>

res <span class="token operator">=</span> sentence_proc<span class="token punctuation">(</span>sentence<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'res='</span><span class="token punctuation">,</span> res<span class="token punctuation">)</span>
</code></pre>
<h5 id="打印-2"><a href="#打印-2" class="headerlink" title="打印"></a>打印</h5><pre class=" language-python"><code class="language-python">res<span class="token operator">=</span> ！ 以前 出现 过该 故障 ？ 缸 压 有没有 测量 一下 ？ 没有 没测 缸 压 测量 一下 缸 压 看 一四缸 缸 压 是否 偏低 电脑 测 ， <span class="token number">14</span> 缸 缺火 点火 线圈 火花塞 喷油嘴 不用 干活 直接 二三 缸 倒 一下 跑 一段 测量 一下 故障 码 进行 排除 师傅 还 调 一下 喷油嘴 测 一下 缸 压 都 正常 发动机 电脑板 问题 影响 不大 缸 压 八个 以上 正常 说 测量 缸 压 缸 压 正常 没有 问题 点击 头像 关注 问题 随时 询问 一定 真诚 用心 解决 师傅 ， 谢谢 不用 客气
</code></pre>
<h5 id="7：语句处理的函数-2"><a href="#7：语句处理的函数-2" class="headerlink" title="7：语句处理的函数(2)"></a>7：语句处理的函数(2)</h5><pre class=" language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">sentences_proc</span><span class="token punctuation">(</span>df<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment" spellcheck="true"># 预处理模块(处理一个句子列表, 对每个句子调用sentence_proc操作)</span>
    <span class="token comment" spellcheck="true"># df: 数据集</span>

    <span class="token comment" spellcheck="true"># 批量预处理训练集和测试集</span>
    <span class="token keyword">for</span> col_name <span class="token keyword">in</span> <span class="token punctuation">[</span><span class="token string">'Brand'</span><span class="token punctuation">,</span> <span class="token string">'Model'</span><span class="token punctuation">,</span> <span class="token string">'Question'</span><span class="token punctuation">,</span> <span class="token string">'Dialogue'</span><span class="token punctuation">]</span><span class="token punctuation">:</span>
        df<span class="token punctuation">[</span>col_name<span class="token punctuation">]</span> <span class="token operator">=</span> df<span class="token punctuation">[</span>col_name<span class="token punctuation">]</span><span class="token punctuation">.</span>apply<span class="token punctuation">(</span>sentence_proc<span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true"># 训练集Report预处理</span>
    <span class="token keyword">if</span> <span class="token string">'Report'</span> <span class="token keyword">in</span> df<span class="token punctuation">.</span>columns<span class="token punctuation">:</span>
        df<span class="token punctuation">[</span><span class="token string">'Report'</span><span class="token punctuation">]</span> <span class="token operator">=</span> df<span class="token punctuation">[</span><span class="token string">'Report'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>apply<span class="token punctuation">(</span>sentence_proc<span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true"># 以Pandas的DataFrame格式返回</span>
    <span class="token keyword">return</span> df
</code></pre>
<h5 id="8：加载构建好的训练集和测试集的函数"><a href="#8：加载构建好的训练集和测试集的函数" class="headerlink" title="8：加载构建好的训练集和测试集的函数"></a>8：加载构建好的训练集和测试集的函数</h5><pre class=" language-python"><code class="language-python">
<span class="token comment" spellcheck="true"># 加载处理好的训练样本和训练标签.npy文件(执行完build_dataset后才能使用)</span>
<span class="token keyword">def</span> <span class="token function">load_train_dataset</span><span class="token punctuation">(</span>max_enc_len<span class="token operator">=</span><span class="token number">300</span><span class="token punctuation">,</span> max_dec_len<span class="token operator">=</span><span class="token number">50</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment" spellcheck="true"># max_enc_len: 最长样本长度, 后面的截断</span>
    <span class="token comment" spellcheck="true"># max_dec_len: 最长标签长度, 后面的截断</span>
    train_X <span class="token operator">=</span> np<span class="token punctuation">.</span>load<span class="token punctuation">(</span>train_x_path<span class="token punctuation">)</span>
    train_Y <span class="token operator">=</span> np<span class="token punctuation">.</span>load<span class="token punctuation">(</span>train_y_path<span class="token punctuation">)</span>

    train_X <span class="token operator">=</span> train_X<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span>max_enc_len<span class="token punctuation">]</span>
    train_Y <span class="token operator">=</span> train_Y<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span>max_dec_len<span class="token punctuation">]</span>

    <span class="token keyword">return</span> train_X<span class="token punctuation">,</span> train_Y

<span class="token comment" spellcheck="true"># 加载处理好的测试样本.npy文件(执行完build_dataset后才能使用)</span>
<span class="token keyword">def</span> <span class="token function">load_test_dataset</span><span class="token punctuation">(</span>max_enc_len<span class="token operator">=</span><span class="token number">300</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment" spellcheck="true"># max_enc_len: 最长样本长度, 后面的截断</span>
    test_X <span class="token operator">=</span> np<span class="token punctuation">.</span>load<span class="token punctuation">(</span>test_x_path<span class="token punctuation">)</span>
    test_X <span class="token operator">=</span> test_X<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span>max_enc_len<span class="token punctuation">]</span>
    <span class="token keyword">return</span> test_X
</code></pre>
<h5 id="9-完成本步骤总体逻辑的函数build-dataset-函数"><a href="#9-完成本步骤总体逻辑的函数build-dataset-函数" class="headerlink" title="9: 完成本步骤总体逻辑的函数build_dataset()函数"></a>9: 完成本步骤总体逻辑的函数build_dataset()函数</h5><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 数据预处理总函数, 用于数据加载 + 预处理 (注意: 只需执行一次)</span>
<span class="token keyword">def</span> <span class="token function">build_dataset</span><span class="token punctuation">(</span>train_raw_data_path<span class="token punctuation">,</span> test_raw_data_path<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment" spellcheck="true"># 1. 加载原始数据</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'1. 加载原始数据'</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>train_raw_data_path<span class="token punctuation">)</span>
    <span class="token comment" spellcheck="true"># 必须设定数据格式为utf-8</span>
    train_df <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span>train_raw_data_path<span class="token punctuation">,</span> engine<span class="token operator">=</span><span class="token string">'python'</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span>
    test_df <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span>test_raw_data_path<span class="token punctuation">,</span> engine<span class="token operator">=</span><span class="token string">'python'</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true"># 82943, 20000</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'原始训练集行数 &amp;#123;&amp;#125;, 测试集行数 &amp;#123;&amp;#125;'</span><span class="token punctuation">.</span>format<span class="token punctuation">(</span>len<span class="token punctuation">(</span>train_df<span class="token punctuation">)</span><span class="token punctuation">,</span> len<span class="token punctuation">(</span>test_df<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'\n'</span><span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true"># 2. 空值去除(对于一行数据, 任意列只要有空值就去掉该行)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'2. 空值去除（对于一行数据，任意列只要有空值就去掉该行）'</span><span class="token punctuation">)</span>
    train_df<span class="token punctuation">.</span>dropna<span class="token punctuation">(</span>subset<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'Question'</span><span class="token punctuation">,</span> <span class="token string">'Dialogue'</span><span class="token punctuation">,</span> <span class="token string">'Report'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> how<span class="token operator">=</span><span class="token string">'any'</span><span class="token punctuation">,</span> inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
    test_df<span class="token punctuation">.</span>dropna<span class="token punctuation">(</span>subset<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'Question'</span><span class="token punctuation">,</span> <span class="token string">'Dialogue'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> how<span class="token operator">=</span><span class="token string">'any'</span><span class="token punctuation">,</span> inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'空值去除后训练集行数 &amp;#123;&amp;#125;, 测试集行数 &amp;#123;&amp;#125;'</span><span class="token punctuation">.</span>format<span class="token punctuation">(</span>len<span class="token punctuation">(</span>train_df<span class="token punctuation">)</span><span class="token punctuation">,</span> len<span class="token punctuation">(</span>test_df<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'\n'</span><span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true"># 3. 多线程, 批量数据预处理(对每个句子执行sentence_proc, 清除无用词, 分词, 过滤停用词, 再用空格拼接为一个字符串)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'3. 多线程, 批量数据预处理(对每个句子执行sentence_proc, 清除无用词, 分词, 过滤停用词, 再用空格拼接为一个字符串)'</span><span class="token punctuation">)</span>
    train_df <span class="token operator">=</span> parallelize<span class="token punctuation">(</span>train_df<span class="token punctuation">,</span> sentences_proc<span class="token punctuation">)</span>
    test_df <span class="token operator">=</span> parallelize<span class="token punctuation">(</span>test_df<span class="token punctuation">,</span> sentences_proc<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'\n'</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'sentences_proc has done!'</span><span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true"># 4. 合并训练测试集, 用于构造映射字典word_to_id</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'4. 合并训练测试集, 用于构造映射字典word_to_id'</span><span class="token punctuation">)</span>
    <span class="token comment" spellcheck="true"># 新建一列, 按行堆积</span>
    train_df<span class="token punctuation">[</span><span class="token string">'merged'</span><span class="token punctuation">]</span> <span class="token operator">=</span> train_df<span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token string">'Question'</span><span class="token punctuation">,</span> <span class="token string">'Dialogue'</span><span class="token punctuation">,</span> <span class="token string">'Report'</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">.</span>apply<span class="token punctuation">(</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span> <span class="token string">' '</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
    <span class="token comment" spellcheck="true"># 新建一列, 按行堆积</span>
    test_df<span class="token punctuation">[</span><span class="token string">'merged'</span><span class="token punctuation">]</span> <span class="token operator">=</span> test_df<span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token string">'Question'</span><span class="token punctuation">,</span> <span class="token string">'Dialogue'</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">.</span>apply<span class="token punctuation">(</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span> <span class="token string">' '</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
    <span class="token comment" spellcheck="true"># merged列是训练集三列和测试集两列按行连接在一起再按列堆积, 用于构造映射字典</span>
    <span class="token comment" spellcheck="true"># 按列堆积, 用于构造映射字典</span>
    merged_df <span class="token operator">=</span> pd<span class="token punctuation">.</span>concat<span class="token punctuation">(</span><span class="token punctuation">[</span>train_df<span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token string">'merged'</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> test_df<span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token string">'merged'</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'训练集行数&amp;#123;&amp;#125;, 测试集行数&amp;#123;&amp;#125;, 合并数据集行数&amp;#123;&amp;#125;'</span><span class="token punctuation">.</span>format<span class="token punctuation">(</span>len<span class="token punctuation">(</span>train_df<span class="token punctuation">)</span><span class="token punctuation">,</span> len<span class="token punctuation">(</span>test_df<span class="token punctuation">)</span><span class="token punctuation">,</span> len<span class="token punctuation">(</span>merged_df<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'\n'</span><span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true"># 5. 保存分割处理好的train_seg_data.csv, test_set_data.csv</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'5. 保存分割处理好的train_seg_data.csv, test_set_data.csv'</span><span class="token punctuation">)</span>
    <span class="token comment" spellcheck="true"># 把建立的列merged去掉, 该列对于神经网络无用</span>
    train_df <span class="token operator">=</span> train_df<span class="token punctuation">.</span>drop<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">'merged'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
    test_df <span class="token operator">=</span> test_df<span class="token punctuation">.</span>drop<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">'merged'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
    <span class="token comment" spellcheck="true"># 将处理后的数据存入持久化文件</span>
    train_df<span class="token punctuation">.</span>to_csv<span class="token punctuation">(</span>train_seg_path<span class="token punctuation">,</span> index<span class="token operator">=</span>None<span class="token punctuation">,</span> header<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
    test_df<span class="token punctuation">.</span>to_csv<span class="token punctuation">(</span>test_seg_path<span class="token punctuation">,</span> index<span class="token operator">=</span>None<span class="token punctuation">,</span> header<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'The csv_file has saved!'</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'\n'</span><span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true"># 6. 保存合并数据merged_seg_data.csv, 用于构造映射字典word_to_id</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'6. 保存合并数据merged_seg_data.csv, 用于构造映射字典word_to_id'</span><span class="token punctuation">)</span>
    merged_df<span class="token punctuation">.</span>to_csv<span class="token punctuation">(</span>merged_seg_path<span class="token punctuation">,</span> index<span class="token operator">=</span>None<span class="token punctuation">,</span> header<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'The word_to_vector file has saved!'</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'\n'</span><span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true"># 7. 构建word_to_id字典和id_to_word字典, 根据第6步存储的合并文件数据来完成.</span>
    word_to_id <span class="token operator">=</span> <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;&amp;#125;</span>
    count <span class="token operator">=</span> <span class="token number">0</span>

    <span class="token comment" spellcheck="true"># 对训练集数据X进行处理</span>
    <span class="token keyword">with</span> open<span class="token punctuation">(</span>merged_seg_path<span class="token punctuation">,</span> <span class="token string">'r'</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f1<span class="token punctuation">:</span>
        <span class="token keyword">for</span> line <span class="token keyword">in</span> f1<span class="token punctuation">.</span>readlines<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            line <span class="token operator">=</span> line<span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">' '</span><span class="token punctuation">)</span>
            <span class="token keyword">for</span> w <span class="token keyword">in</span> line<span class="token punctuation">:</span>
                <span class="token keyword">if</span> w <span class="token operator">not</span> <span class="token keyword">in</span> word_to_id<span class="token punctuation">:</span>
                    word_to_id<span class="token punctuation">[</span>w<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">1</span>
                    count <span class="token operator">+=</span> <span class="token number">1</span>
                <span class="token keyword">else</span><span class="token punctuation">:</span>
                    word_to_id<span class="token punctuation">[</span>w<span class="token punctuation">]</span> <span class="token operator">+=</span> <span class="token number">1</span>

    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'总体单词总数count='</span><span class="token punctuation">,</span> count<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'\n'</span><span class="token punctuation">)</span>

    res_dict <span class="token operator">=</span> <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;&amp;#125;</span>
    number <span class="token operator">=</span> <span class="token number">0</span>
    <span class="token keyword">for</span> w<span class="token punctuation">,</span> i <span class="token keyword">in</span> word_to_id<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">if</span> i <span class="token operator">>=</span> <span class="token number">5</span><span class="token punctuation">:</span>
            res_dict<span class="token punctuation">[</span>w<span class="token punctuation">]</span> <span class="token operator">=</span> i
            number <span class="token operator">+=</span> <span class="token number">1</span>

    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'进入到字典中的单词总数number='</span><span class="token punctuation">,</span> number<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'合并数据集的字典构造完毕, word_to_id容量: '</span><span class="token punctuation">,</span> len<span class="token punctuation">(</span>res_dict<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'\n'</span><span class="token punctuation">)</span>

    word_to_id <span class="token operator">=</span> <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;&amp;#125;</span>
    count <span class="token operator">=</span> <span class="token number">0</span>
    <span class="token keyword">for</span> w<span class="token punctuation">,</span> i <span class="token keyword">in</span> res_dict<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">if</span> w <span class="token operator">not</span> <span class="token keyword">in</span> word_to_id<span class="token punctuation">:</span>
            word_to_id<span class="token punctuation">[</span>w<span class="token punctuation">]</span> <span class="token operator">=</span> count
            count <span class="token operator">+=</span> <span class="token number">1</span>

    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'最终构造完毕字典, word_to_id容量='</span><span class="token punctuation">,</span> len<span class="token punctuation">(</span>word_to_id<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'count='</span><span class="token punctuation">,</span> count<span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true"># 8. 将Question和Dialogue用空格连接作为模型输入形成train_df['X']</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"8. 将Question和Dialogue用空格连接作为模型输入形成train_df['X']"</span><span class="token punctuation">)</span>
    train_df<span class="token punctuation">[</span><span class="token string">'X'</span><span class="token punctuation">]</span> <span class="token operator">=</span> train_df<span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token string">'Question'</span><span class="token punctuation">,</span> <span class="token string">'Dialogue'</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">.</span>apply<span class="token punctuation">(</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span> <span class="token string">' '</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
    test_df<span class="token punctuation">[</span><span class="token string">'X'</span><span class="token punctuation">]</span> <span class="token operator">=</span> test_df<span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token string">'Question'</span><span class="token punctuation">,</span> <span class="token string">'Dialogue'</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">.</span>apply<span class="token punctuation">(</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span> <span class="token string">' '</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'\n'</span><span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true"># 9. 填充&lt;START>, &lt;STOP>, &lt;UNK>和&lt;PAD>, 使数据变为等长</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'9. 填充&lt;START>, &lt;STOP>, &lt;UNK> 和 &lt;PAD>, 使数据变为等长'</span><span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true"># 获取适当的最大长度</span>
    train_x_max_len <span class="token operator">=</span> get_max_len<span class="token punctuation">(</span>train_df<span class="token punctuation">[</span><span class="token string">'X'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    test_x_max_len <span class="token operator">=</span> get_max_len<span class="token punctuation">(</span>test_df<span class="token punctuation">[</span><span class="token string">'X'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    train_y_max_len <span class="token operator">=</span> get_max_len<span class="token punctuation">(</span>train_df<span class="token punctuation">[</span><span class="token string">'Report'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'填充前训练集样本的最大长度为: '</span><span class="token punctuation">,</span> train_x_max_len<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'填充前测试集样本的最大长度为: '</span><span class="token punctuation">,</span> test_x_max_len<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'填充前训练集标签的最大长度为: '</span><span class="token punctuation">,</span> train_y_max_len<span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true"># 选训练集和测试集中较大的值</span>
    x_max_len <span class="token operator">=</span> max<span class="token punctuation">(</span>train_x_max_len<span class="token punctuation">,</span> test_x_max_len<span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true"># 训练集X填充处理</span>
    <span class="token comment" spellcheck="true"># train_df['X'] = train_df['X'].apply(lambda x: pad_proc(x, x_max_len, vocab))</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'训练集X填充PAD, START, STOP, UNK处理中...'</span><span class="token punctuation">)</span>
    train_df<span class="token punctuation">[</span><span class="token string">'X'</span><span class="token punctuation">]</span> <span class="token operator">=</span> train_df<span class="token punctuation">[</span><span class="token string">'X'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>apply<span class="token punctuation">(</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span> pad_proc<span class="token punctuation">(</span>x<span class="token punctuation">,</span> x_max_len<span class="token punctuation">,</span> word_to_id<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token comment" spellcheck="true"># 测试集X填充处理</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'测试集X填充PAD, START, STOP, UNK处理中...'</span><span class="token punctuation">)</span>
    test_df<span class="token punctuation">[</span><span class="token string">'X'</span><span class="token punctuation">]</span> <span class="token operator">=</span> test_df<span class="token punctuation">[</span><span class="token string">'X'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>apply<span class="token punctuation">(</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span> pad_proc<span class="token punctuation">(</span>x<span class="token punctuation">,</span> x_max_len<span class="token punctuation">,</span> word_to_id<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token comment" spellcheck="true"># 训练集Y填充处理</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'训练集Y填充PAD, START, STOP, UNK处理中...'</span><span class="token punctuation">)</span>
    train_df<span class="token punctuation">[</span><span class="token string">'Y'</span><span class="token punctuation">]</span> <span class="token operator">=</span> train_df<span class="token punctuation">[</span><span class="token string">'Report'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>apply<span class="token punctuation">(</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span> pad_proc<span class="token punctuation">(</span>x<span class="token punctuation">,</span> train_y_max_len<span class="token punctuation">,</span> word_to_id<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'\n'</span><span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true"># 10. 保存填充&lt;START>, &lt;STOP>, &lt;UNK>和&lt;PAD>后的X和Y</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'10. 保存填充&lt;START>, &lt;STOP>, &lt;UNK> 和 &lt;PAD>后的X和Y'</span><span class="token punctuation">)</span>
    train_df<span class="token punctuation">[</span><span class="token string">'X'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>to_csv<span class="token punctuation">(</span>train_x_pad_path<span class="token punctuation">,</span> index<span class="token operator">=</span>None<span class="token punctuation">,</span> header<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
    train_df<span class="token punctuation">[</span><span class="token string">'Y'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>to_csv<span class="token punctuation">(</span>train_y_pad_path<span class="token punctuation">,</span> index<span class="token operator">=</span>None<span class="token punctuation">,</span> header<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
    test_df<span class="token punctuation">[</span><span class="token string">'X'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>to_csv<span class="token punctuation">(</span>test_x_pad_path<span class="token punctuation">,</span> index<span class="token operator">=</span>None<span class="token punctuation">,</span> header<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'填充后的三个文件保存完毕!'</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'\n'</span><span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true"># 11. 重新构建word_to_id字典和id_to_word字典, 根据第10步存储的3个文件数据来完成.</span>
    word_to_id <span class="token operator">=</span> <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;&amp;#125;</span>
    count <span class="token operator">=</span> <span class="token number">0</span>

    <span class="token comment" spellcheck="true"># 对训练集数据X进行处理</span>
    <span class="token keyword">with</span> open<span class="token punctuation">(</span>train_x_pad_path<span class="token punctuation">,</span> <span class="token string">'r'</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f1<span class="token punctuation">:</span>
        <span class="token keyword">for</span> line <span class="token keyword">in</span> f1<span class="token punctuation">.</span>readlines<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            line <span class="token operator">=</span> line<span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">' '</span><span class="token punctuation">)</span>
            <span class="token keyword">for</span> w <span class="token keyword">in</span> line<span class="token punctuation">:</span>
                <span class="token keyword">if</span> w <span class="token operator">not</span> <span class="token keyword">in</span> word_to_id<span class="token punctuation">:</span>
                    word_to_id<span class="token punctuation">[</span>w<span class="token punctuation">]</span> <span class="token operator">=</span> count
                    count <span class="token operator">+=</span> <span class="token number">1</span>

    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'训练集X字典构造完毕, word_to_id容量: '</span><span class="token punctuation">,</span> len<span class="token punctuation">(</span>word_to_id<span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true"># 对训练集数据Y进行处理</span>
    <span class="token keyword">with</span> open<span class="token punctuation">(</span>train_y_pad_path<span class="token punctuation">,</span> <span class="token string">'r'</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f2<span class="token punctuation">:</span>
        <span class="token keyword">for</span> line <span class="token keyword">in</span> f2<span class="token punctuation">.</span>readlines<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            line <span class="token operator">=</span> line<span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">' '</span><span class="token punctuation">)</span>
            <span class="token keyword">for</span> w <span class="token keyword">in</span> line<span class="token punctuation">:</span>
                <span class="token keyword">if</span> w <span class="token operator">not</span> <span class="token keyword">in</span> word_to_id<span class="token punctuation">:</span>
                    word_to_id<span class="token punctuation">[</span>w<span class="token punctuation">]</span> <span class="token operator">=</span> count
                    count <span class="token operator">+=</span> <span class="token number">1</span>

    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'训练集Y字典构造完毕, word_to_id容量: '</span><span class="token punctuation">,</span> len<span class="token punctuation">(</span>word_to_id<span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true"># 对测试集数据X进行处理</span>
    <span class="token keyword">with</span> open<span class="token punctuation">(</span>test_x_pad_path<span class="token punctuation">,</span> <span class="token string">'r'</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f3<span class="token punctuation">:</span>
        <span class="token keyword">for</span> line <span class="token keyword">in</span> f3<span class="token punctuation">.</span>readlines<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            line <span class="token operator">=</span> line<span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">' '</span><span class="token punctuation">)</span>
            <span class="token keyword">for</span> w <span class="token keyword">in</span> line<span class="token punctuation">:</span>
                <span class="token keyword">if</span> w <span class="token operator">not</span> <span class="token keyword">in</span> word_to_id<span class="token punctuation">:</span>
                    word_to_id<span class="token punctuation">[</span>w<span class="token punctuation">]</span> <span class="token operator">=</span> count
                    count <span class="token operator">+=</span> <span class="token number">1</span>

    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'测试集X字典构造完毕, word_to_id容量: '</span><span class="token punctuation">,</span> len<span class="token punctuation">(</span>word_to_id<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'单词总数量count= '</span><span class="token punctuation">,</span> count<span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true"># 构造逆向字典id_to_word</span>
    id_to_word <span class="token operator">=</span> <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;&amp;#125;</span>
    <span class="token keyword">for</span> w<span class="token punctuation">,</span> i <span class="token keyword">in</span> word_to_id<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        id_to_word<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">=</span> w

    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'逆向字典构造完毕, id_to_word容量: '</span><span class="token punctuation">,</span> len<span class="token punctuation">(</span>id_to_word<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'\n'</span><span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true"># 12. 更新vocab并保存</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'12. 更新vocab并保存'</span><span class="token punctuation">)</span>
    save_vocab_as_txt<span class="token punctuation">(</span>vocab_path<span class="token punctuation">,</span> word_to_id<span class="token punctuation">)</span>
    save_vocab_as_txt<span class="token punctuation">(</span>reverse_vocab_path<span class="token punctuation">,</span> id_to_word<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'字典映射器word_to_id, id_to_word保存完毕!'</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'\n'</span><span class="token punctuation">)</span>


    <span class="token comment" spellcheck="true"># 13. 数据集转换 将词转换成索引[&lt;START> 方向机 重 ...] -> [32800, 403, 986, 246, 231]</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'13. 数据集转换 将词转换成索引[&lt;START> 方向机 重 ...] -> [32800, 403, 986, 246, 231]'</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'训练集X执行transform_data中......'</span><span class="token punctuation">)</span>
    train_ids_x <span class="token operator">=</span> train_df<span class="token punctuation">[</span><span class="token string">'X'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>apply<span class="token punctuation">(</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span> transform_data<span class="token punctuation">(</span>x<span class="token punctuation">,</span> word_to_id<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'训练集Y执行transform_data中......'</span><span class="token punctuation">)</span>
    train_ids_y <span class="token operator">=</span> train_df<span class="token punctuation">[</span><span class="token string">'Y'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>apply<span class="token punctuation">(</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span> transform_data<span class="token punctuation">(</span>x<span class="token punctuation">,</span> word_to_id<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'测试集X执行transform_data中......'</span><span class="token punctuation">)</span>
    test_ids_x <span class="token operator">=</span> test_df<span class="token punctuation">[</span><span class="token string">'X'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>apply<span class="token punctuation">(</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span> transform_data<span class="token punctuation">(</span>x<span class="token punctuation">,</span> word_to_id<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'\n'</span><span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true"># 14. 数据转换成numpy数组(需等长)</span>
    <span class="token comment" spellcheck="true"># 将索引列表转换成矩阵 [32800, 403, 986, 246, 231] --> array([[32800, 403, 986, 246, 231], ...])</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'14. 数据转换成numpy数组(需等长)'</span><span class="token punctuation">)</span>
    train_X <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>train_ids_x<span class="token punctuation">.</span>tolist<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    train_Y <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>train_ids_y<span class="token punctuation">.</span>tolist<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    test_X <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>test_ids_x<span class="token punctuation">.</span>tolist<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'转换为numpy数组的形状如下: \ntrain_X的shape为: '</span><span class="token punctuation">,</span> train_X<span class="token punctuation">.</span>shape<span class="token punctuation">,</span> <span class="token string">'\ntrain_Y的shape为: '</span><span class="token punctuation">,</span> train_Y<span class="token punctuation">.</span>shape<span class="token punctuation">,</span> <span class="token string">'\ntest_X的shape为: '</span><span class="token punctuation">,</span> test_X<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'\n'</span><span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true"># 15. 保存数据</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'15. 保存数据......'</span><span class="token punctuation">)</span>
    np<span class="token punctuation">.</span>save<span class="token punctuation">(</span>train_x_path<span class="token punctuation">,</span> train_X<span class="token punctuation">)</span>
    np<span class="token punctuation">.</span>save<span class="token punctuation">(</span>train_y_path<span class="token punctuation">,</span> train_Y<span class="token punctuation">)</span>
    np<span class="token punctuation">.</span>save<span class="token punctuation">(</span>test_x_path<span class="token punctuation">,</span> test_X<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'\n'</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'数据集构造完毕, 存储于seq2seq/data/目录下.'</span><span class="token punctuation">)</span>
</code></pre>
<h4 id="前面数据处理合并的代码"><a href="#前面数据处理合并的代码" class="headerlink" title="前面数据处理合并的代码"></a>前面数据处理合并的代码</h4><pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">import</span> os
<span class="token keyword">import</span> sys
<span class="token keyword">import</span> re
<span class="token keyword">import</span> jieba
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd
<span class="token keyword">from</span> utils<span class="token punctuation">.</span>multi_proc_utils <span class="token keyword">import</span> parallelize
<span class="token keyword">from</span> utils<span class="token punctuation">.</span>word2vec_utils <span class="token keyword">import</span> save_vocab_as_txt
root_path <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>dirname<span class="token punctuation">(</span>os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>dirname<span class="token punctuation">(</span>os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>abspath<span class="token punctuation">(</span>__file__<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
sys<span class="token punctuation">.</span>path<span class="token punctuation">.</span>append<span class="token punctuation">(</span>root_path<span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># 配置模块</span>
<span class="token keyword">from</span> utils<span class="token punctuation">.</span>config <span class="token keyword">import</span> <span class="token operator">*</span>

<span class="token keyword">from</span> utils<span class="token punctuation">.</span>params_utils <span class="token keyword">import</span> get_params


<span class="token comment" spellcheck="true"># 载入词向量参数</span>
params <span class="token operator">=</span> get_params<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token comment" spellcheck="true"># jieba载入自定义切词表</span>
jieba<span class="token punctuation">.</span>load_userdict<span class="token punctuation">(</span>user_dict_path<span class="token punctuation">)</span>

<span class="token keyword">def</span> <span class="token function">get_max_len</span><span class="token punctuation">(</span>data<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment" spellcheck="true"># 获得合适的最大长度值(被build_dataset调用)</span>
    <span class="token comment" spellcheck="true"># data: 待统计的数据train_df['Question']</span>
    <span class="token comment" spellcheck="true"># 句子最大长度为空格数+1</span>
    max_lens <span class="token operator">=</span> data<span class="token punctuation">.</span>apply<span class="token punctuation">(</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span> x<span class="token punctuation">.</span>count<span class="token punctuation">(</span><span class="token string">' '</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span>
    <span class="token comment" spellcheck="true"># 平均值+2倍方差的方式</span>
    <span class="token keyword">return</span> int<span class="token punctuation">(</span>np<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>max_lens<span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token number">2</span> <span class="token operator">*</span> np<span class="token punctuation">.</span>std<span class="token punctuation">(</span>max_lens<span class="token punctuation">)</span><span class="token punctuation">)</span>


<span class="token comment" spellcheck="true">#完成文本语句单词到id的数字映射函数</span>
<span class="token keyword">def</span> <span class="token function">transform_data</span><span class="token punctuation">(</span>sentence<span class="token punctuation">,</span> word_to_id<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment" spellcheck="true"># 句子转换为index序列(被build_dataset调用)</span>
    <span class="token comment" spellcheck="true"># sentence: 'word1 word2 word3 ...'  ->  [index1, index2, index3 ...]</span>
    <span class="token comment" spellcheck="true"># word_to_id: 映射字典</span>

    <span class="token comment" spellcheck="true"># 字符串切分成词</span>
    words <span class="token operator">=</span> sentence<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">' '</span><span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true"># 按照word_to_id的id进行转换, 到未知词就填充unk的索引</span>
    ids <span class="token operator">=</span> <span class="token punctuation">[</span>word_to_id<span class="token punctuation">[</span>w<span class="token punctuation">]</span> <span class="token keyword">if</span> w <span class="token keyword">in</span> word_to_id <span class="token keyword">else</span> word_to_id<span class="token punctuation">[</span><span class="token string">'&lt;UNK>'</span><span class="token punctuation">]</span> <span class="token keyword">for</span> w <span class="token keyword">in</span> words<span class="token punctuation">]</span>

    <span class="token comment" spellcheck="true"># 返回映射后的文本id值列表</span>
    <span class="token keyword">return</span> ids

<span class="token comment" spellcheck="true"># 填充特殊标识符的函数</span>
<span class="token keyword">def</span> <span class="token function">pad_proc</span><span class="token punctuation">(</span>sentence<span class="token punctuation">,</span> max_len<span class="token punctuation">,</span> word_to_id<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment" spellcheck="true"># 根据max_len和vocab填充&lt;START> &lt;STOP> &lt;PAD> &lt;UNK></span>

    <span class="token comment" spellcheck="true"># 0. 按空格统计切分出词</span>
    words <span class="token operator">=</span> sentence<span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">' '</span><span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true"># 1. 截取规定长度的词数</span>
    words <span class="token operator">=</span> words<span class="token punctuation">[</span><span class="token punctuation">:</span>max_len<span class="token punctuation">]</span>

    <span class="token comment" spellcheck="true"># 2. 填充&lt;UNK></span>
    sentence <span class="token operator">=</span> <span class="token punctuation">[</span>w <span class="token keyword">if</span> w <span class="token keyword">in</span> word_to_id <span class="token keyword">else</span> <span class="token string">'&lt;UNK>'</span> <span class="token keyword">for</span> w <span class="token keyword">in</span> words<span class="token punctuation">]</span>

    <span class="token comment" spellcheck="true"># 3. 填充&lt;START> &lt;END></span>
    sentence <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'&lt;START>'</span><span class="token punctuation">]</span> <span class="token operator">+</span> sentence <span class="token operator">+</span> <span class="token punctuation">[</span><span class="token string">'&lt;STOP>'</span><span class="token punctuation">]</span>

    <span class="token comment" spellcheck="true"># 4. 判断长度，填充&lt;PAD></span>
    sentence <span class="token operator">=</span> sentence <span class="token operator">+</span> <span class="token punctuation">[</span><span class="token string">'&lt;PAD>'</span><span class="token punctuation">]</span> <span class="token operator">*</span> <span class="token punctuation">(</span>max_len <span class="token operator">-</span> len<span class="token punctuation">(</span>words<span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true"># 以空格连接列表, 返回结果字符串</span>
    <span class="token keyword">return</span> <span class="token string">' '</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>sentence<span class="token punctuation">)</span>


<span class="token comment" spellcheck="true">#加载停用词的函数</span>
<span class="token keyword">def</span> <span class="token function">load_stop_words</span><span class="token punctuation">(</span>stop_word_payh<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment" spellcheck="true">#stop_word_payh:停用词的存储路径</span>
    <span class="token comment" spellcheck="true">#打开停用词表</span>
    f <span class="token operator">=</span> open<span class="token punctuation">(</span>stop_word_payh<span class="token punctuation">,</span><span class="token string">"r"</span><span class="token punctuation">,</span>encoding<span class="token operator">=</span><span class="token string">"utf-8"</span><span class="token punctuation">)</span>
    stop_words <span class="token operator">=</span> f<span class="token punctuation">.</span>readlines<span class="token punctuation">(</span><span class="token punctuation">)</span>
    stop_words <span class="token operator">=</span> <span class="token punctuation">[</span>stop_word<span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">for</span>  stop_word <span class="token keyword">in</span> stop_words<span class="token punctuation">]</span>
    <span class="token keyword">return</span> stop_words


<span class="token comment" spellcheck="true"># 加载停用词, 这里面的stop_words_path是早已在config.py文件中配置好的</span>
stop_words <span class="token operator">=</span> load_stop_words<span class="token punctuation">(</span>stop_words_path<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'stop_words: '</span><span class="token punctuation">,</span> stop_words<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">20</span><span class="token punctuation">]</span><span class="token punctuation">)</span>


<span class="token comment" spellcheck="true">#清理文本的函数</span>
<span class="token keyword">def</span> <span class="token function">clean_sentence</span><span class="token punctuation">(</span>sentence<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment" spellcheck="true"># 特殊符号去除(被sentence_proc调用)</span>
    <span class="token comment" spellcheck="true"># sentence: 待处理的字符串</span>
    <span class="token keyword">if</span> isinstance<span class="token punctuation">(</span>sentence<span class="token punctuation">,</span> str<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment" spellcheck="true"># 删除1. 2. 3. 这些标题</span>
        r <span class="token operator">=</span> re<span class="token punctuation">.</span>compile<span class="token punctuation">(</span><span class="token string">"\D(\d\.)\D"</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">#正则表达式</span>
        sentence <span class="token operator">=</span> r<span class="token punctuation">.</span>sub<span class="token punctuation">(</span><span class="token string">""</span><span class="token punctuation">,</span> sentence<span class="token punctuation">)</span>

        <span class="token comment" spellcheck="true"># 删除带括号的 进口 海外</span>
        r <span class="token operator">=</span> re<span class="token punctuation">.</span>compile<span class="token punctuation">(</span>r<span class="token string">"[(（]进口[)）]|\(海外\)"</span><span class="token punctuation">)</span>
        sentence <span class="token operator">=</span> r<span class="token punctuation">.</span>sub<span class="token punctuation">(</span><span class="token string">""</span><span class="token punctuation">,</span> sentence<span class="token punctuation">)</span>
        <span class="token comment" spellcheck="true"># 删除除了汉字数字字母和，！？。.- 以外的字符</span>
        r <span class="token operator">=</span> re<span class="token punctuation">.</span>compile<span class="token punctuation">(</span><span class="token string">"[^，！？。\.\-\u4e00-\u9fa5_a-zA-Z0-9]"</span><span class="token punctuation">)</span>
        <span class="token comment" spellcheck="true"># 用中文输入法下的，！？来替换英文输入法下的,!?</span>
        sentence <span class="token operator">=</span> sentence<span class="token punctuation">.</span>replace<span class="token punctuation">(</span><span class="token string">","</span><span class="token punctuation">,</span> <span class="token string">"，"</span><span class="token punctuation">)</span>
        sentence <span class="token operator">=</span> sentence<span class="token punctuation">.</span>replace<span class="token punctuation">(</span><span class="token string">"!"</span><span class="token punctuation">,</span> <span class="token string">"！"</span><span class="token punctuation">)</span>
        sentence <span class="token operator">=</span> sentence<span class="token punctuation">.</span>replace<span class="token punctuation">(</span><span class="token string">"?"</span><span class="token punctuation">,</span> <span class="token string">"？"</span><span class="token punctuation">)</span>
        sentence <span class="token operator">=</span> r<span class="token punctuation">.</span>sub<span class="token punctuation">(</span><span class="token string">""</span><span class="token punctuation">,</span> sentence<span class="token punctuation">)</span>

        <span class="token comment" spellcheck="true"># 删除 车主说 技师说 语音 图片 你好 您好</span>
        r <span class="token operator">=</span> re<span class="token punctuation">.</span>compile<span class="token punctuation">(</span>r<span class="token string">"车主说|技师说|语音|图片|你好|您好"</span><span class="token punctuation">)</span>
        sentence <span class="token operator">=</span> r<span class="token punctuation">.</span>sub<span class="token punctuation">(</span><span class="token string">""</span><span class="token punctuation">,</span> sentence<span class="token punctuation">)</span>
        <span class="token keyword">return</span> sentence
    <span class="token keyword">else</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> <span class="token string">''</span>
sentence <span class="token operator">=</span> <span class="token string">'技师说：你好！以前也出现过该故障吗？|技师说：缸压多少有没有测量一下?|车主说：没有过|车主说：没测缸压|技师说：测量一下缸压 看一四缸缸压是否偏低|车主说：用电脑测，只是14缸缺火|车主说：[语音]|车主说：[语音]|技师说：点火线圈  火花塞 喷油嘴不用干活  直接和二三缸对倒一下  跑一段在测量一下故障码进行排除|车主说：[语音]|车主>说：[语音]|车主说：[语音]|车主说：[语音]|车主说：师傅还在吗|技师说：调一下喷油嘴  测一下缸压  都正常则为发动机电脑板问题|车主说：[语音]|车主说：[语音]|车主说：[语音]|技师说：这个影响不大的|技师说：缸压八个以上正常|车主说：[语音]|技师说：所以说让你测量缸压  只要缸压正常则没有问题|车主说：[语音]|车主说：[语音]|技师说：可以点击头像关注我  有什么问题随时询问  一定真诚用心为你解决|车主说：师傅，谢谢了|技师说：不用客气'</span>


<span class="token comment" spellcheck="true">#过滤停用词的函数</span>
<span class="token keyword">def</span> <span class="token function">filter_stopwords</span><span class="token punctuation">(</span>seg_list<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment" spellcheck="true"># 过滤一句切好词的话中的停用词(被sentence_proc调用)</span>
    <span class="token comment" spellcheck="true"># seg_list: 切好词的列表 [word1 ,word2 .......]</span>
    <span class="token comment" spellcheck="true"># 首先去掉多余空字符</span>
    words <span class="token operator">=</span> <span class="token punctuation">[</span>word <span class="token keyword">for</span> word <span class="token keyword">in</span> seg_list <span class="token keyword">if</span> word<span class="token punctuation">]</span>
    <span class="token comment" spellcheck="true"># 去掉停用词</span>
    <span class="token keyword">return</span> <span class="token punctuation">[</span>word <span class="token keyword">for</span> word <span class="token keyword">in</span> words <span class="token keyword">if</span> word <span class="token operator">not</span> <span class="token keyword">in</span> stop_words<span class="token punctuation">]</span>


<span class="token comment" spellcheck="true"># 第一步: 先将原始文本执行清洗操作</span>
res <span class="token operator">=</span> clean_sentence<span class="token punctuation">(</span>sentence<span class="token punctuation">)</span>
<span class="token comment" spellcheck="true"># print('res=', res)</span>

<span class="token comment" spellcheck="true"># 第二步: 对清洗结果进行分词, 默认是精确模式, 当设置cut_all=True时, 采用全模式</span>
words <span class="token operator">=</span> jieba<span class="token punctuation">.</span>cut<span class="token punctuation">(</span>res<span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># 第三步: 将分词的结果传入过滤停用词函数中, 并打印结果</span>
result <span class="token operator">=</span> filter_stopwords<span class="token punctuation">(</span>words<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>result<span class="token punctuation">)</span>



<span class="token comment" spellcheck="true"># 句子的处理</span>
<span class="token keyword">def</span> <span class="token function">sentence_proc</span><span class="token punctuation">(</span>sentence<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment" spellcheck="true"># 预处理模块(处理一条句子, 被sentences_proc调用)</span>
    <span class="token comment" spellcheck="true"># sentence: 待处理字符串</span>

    <span class="token comment" spellcheck="true"># 第一步: 执行清洗原始文本的操作</span>
    sentence <span class="token operator">=</span> clean_sentence<span class="token punctuation">(</span>sentence<span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true"># 第二步: 执行分词操作, 默认精确模式, 全模式cut参数cut_all=True</span>
    words <span class="token operator">=</span> jieba<span class="token punctuation">.</span>cut<span class="token punctuation">(</span>sentence<span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true"># 第三步: 将分词结果输入过滤停用词函数中</span>
    words <span class="token operator">=</span> filter_stopwords<span class="token punctuation">(</span>words<span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true"># 返回字符串结果, 按空格分隔, 将过滤停用词后的列表拼接</span>
    <span class="token keyword">return</span> <span class="token string">' '</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>words<span class="token punctuation">)</span>

res <span class="token operator">=</span> sentence_proc<span class="token punctuation">(</span>sentence<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'res='</span><span class="token punctuation">,</span> res<span class="token punctuation">)</span>


    <span class="token comment" spellcheck="true"># 语句处理的函数(2)</span>

<span class="token keyword">def</span> <span class="token function">sentences_proc</span><span class="token punctuation">(</span>df<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment" spellcheck="true"># 预处理模块(处理一个句子列表, 对每个句子调用sentence_proc操作)</span>
    <span class="token comment" spellcheck="true"># df: 数据集</span>

    <span class="token comment" spellcheck="true"># 批量预处理训练集和测试集</span>
    <span class="token keyword">for</span> col_name <span class="token keyword">in</span> <span class="token punctuation">[</span><span class="token string">'Brand'</span><span class="token punctuation">,</span> <span class="token string">'Model'</span><span class="token punctuation">,</span> <span class="token string">'Question'</span><span class="token punctuation">,</span> <span class="token string">'Dialogue'</span><span class="token punctuation">]</span><span class="token punctuation">:</span>
        df<span class="token punctuation">[</span>col_name<span class="token punctuation">]</span> <span class="token operator">=</span> df<span class="token punctuation">[</span>col_name<span class="token punctuation">]</span><span class="token punctuation">.</span>apply<span class="token punctuation">(</span>sentence_proc<span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true"># 训练集Report预处理</span>
    <span class="token keyword">if</span> <span class="token string">'Report'</span> <span class="token keyword">in</span> df<span class="token punctuation">.</span>columns<span class="token punctuation">:</span>
        df<span class="token punctuation">[</span><span class="token string">'Report'</span><span class="token punctuation">]</span> <span class="token operator">=</span> df<span class="token punctuation">[</span><span class="token string">'Report'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>apply<span class="token punctuation">(</span>sentence_proc<span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true"># 以Pandas的DataFrame格式返回</span>
    <span class="token keyword">return</span> df





<span class="token comment" spellcheck="true"># 加载构建好的训练集和测试集的函数</span>
<span class="token comment" spellcheck="true"># 加载处理好的训练样本和训练标签.npy文件(执行完build_dataset后才能使用)</span>
<span class="token keyword">def</span> <span class="token function">load_train_dataset</span><span class="token punctuation">(</span>max_enc_len<span class="token operator">=</span><span class="token number">300</span><span class="token punctuation">,</span> max_dec_len<span class="token operator">=</span><span class="token number">50</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment" spellcheck="true"># max_enc_len: 最长样本长度, 后面的截断</span>
    <span class="token comment" spellcheck="true"># max_dec_len: 最长标签长度, 后面的截断</span>
    train_X <span class="token operator">=</span> np<span class="token punctuation">.</span>load<span class="token punctuation">(</span>train_x_path<span class="token punctuation">)</span>
    train_Y <span class="token operator">=</span> np<span class="token punctuation">.</span>load<span class="token punctuation">(</span>train_y_path<span class="token punctuation">)</span>

    train_X <span class="token operator">=</span> train_X<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span>max_enc_len<span class="token punctuation">]</span>
    train_Y <span class="token operator">=</span> train_Y<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span>max_dec_len<span class="token punctuation">]</span>

    <span class="token keyword">return</span> train_X<span class="token punctuation">,</span> train_Y

<span class="token comment" spellcheck="true"># 加载处理好的测试样本.npy文件(执行完build_dataset后才能使用)</span>
<span class="token keyword">def</span> <span class="token function">load_test_dataset</span><span class="token punctuation">(</span>max_enc_len<span class="token operator">=</span><span class="token number">300</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment" spellcheck="true"># max_enc_len: 最长样本长度, 后面的截断</span>
    test_X <span class="token operator">=</span> np<span class="token punctuation">.</span>load<span class="token punctuation">(</span>test_x_path<span class="token punctuation">)</span>
    test_X <span class="token operator">=</span> test_X<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span>max_enc_len<span class="token punctuation">]</span>
    <span class="token keyword">return</span> test_X



    <span class="token comment" spellcheck="true"># 9: 完成本步骤总体逻辑的函数build_dataset()函数</span>

<span class="token comment" spellcheck="true"># 数据预处理总函数, 用于数据加载 + 预处理 (注意: 只需执行一次)</span>
<span class="token keyword">def</span> <span class="token function">build_dataset</span><span class="token punctuation">(</span>train_raw_data_path<span class="token punctuation">,</span> test_raw_data_path<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment" spellcheck="true"># 1. 加载原始数据</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'1. 加载原始数据'</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>train_raw_data_path<span class="token punctuation">)</span>
    <span class="token comment" spellcheck="true"># 必须设定数据格式为utf-8</span>
    train_df <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span>train_raw_data_path<span class="token punctuation">,</span> engine<span class="token operator">=</span><span class="token string">'python'</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span>
    test_df <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span>test_raw_data_path<span class="token punctuation">,</span> engine<span class="token operator">=</span><span class="token string">'python'</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true"># 82943, 20000</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'原始训练集行数 &amp;#123;&amp;#125;, 测试集行数 &amp;#123;&amp;#125;'</span><span class="token punctuation">.</span>format<span class="token punctuation">(</span>len<span class="token punctuation">(</span>train_df<span class="token punctuation">)</span><span class="token punctuation">,</span> len<span class="token punctuation">(</span>test_df<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'\n'</span><span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true"># 2. 空值去除(对于一行数据, 任意列只要有空值就去掉该行)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'2. 空值去除（对于一行数据，任意列只要有空值就去掉该行）'</span><span class="token punctuation">)</span>
    train_df<span class="token punctuation">.</span>dropna<span class="token punctuation">(</span>subset<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'Question'</span><span class="token punctuation">,</span> <span class="token string">'Dialogue'</span><span class="token punctuation">,</span> <span class="token string">'Report'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> how<span class="token operator">=</span><span class="token string">'any'</span><span class="token punctuation">,</span> inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
    test_df<span class="token punctuation">.</span>dropna<span class="token punctuation">(</span>subset<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'Question'</span><span class="token punctuation">,</span> <span class="token string">'Dialogue'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> how<span class="token operator">=</span><span class="token string">'any'</span><span class="token punctuation">,</span> inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'空值去除后训练集行数 &amp;#123;&amp;#125;, 测试集行数 &amp;#123;&amp;#125;'</span><span class="token punctuation">.</span>format<span class="token punctuation">(</span>len<span class="token punctuation">(</span>train_df<span class="token punctuation">)</span><span class="token punctuation">,</span> len<span class="token punctuation">(</span>test_df<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'\n'</span><span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true"># 3. 多线程, 批量数据预处理(对每个句子执行sentence_proc, 清除无用词, 分词, 过滤停用词, 再用空格拼接为一个字符串)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'3. 多线程, 批量数据预处理(对每个句子执行sentence_proc, 清除无用词, 分词, 过滤停用词, 再用空格拼接为一个字符串)'</span><span class="token punctuation">)</span>
    train_df <span class="token operator">=</span> parallelize<span class="token punctuation">(</span>train_df<span class="token punctuation">,</span> sentences_proc<span class="token punctuation">)</span>
    test_df <span class="token operator">=</span> parallelize<span class="token punctuation">(</span>test_df<span class="token punctuation">,</span> sentences_proc<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'\n'</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'sentences_proc has done!'</span><span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true"># 4. 合并训练测试集, 用于构造映射字典word_to_id</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'4. 合并训练测试集, 用于构造映射字典word_to_id'</span><span class="token punctuation">)</span>
    <span class="token comment" spellcheck="true"># 新建一列, 按行堆积</span>
    train_df<span class="token punctuation">[</span><span class="token string">'merged'</span><span class="token punctuation">]</span> <span class="token operator">=</span> train_df<span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token string">'Question'</span><span class="token punctuation">,</span> <span class="token string">'Dialogue'</span><span class="token punctuation">,</span> <span class="token string">'Report'</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">.</span>apply<span class="token punctuation">(</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span> <span class="token string">' '</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
    <span class="token comment" spellcheck="true"># 新建一列, 按行堆积</span>
    test_df<span class="token punctuation">[</span><span class="token string">'merged'</span><span class="token punctuation">]</span> <span class="token operator">=</span> test_df<span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token string">'Question'</span><span class="token punctuation">,</span> <span class="token string">'Dialogue'</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">.</span>apply<span class="token punctuation">(</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span> <span class="token string">' '</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
    <span class="token comment" spellcheck="true"># merged列是训练集三列和测试集两列按行连接在一起再按列堆积, 用于构造映射字典</span>
    <span class="token comment" spellcheck="true"># 按列堆积, 用于构造映射字典</span>
    merged_df <span class="token operator">=</span> pd<span class="token punctuation">.</span>concat<span class="token punctuation">(</span><span class="token punctuation">[</span>train_df<span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token string">'merged'</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> test_df<span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token string">'merged'</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'训练集行数&amp;#123;&amp;#125;, 测试集行数&amp;#123;&amp;#125;, 合并数据集行数&amp;#123;&amp;#125;'</span><span class="token punctuation">.</span>format<span class="token punctuation">(</span>len<span class="token punctuation">(</span>train_df<span class="token punctuation">)</span><span class="token punctuation">,</span> len<span class="token punctuation">(</span>test_df<span class="token punctuation">)</span><span class="token punctuation">,</span> len<span class="token punctuation">(</span>merged_df<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'\n'</span><span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true"># 5. 保存分割处理好的train_seg_data.csv, test_set_data.csv</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'5. 保存分割处理好的train_seg_data.csv, test_set_data.csv'</span><span class="token punctuation">)</span>
    <span class="token comment" spellcheck="true"># 把建立的列merged去掉, 该列对于神经网络无用</span>
    train_df <span class="token operator">=</span> train_df<span class="token punctuation">.</span>drop<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">'merged'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
    test_df <span class="token operator">=</span> test_df<span class="token punctuation">.</span>drop<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">'merged'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
    <span class="token comment" spellcheck="true"># 将处理后的数据存入持久化文件</span>
    train_df<span class="token punctuation">.</span>to_csv<span class="token punctuation">(</span>train_seg_path<span class="token punctuation">,</span> index<span class="token operator">=</span>None<span class="token punctuation">,</span> header<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
    test_df<span class="token punctuation">.</span>to_csv<span class="token punctuation">(</span>test_seg_path<span class="token punctuation">,</span> index<span class="token operator">=</span>None<span class="token punctuation">,</span> header<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'The csv_file has saved!'</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'\n'</span><span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true"># 6. 保存合并数据merged_seg_data.csv, 用于构造映射字典word_to_id</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'6. 保存合并数据merged_seg_data.csv, 用于构造映射字典word_to_id'</span><span class="token punctuation">)</span>
    merged_df<span class="token punctuation">.</span>to_csv<span class="token punctuation">(</span>merged_seg_path<span class="token punctuation">,</span> index<span class="token operator">=</span>None<span class="token punctuation">,</span> header<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'The word_to_vector file has saved!'</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'\n'</span><span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true"># 7. 构建word_to_id字典和id_to_word字典, 根据第6步存储的合并文件数据来完成.</span>
    word_to_id <span class="token operator">=</span> <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;&amp;#125;</span>
    count <span class="token operator">=</span> <span class="token number">0</span>

    <span class="token comment" spellcheck="true"># 对训练集数据X进行处理</span>
    <span class="token keyword">with</span> open<span class="token punctuation">(</span>merged_seg_path<span class="token punctuation">,</span> <span class="token string">'r'</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f1<span class="token punctuation">:</span>
        <span class="token keyword">for</span> line <span class="token keyword">in</span> f1<span class="token punctuation">.</span>readlines<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            line <span class="token operator">=</span> line<span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">' '</span><span class="token punctuation">)</span>
            <span class="token keyword">for</span> w <span class="token keyword">in</span> line<span class="token punctuation">:</span>
                <span class="token keyword">if</span> w <span class="token operator">not</span> <span class="token keyword">in</span> word_to_id<span class="token punctuation">:</span>
                    word_to_id<span class="token punctuation">[</span>w<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">1</span>
                    count <span class="token operator">+=</span> <span class="token number">1</span>
                <span class="token keyword">else</span><span class="token punctuation">:</span>
                    word_to_id<span class="token punctuation">[</span>w<span class="token punctuation">]</span> <span class="token operator">+=</span> <span class="token number">1</span>

    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'总体单词总数count='</span><span class="token punctuation">,</span> count<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'\n'</span><span class="token punctuation">)</span>

    res_dict <span class="token operator">=</span> <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;&amp;#125;</span>
    number <span class="token operator">=</span> <span class="token number">0</span>
    <span class="token keyword">for</span> w<span class="token punctuation">,</span> i <span class="token keyword">in</span> word_to_id<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">if</span> i <span class="token operator">>=</span> <span class="token number">5</span><span class="token punctuation">:</span>
            res_dict<span class="token punctuation">[</span>w<span class="token punctuation">]</span> <span class="token operator">=</span> i
            number <span class="token operator">+=</span> <span class="token number">1</span>

    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'进入到字典中的单词总数number='</span><span class="token punctuation">,</span> number<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'合并数据集的字典构造完毕, word_to_id容量: '</span><span class="token punctuation">,</span> len<span class="token punctuation">(</span>res_dict<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'\n'</span><span class="token punctuation">)</span>

    word_to_id <span class="token operator">=</span> <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;&amp;#125;</span>
    count <span class="token operator">=</span> <span class="token number">0</span>
    <span class="token keyword">for</span> w<span class="token punctuation">,</span> i <span class="token keyword">in</span> res_dict<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">if</span> w <span class="token operator">not</span> <span class="token keyword">in</span> word_to_id<span class="token punctuation">:</span>
            word_to_id<span class="token punctuation">[</span>w<span class="token punctuation">]</span> <span class="token operator">=</span> count
            count <span class="token operator">+=</span> <span class="token number">1</span>

    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'最终构造完毕字典, word_to_id容量='</span><span class="token punctuation">,</span> len<span class="token punctuation">(</span>word_to_id<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'count='</span><span class="token punctuation">,</span> count<span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true"># 8. 将Question和Dialogue用空格连接作为模型输入形成train_df['X']</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"8. 将Question和Dialogue用空格连接作为模型输入形成train_df['X']"</span><span class="token punctuation">)</span>
    train_df<span class="token punctuation">[</span><span class="token string">'X'</span><span class="token punctuation">]</span> <span class="token operator">=</span> train_df<span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token string">'Question'</span><span class="token punctuation">,</span> <span class="token string">'Dialogue'</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">.</span>apply<span class="token punctuation">(</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span> <span class="token string">' '</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
    test_df<span class="token punctuation">[</span><span class="token string">'X'</span><span class="token punctuation">]</span> <span class="token operator">=</span> test_df<span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token string">'Question'</span><span class="token punctuation">,</span> <span class="token string">'Dialogue'</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">.</span>apply<span class="token punctuation">(</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span> <span class="token string">' '</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'\n'</span><span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true"># 9. 填充&lt;START>, &lt;STOP>, &lt;UNK>和&lt;PAD>, 使数据变为等长</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'9. 填充&lt;START>, &lt;STOP>, &lt;UNK> 和 &lt;PAD>, 使数据变为等长'</span><span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true"># 获取适当的最大长度</span>
    train_x_max_len <span class="token operator">=</span> get_max_len<span class="token punctuation">(</span>train_df<span class="token punctuation">[</span><span class="token string">'X'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    test_x_max_len <span class="token operator">=</span> get_max_len<span class="token punctuation">(</span>test_df<span class="token punctuation">[</span><span class="token string">'X'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    train_y_max_len <span class="token operator">=</span> get_max_len<span class="token punctuation">(</span>train_df<span class="token punctuation">[</span><span class="token string">'Report'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'填充前训练集样本的最大长度为: '</span><span class="token punctuation">,</span> train_x_max_len<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'填充前测试集样本的最大长度为: '</span><span class="token punctuation">,</span> test_x_max_len<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'填充前训练集标签的最大长度为: '</span><span class="token punctuation">,</span> train_y_max_len<span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true"># 选训练集和测试集中较大的值</span>
    x_max_len <span class="token operator">=</span> max<span class="token punctuation">(</span>train_x_max_len<span class="token punctuation">,</span> test_x_max_len<span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true"># 训练集X填充处理</span>
    <span class="token comment" spellcheck="true"># train_df['X'] = train_df['X'].apply(lambda x: pad_proc(x, x_max_len, vocab))</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'训练集X填充PAD, START, STOP, UNK处理中...'</span><span class="token punctuation">)</span>
    train_df<span class="token punctuation">[</span><span class="token string">'X'</span><span class="token punctuation">]</span> <span class="token operator">=</span> train_df<span class="token punctuation">[</span><span class="token string">'X'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>apply<span class="token punctuation">(</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span> pad_proc<span class="token punctuation">(</span>x<span class="token punctuation">,</span> x_max_len<span class="token punctuation">,</span> word_to_id<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token comment" spellcheck="true"># 测试集X填充处理</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'测试集X填充PAD, START, STOP, UNK处理中...'</span><span class="token punctuation">)</span>
    test_df<span class="token punctuation">[</span><span class="token string">'X'</span><span class="token punctuation">]</span> <span class="token operator">=</span> test_df<span class="token punctuation">[</span><span class="token string">'X'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>apply<span class="token punctuation">(</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span> pad_proc<span class="token punctuation">(</span>x<span class="token punctuation">,</span> x_max_len<span class="token punctuation">,</span> word_to_id<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token comment" spellcheck="true"># 训练集Y填充处理</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'训练集Y填充PAD, START, STOP, UNK处理中...'</span><span class="token punctuation">)</span>
    train_df<span class="token punctuation">[</span><span class="token string">'Y'</span><span class="token punctuation">]</span> <span class="token operator">=</span> train_df<span class="token punctuation">[</span><span class="token string">'Report'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>apply<span class="token punctuation">(</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span> pad_proc<span class="token punctuation">(</span>x<span class="token punctuation">,</span> train_y_max_len<span class="token punctuation">,</span> word_to_id<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'\n'</span><span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true"># 10. 保存填充&lt;START>, &lt;STOP>, &lt;UNK>和&lt;PAD>后的X和Y</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'10. 保存填充&lt;START>, &lt;STOP>, &lt;UNK> 和 &lt;PAD>后的X和Y'</span><span class="token punctuation">)</span>
    train_df<span class="token punctuation">[</span><span class="token string">'X'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>to_csv<span class="token punctuation">(</span>train_x_pad_path<span class="token punctuation">,</span> index<span class="token operator">=</span>None<span class="token punctuation">,</span> header<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
    train_df<span class="token punctuation">[</span><span class="token string">'Y'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>to_csv<span class="token punctuation">(</span>train_y_pad_path<span class="token punctuation">,</span> index<span class="token operator">=</span>None<span class="token punctuation">,</span> header<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
    test_df<span class="token punctuation">[</span><span class="token string">'X'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>to_csv<span class="token punctuation">(</span>test_x_pad_path<span class="token punctuation">,</span> index<span class="token operator">=</span>None<span class="token punctuation">,</span> header<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'填充后的三个文件保存完毕!'</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'\n'</span><span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true"># 11. 重新构建word_to_id字典和id_to_word字典, 根据第10步存储的3个文件数据来完成.</span>
    word_to_id <span class="token operator">=</span> <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;&amp;#125;</span>
    count <span class="token operator">=</span> <span class="token number">0</span>

    <span class="token comment" spellcheck="true"># 对训练集数据X进行处理</span>
    <span class="token keyword">with</span> open<span class="token punctuation">(</span>train_x_pad_path<span class="token punctuation">,</span> <span class="token string">'r'</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f1<span class="token punctuation">:</span>
        <span class="token keyword">for</span> line <span class="token keyword">in</span> f1<span class="token punctuation">.</span>readlines<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            line <span class="token operator">=</span> line<span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">' '</span><span class="token punctuation">)</span>
            <span class="token keyword">for</span> w <span class="token keyword">in</span> line<span class="token punctuation">:</span>
                <span class="token keyword">if</span> w <span class="token operator">not</span> <span class="token keyword">in</span> word_to_id<span class="token punctuation">:</span>
                    word_to_id<span class="token punctuation">[</span>w<span class="token punctuation">]</span> <span class="token operator">=</span> count
                    count <span class="token operator">+=</span> <span class="token number">1</span>

    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'训练集X字典构造完毕, word_to_id容量: '</span><span class="token punctuation">,</span> len<span class="token punctuation">(</span>word_to_id<span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true"># 对训练集数据Y进行处理</span>
    <span class="token keyword">with</span> open<span class="token punctuation">(</span>train_y_pad_path<span class="token punctuation">,</span> <span class="token string">'r'</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f2<span class="token punctuation">:</span>
        <span class="token keyword">for</span> line <span class="token keyword">in</span> f2<span class="token punctuation">.</span>readlines<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            line <span class="token operator">=</span> line<span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">' '</span><span class="token punctuation">)</span>
            <span class="token keyword">for</span> w <span class="token keyword">in</span> line<span class="token punctuation">:</span>
                <span class="token keyword">if</span> w <span class="token operator">not</span> <span class="token keyword">in</span> word_to_id<span class="token punctuation">:</span>
                    word_to_id<span class="token punctuation">[</span>w<span class="token punctuation">]</span> <span class="token operator">=</span> count
                    count <span class="token operator">+=</span> <span class="token number">1</span>

    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'训练集Y字典构造完毕, word_to_id容量: '</span><span class="token punctuation">,</span> len<span class="token punctuation">(</span>word_to_id<span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true"># 对测试集数据X进行处理</span>
    <span class="token keyword">with</span> open<span class="token punctuation">(</span>test_x_pad_path<span class="token punctuation">,</span> <span class="token string">'r'</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f3<span class="token punctuation">:</span>
        <span class="token keyword">for</span> line <span class="token keyword">in</span> f3<span class="token punctuation">.</span>readlines<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            line <span class="token operator">=</span> line<span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">' '</span><span class="token punctuation">)</span>
            <span class="token keyword">for</span> w <span class="token keyword">in</span> line<span class="token punctuation">:</span>
                <span class="token keyword">if</span> w <span class="token operator">not</span> <span class="token keyword">in</span> word_to_id<span class="token punctuation">:</span>
                    word_to_id<span class="token punctuation">[</span>w<span class="token punctuation">]</span> <span class="token operator">=</span> count
                    count <span class="token operator">+=</span> <span class="token number">1</span>

    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'测试集X字典构造完毕, word_to_id容量: '</span><span class="token punctuation">,</span> len<span class="token punctuation">(</span>word_to_id<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'单词总数量count= '</span><span class="token punctuation">,</span> count<span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true"># 构造逆向字典id_to_word</span>
    id_to_word <span class="token operator">=</span> <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;&amp;#125;</span>
    <span class="token keyword">for</span> w<span class="token punctuation">,</span> i <span class="token keyword">in</span> word_to_id<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        id_to_word<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">=</span> w

    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'逆向字典构造完毕, id_to_word容量: '</span><span class="token punctuation">,</span> len<span class="token punctuation">(</span>id_to_word<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'\n'</span><span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true"># 12. 更新vocab并保存</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'12. 更新vocab并保存'</span><span class="token punctuation">)</span>
    save_vocab_as_txt<span class="token punctuation">(</span>vocab_path<span class="token punctuation">,</span> word_to_id<span class="token punctuation">)</span>
    save_vocab_as_txt<span class="token punctuation">(</span>reverse_vocab_path<span class="token punctuation">,</span> id_to_word<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'字典映射器word_to_id, id_to_word保存完毕!'</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'\n'</span><span class="token punctuation">)</span>


    <span class="token comment" spellcheck="true"># 13. 数据集转换 将词转换成索引[&lt;START> 方向机 重 ...] -> [32800, 403, 986, 246, 231]</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'13. 数据集转换 将词转换成索引[&lt;START> 方向机 重 ...] -> [32800, 403, 986, 246, 231]'</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'训练集X执行transform_data中......'</span><span class="token punctuation">)</span>
    train_ids_x <span class="token operator">=</span> train_df<span class="token punctuation">[</span><span class="token string">'X'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>apply<span class="token punctuation">(</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span> transform_data<span class="token punctuation">(</span>x<span class="token punctuation">,</span> word_to_id<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'训练集Y执行transform_data中......'</span><span class="token punctuation">)</span>
    train_ids_y <span class="token operator">=</span> train_df<span class="token punctuation">[</span><span class="token string">'Y'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>apply<span class="token punctuation">(</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span> transform_data<span class="token punctuation">(</span>x<span class="token punctuation">,</span> word_to_id<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'测试集X执行transform_data中......'</span><span class="token punctuation">)</span>
    test_ids_x <span class="token operator">=</span> test_df<span class="token punctuation">[</span><span class="token string">'X'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>apply<span class="token punctuation">(</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span> transform_data<span class="token punctuation">(</span>x<span class="token punctuation">,</span> word_to_id<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'\n'</span><span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true"># 14. 数据转换成numpy数组(需等长)</span>
    <span class="token comment" spellcheck="true"># 将索引列表转换成矩阵 [32800, 403, 986, 246, 231] --> array([[32800, 403, 986, 246, 231], ...])</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'14. 数据转换成numpy数组(需等长)'</span><span class="token punctuation">)</span>
    train_X <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>train_ids_x<span class="token punctuation">.</span>tolist<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    train_Y <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>train_ids_y<span class="token punctuation">.</span>tolist<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    test_X <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>test_ids_x<span class="token punctuation">.</span>tolist<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'转换为numpy数组的形状如下: \ntrain_X的shape为: '</span><span class="token punctuation">,</span> train_X<span class="token punctuation">.</span>shape<span class="token punctuation">,</span> <span class="token string">'\ntrain_Y的shape为: '</span><span class="token punctuation">,</span> train_Y<span class="token punctuation">.</span>shape<span class="token punctuation">,</span> <span class="token string">'\ntest_X的shape为: '</span><span class="token punctuation">,</span> test_X<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'\n'</span><span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true"># 15. 保存数据</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'15. 保存数据......'</span><span class="token punctuation">)</span>
    np<span class="token punctuation">.</span>save<span class="token punctuation">(</span>train_x_path<span class="token punctuation">,</span> train_X<span class="token punctuation">)</span>
    np<span class="token punctuation">.</span>save<span class="token punctuation">(</span>train_y_path<span class="token punctuation">,</span> train_Y<span class="token punctuation">)</span>
    np<span class="token punctuation">.</span>save<span class="token punctuation">(</span>test_x_path<span class="token punctuation">,</span> test_X<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'\n'</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'数据集构造完毕, 存储于seq2seq/data/目录下.'</span><span class="token punctuation">)</span>

<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">'__main__'</span><span class="token punctuation">:</span>
    build_dataset<span class="token punctuation">(</span>train_raw_data_path<span class="token punctuation">,</span> test_raw_data_path<span class="token punctuation">)</span>
</code></pre>
<h5 id="打印输出"><a href="#打印输出" class="headerlink" title="打印输出"></a>打印输出</h5><pre class=" language-python"><code class="language-python">Building prefix dict <span class="token keyword">from</span> the default dictionary <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
Loading model <span class="token keyword">from</span> cache <span class="token operator">/</span>tmp<span class="token operator">/</span>jieba<span class="token punctuation">.</span>cache
Loading model cost <span class="token number">0.753</span> seconds<span class="token punctuation">.</span>
Prefix dict has been built successfully<span class="token punctuation">.</span>
<span class="token number">1</span><span class="token punctuation">.</span> 加载原始数据
<span class="token operator">/</span>home<span class="token operator">/</span>ec2<span class="token operator">-</span>user<span class="token operator">/</span>text_summary<span class="token operator">/</span>seq2seq<span class="token operator">/</span>data<span class="token operator">/</span>train<span class="token punctuation">.</span>csv
原始训练集行数 <span class="token number">82943</span><span class="token punctuation">,</span> 测试集行数 <span class="token number">20000</span>


<span class="token number">2</span><span class="token punctuation">.</span> 空值去除（对于一行数据，任意列只要有空值就去掉该行）
空值去除后训练集行数 <span class="token number">82871</span><span class="token punctuation">,</span> 测试集行数 <span class="token number">20000</span>


<span class="token number">3</span><span class="token punctuation">.</span> 多线程<span class="token punctuation">,</span> 批量数据预处理<span class="token punctuation">(</span>对每个句子执行sentence_proc，清除无用词，切词，过滤停用词，再用空格拼接为一个字符串<span class="token punctuation">)</span>


sentences_proc has done!
<span class="token number">4</span><span class="token punctuation">.</span> 合并训练测试集，用于训练词向量
训练集行数<span class="token number">82871</span><span class="token punctuation">,</span> 测试集行数<span class="token number">20000</span><span class="token punctuation">,</span> 合并数据集行数<span class="token number">102871</span>


<span class="token number">5</span><span class="token punctuation">.</span> 保存分割处理好的train_seg_data<span class="token punctuation">.</span>csv、test_set_data<span class="token punctuation">.</span>csv
The csv_file has saved!


<span class="token number">6</span><span class="token punctuation">.</span> 保存合并数据merged_seg_data<span class="token punctuation">.</span>csv，用于训练词向量
The word_to_vector file has saved!


总体单词总数count<span class="token operator">=</span> <span class="token number">124520</span>


进入到字典中的单词总数number<span class="token operator">=</span> <span class="token number">32227</span>
合并数据集的字典构造完毕<span class="token punctuation">,</span> word_to_id容量<span class="token punctuation">:</span>  <span class="token number">32227</span>


最终构造完毕字典<span class="token punctuation">,</span> word_to_id容量<span class="token operator">=</span> <span class="token number">32227</span>
count<span class="token operator">=</span> <span class="token number">32227</span>
<span class="token number">8</span><span class="token punctuation">.</span> 将Question和Dialogue用空格连接作为模型输入形成train_df<span class="token punctuation">[</span><span class="token string">'X'</span><span class="token punctuation">]</span>


<span class="token number">9</span><span class="token punctuation">.</span> 填充<span class="token operator">&lt;</span>START<span class="token operator">></span><span class="token punctuation">,</span> <span class="token operator">&lt;</span>STOP<span class="token operator">></span><span class="token punctuation">,</span> <span class="token operator">&lt;</span>UNK<span class="token operator">></span>和<span class="token operator">&lt;</span>PAD<span class="token operator">></span>，使数据变为等长
填充前训练集样本的最大长度为<span class="token punctuation">:</span>  <span class="token number">298</span>
填充前测试集样本的最大长度为<span class="token punctuation">:</span>  <span class="token number">312</span>
填充前训练集标签的最大长度为<span class="token punctuation">:</span>  <span class="token number">38</span>
训练集X填充PAD<span class="token punctuation">,</span>START<span class="token punctuation">,</span>STOP<span class="token punctuation">,</span>UNK处理中<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
测试集X填充PAD<span class="token punctuation">,</span>START<span class="token punctuation">,</span>STOP<span class="token punctuation">,</span>UNK处理中<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
训练集Y填充PAD<span class="token punctuation">,</span>START<span class="token punctuation">,</span>STOP<span class="token punctuation">,</span>UNK处理中<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>


<span class="token number">10</span><span class="token punctuation">.</span> 保存填充<span class="token operator">&lt;</span>START<span class="token operator">></span><span class="token punctuation">,</span> <span class="token operator">&lt;</span>STOP<span class="token operator">></span><span class="token punctuation">,</span> <span class="token operator">&lt;</span>UNK<span class="token operator">></span>和<span class="token operator">&lt;</span>PAD<span class="token operator">></span>后的X和Y
填充后的三个文件保存完毕!


训练集X字典构造完毕<span class="token punctuation">,</span> word_to_id容量<span class="token punctuation">:</span>  <span class="token number">32101</span>
训练集Y字典构造完毕<span class="token punctuation">,</span> word_to_id容量<span class="token punctuation">:</span>  <span class="token number">32130</span>
测试集X字典构造完毕<span class="token punctuation">,</span> word_to_id容量<span class="token punctuation">:</span>  <span class="token number">32217</span>
单词总数量count<span class="token operator">=</span>  <span class="token number">32217</span>
逆向字典构造完毕<span class="token punctuation">,</span> id_to_word容量<span class="token punctuation">:</span>  <span class="token number">32217</span>


字典映射器word_to_id<span class="token punctuation">,</span> id_to_word保存完毕!


<span class="token number">13</span><span class="token punctuation">.</span> 数据集转换 将词转换成索引  <span class="token punctuation">[</span><span class="token operator">&lt;</span>START<span class="token operator">></span> 方向机 重 <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">]</span> <span class="token operator">-</span><span class="token operator">></span> <span class="token punctuation">[</span><span class="token number">32800</span><span class="token punctuation">,</span> <span class="token number">403</span><span class="token punctuation">,</span> <span class="token number">986</span><span class="token punctuation">,</span> <span class="token number">246</span><span class="token punctuation">,</span> <span class="token number">231</span><span class="token punctuation">]</span>
训练集X执行transform_data中<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
训练集Y执行transform_data中<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
测试集X执行transform_data中<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>


<span class="token number">14</span><span class="token punctuation">.</span> 数据转换成numpy数组<span class="token punctuation">(</span>需等长<span class="token punctuation">)</span>
转换为numpy数组的形状如下<span class="token punctuation">:</span> 
train_X的shape为<span class="token punctuation">:</span>  <span class="token punctuation">(</span><span class="token number">82871</span><span class="token punctuation">,</span> <span class="token number">314</span><span class="token punctuation">)</span> 
train_Y的shape为<span class="token punctuation">:</span>  <span class="token punctuation">(</span><span class="token number">82871</span><span class="token punctuation">,</span> <span class="token number">40</span><span class="token punctuation">)</span> 
test_X的shape为<span class="token punctuation">:</span>  <span class="token punctuation">(</span><span class="token number">20000</span><span class="token punctuation">,</span> <span class="token number">314</span><span class="token punctuation">)</span>


<span class="token number">15</span><span class="token punctuation">.</span> 保存数据


数据集构造完毕，于seq2seq<span class="token operator">/</span>data<span class="token operator">/</span>目录下
</code></pre>
<p><strong>结论</strong>: 通过五个步骤实现了全部的工具函数, 并完成了数据预处理. 后续模型类需要数据的时候, 可以直接通过加载文件的方式读取数据, 非常方便. 对于任意工业级别的项目来说, 数据预处理都处于非常重要的地位, 代码量和耗费的时间也占了整个项目很大的比例.</p>
<h4 id="模型类的实现"><a href="#模型类的实现" class="headerlink" title="模型类的实现"></a>模型类的实现</h4><ul>
<li><p>在模型类的实现过程中, 为了代码的解耦和结构清晰, 总共需要完成以下几个函数的实现:</p>
<ul>
<li>第一步: 实现批次数据加载的函数batcher.py</li>
<li>第二步: 实现模型中子层的函数layers.py</li>
<li>第三步: 实现模型类的函数model.py</li>
</ul>
</li>
<li><h5 id="第一步-实现批次数据加载的函数batcher-py"><a href="#第一步-实现批次数据加载的函数batcher-py" class="headerlink" title="第一步: 实现批次数据加载的函数batcher.py"></a>第一步: 实现批次数据加载的函数batcher.py</h5><ul>
<li>代码文件路径: /home/ec2-user/text_summary/seq2seq/src/batcher.py</li>
</ul>
</li>
</ul>
<pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 导入工具包</span>
<span class="token keyword">import</span> os
<span class="token keyword">import</span> sys
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">import</span> torch
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn
<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> DataLoader<span class="token punctuation">,</span> TensorDataset

<span class="token comment" spellcheck="true"># 设定项目的rootL路径, 方便后续相关代码文件的导入</span>
root_path <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>dirname<span class="token punctuation">(</span>os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>dirname<span class="token punctuation">(</span>os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>abspath<span class="token punctuation">(</span>__file__<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
sys<span class="token punctuation">.</span>path<span class="token punctuation">.</span>append<span class="token punctuation">(</span>root_path<span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># 导入项目相关的代码文件</span>
<span class="token keyword">from</span> utils<span class="token punctuation">.</span>data_loader <span class="token keyword">import</span> load_train_dataset<span class="token punctuation">,</span> load_test_dataset

<span class="token comment" spellcheck="true"># 训练批次数据生成器函数</span>
<span class="token keyword">def</span> <span class="token function">train_batch_generator</span><span class="token punctuation">(</span>batch_size<span class="token punctuation">,</span> max_enc_len<span class="token operator">=</span><span class="token number">300</span><span class="token punctuation">,</span> max_dec_len<span class="token operator">=</span><span class="token number">50</span><span class="token punctuation">,</span> sample_num<span class="token operator">=</span>None<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment" spellcheck="true"># batch_size: batch大小</span>
    <span class="token comment" spellcheck="true"># max_enc_len: 样本最大长度</span>
    <span class="token comment" spellcheck="true"># max_dec_len: 标签最大长度</span>
    <span class="token comment" spellcheck="true"># sample_num: 限定样本个数大小</span>

    <span class="token comment" spellcheck="true"># 直接从已经预处理好的数据文件中加载训练集数据</span>
    train_X<span class="token punctuation">,</span> train_Y <span class="token operator">=</span> load_train_dataset<span class="token punctuation">(</span>max_enc_len<span class="token punctuation">,</span> max_dec_len<span class="token punctuation">)</span>
    <span class="token comment" spellcheck="true"># 对数据进行限定长度的切分</span>
    <span class="token keyword">if</span> sample_num<span class="token punctuation">:</span>
        train_X <span class="token operator">=</span> train_X<span class="token punctuation">[</span><span class="token punctuation">:</span>sample_num<span class="token punctuation">]</span>
        train_Y <span class="token operator">=</span> train_Y<span class="token punctuation">[</span><span class="token punctuation">:</span>sample_num<span class="token punctuation">]</span>

    <span class="token comment" spellcheck="true"># 将numpy类型的数据转换为Pytorch下的tensor类型, 因为TensorDataset只接收tensor类型数据</span>
    x_data <span class="token operator">=</span> torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>train_X<span class="token punctuation">)</span>
    y_data <span class="token operator">=</span> torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>train_Y<span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true"># 第一步: 先对数据进行封装</span>
    dataset <span class="token operator">=</span> TensorDataset<span class="token punctuation">(</span>x_data<span class="token punctuation">,</span> y_data<span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true"># 第二步: 再对dataset进行迭代器的构建</span>
    <span class="token comment" spellcheck="true"># 如果机器没有GPU, 请采用下面的注释行代码</span>
    <span class="token comment" spellcheck="true"># dataset = DataLoader(dataset, batch_size=batch_size, shuffle=True, drop_last=True)</span>

    <span class="token comment" spellcheck="true"># 如果机器有GPU, 请采用下面的代码, 可以加速训练流程</span>
    dataset <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>dataset<span class="token punctuation">,</span> batch_size<span class="token operator">=</span>batch_size<span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> drop_last<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
                         num_workers<span class="token operator">=</span><span class="token number">4</span><span class="token punctuation">,</span> pin_memory<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true"># 计算每个epoch要循环多少次</span>
    steps_per_epoch <span class="token operator">=</span> len<span class="token punctuation">(</span>train_X<span class="token punctuation">)</span> <span class="token operator">//</span> batch_size

    <span class="token comment" spellcheck="true"># 将封装好的数据集和次数返回</span>
    <span class="token keyword">return</span> dataset<span class="token punctuation">,</span> steps_per_epoch

<span class="token comment" spellcheck="true"># 测试批次数据生成器函数</span>
<span class="token keyword">def</span> <span class="token function">test_batch_generator</span><span class="token punctuation">(</span>batch_size<span class="token punctuation">,</span> max_enc_len<span class="token operator">=</span><span class="token number">300</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment" spellcheck="true"># batch_size: batch大小</span>
    <span class="token comment" spellcheck="true"># max_enc_len: 样本最大长度</span>

    <span class="token comment" spellcheck="true"># 直接从已经预处理好的数据文件中加载测试集数据</span>
    test_X <span class="token operator">=</span> load_test_dataset<span class="token punctuation">(</span>max_enc_len<span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true"># 将numpy类型的数据转换为Pytorch下的tensor类型, 因为TensorDataset只接收tensor类型数据</span>
    x_data <span class="token operator">=</span> torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>test_X<span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true"># 第一步: 先对数据进行封装</span>
    dataset <span class="token operator">=</span> TensorDataset<span class="token punctuation">(</span>x_data<span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true"># 第二步: 再对dataset进行迭代器的构建</span>
    dataset <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>dataset<span class="token punctuation">,</span> batch_size<span class="token operator">=</span>batch_size<span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> drop_last<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true"># 计算每个epoch要循环多少次</span>
    steps_per_epoch <span class="token operator">=</span> len<span class="token punctuation">(</span>test_X<span class="token punctuation">)</span> <span class="token operator">//</span> batch_size

    <span class="token comment" spellcheck="true"># 将封装好的数据集和次数返回</span>
    <span class="token keyword">return</span> dataset<span class="token punctuation">,</span> steps_per_epoch
</code></pre>
<h5 id="打印-3"><a href="#打印-3" class="headerlink" title="打印"></a>打印</h5><pre class=" language-python"><code class="language-python">
Building prefix dict <span class="token keyword">from</span> the default dictionary <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
Loading model <span class="token keyword">from</span> cache 
Loading model cost <span class="token number">0.829</span> seconds<span class="token punctuation">.</span>
Prefix dict has been built successfully<span class="token punctuation">.</span>
stop_words<span class="token punctuation">:</span>  <span class="token punctuation">[</span><span class="token string">':'</span><span class="token punctuation">,</span> <span class="token string">'：'</span><span class="token punctuation">,</span> <span class="token string">'———'</span><span class="token punctuation">,</span> <span class="token string">'》），'</span><span class="token punctuation">,</span> <span class="token string">'）÷（１－'</span><span class="token punctuation">,</span> <span class="token string">'”，'</span><span class="token punctuation">,</span> <span class="token string">'）、'</span><span class="token punctuation">,</span> <span class="token string">'＝（'</span><span class="token punctuation">,</span> <span class="token string">'→'</span><span class="token punctuation">,</span> <span class="token string">'℃'</span><span class="token punctuation">,</span> <span class="token string">'&amp;'</span><span class="token punctuation">,</span> <span class="token string">'*'</span><span class="token punctuation">,</span> <span class="token string">'一一'</span><span class="token punctuation">,</span> <span class="token string">'~~~~'</span><span class="token punctuation">,</span> <span class="token string">'『'</span><span class="token punctuation">,</span> <span class="token string">'.一'</span><span class="token punctuation">,</span> <span class="token string">'./'</span><span class="token punctuation">,</span> <span class="token string">'--'</span><span class="token punctuation">,</span> <span class="token string">'』'</span><span class="token punctuation">,</span> <span class="token string">'＝″'</span><span class="token punctuation">]</span>
<span class="token punctuation">[</span><span class="token string">'！'</span><span class="token punctuation">,</span> <span class="token string">'以前'</span><span class="token punctuation">,</span> <span class="token string">'出现'</span><span class="token punctuation">,</span> <span class="token string">'过该'</span><span class="token punctuation">,</span> <span class="token string">'故障'</span><span class="token punctuation">,</span> <span class="token string">'？'</span><span class="token punctuation">,</span> <span class="token string">'缸'</span><span class="token punctuation">,</span> <span class="token string">'压'</span><span class="token punctuation">,</span> <span class="token string">'有没有'</span><span class="token punctuation">,</span> <span class="token string">'测量'</span><span class="token punctuation">,</span> <span class="token string">'一下'</span><span class="token punctuation">,</span> <span class="token string">'？'</span><span class="token punctuation">,</span> <span class="token string">'没有'</span><span class="token punctuation">,</span> <span class="token string">'没测'</span><span class="token punctuation">,</span> <span class="token string">'缸'</span><span class="token punctuation">,</span> <span class="token string">'压'</span><span class="token punctuation">,</span> <span class="token string">'测量'</span><span class="token punctuation">,</span> <span class="token string">'一下'</span><span class="token punctuation">,</span> <span class="token string">'缸'</span><span class="token punctuation">,</span> <span class="token string">'压'</span><span class="token punctuation">,</span> <span class="token string">'看'</span><span class="token punctuation">,</span> <span class="token string">'一四缸'</span><span class="token punctuation">,</span> <span class="token string">'缸'</span><span class="token punctuation">,</span> <span class="token string">'压'</span><span class="token punctuation">,</span> <span class="token string">'是否'</span><span class="token punctuation">,</span> <span class="token string">'偏低'</span><span class="token punctuation">,</span> <span class="token string">'电脑'</span><span class="token punctuation">,</span> <span class="token string">'测'</span><span class="token punctuation">,</span> <span class="token string">'，'</span><span class="token punctuation">,</span> <span class="token string">'14'</span><span class="token punctuation">,</span> <span class="token string">'缸'</span><span class="token punctuation">,</span> <span class="token string">'缺火'</span><span class="token punctuation">,</span> <span class="token string">'点火'</span><span class="token punctuation">,</span> <span class="token string">'线圈'</span><span class="token punctuation">,</span> <span class="token string">'火花塞'</span><span class="token punctuation">,</span> <span class="token string">'喷油嘴'</span><span class="token punctuation">,</span> <span class="token string">'不用'</span><span class="token punctuation">,</span> <span class="token string">'干活'</span><span class="token punctuation">,</span> <span class="token string">'直接'</span><span class="token punctuation">,</span> <span class="token string">'二三'</span><span class="token punctuation">,</span> <span class="token string">'缸'</span><span class="token punctuation">,</span> <span class="token string">'倒'</span><span class="token punctuation">,</span> <span class="token string">'一下'</span><span class="token punctuation">,</span> <span class="token string">'跑'</span><span class="token punctuation">,</span> <span class="token string">'一段'</span><span class="token punctuation">,</span> <span class="token string">'测量'</span><span class="token punctuation">,</span> <span class="token string">'一下'</span><span class="token punctuation">,</span> <span class="token string">'故障'</span><span class="token punctuation">,</span> <span class="token string">'码'</span><span class="token punctuation">,</span> <span class="token string">'进行'</span><span class="token punctuation">,</span> <span class="token string">'排除'</span><span class="token punctuation">,</span> <span class="token string">'师傅'</span><span class="token punctuation">,</span> <span class="token string">'还'</span><span class="token punctuation">,</span> <span class="token string">'调'</span><span class="token punctuation">,</span> <span class="token string">'一下'</span><span class="token punctuation">,</span> <span class="token string">'喷油嘴'</span><span class="token punctuation">,</span> <span class="token string">'测'</span><span class="token punctuation">,</span> <span class="token string">'一下'</span><span class="token punctuation">,</span> <span class="token string">'缸'</span><span class="token punctuation">,</span> <span class="token string">'压'</span><span class="token punctuation">,</span> <span class="token string">'都'</span><span class="token punctuation">,</span> <span class="token string">'正常'</span><span class="token punctuation">,</span> <span class="token string">'发动机'</span><span class="token punctuation">,</span> <span class="token string">'电脑板'</span><span class="token punctuation">,</span> <span class="token string">'问题'</span><span class="token punctuation">,</span> <span class="token string">'影响'</span><span class="token punctuation">,</span> <span class="token string">'不大'</span><span class="token punctuation">,</span> <span class="token string">'缸'</span><span class="token punctuation">,</span> <span class="token string">'压'</span><span class="token punctuation">,</span> <span class="token string">'八个'</span><span class="token punctuation">,</span> <span class="token string">'以上'</span><span class="token punctuation">,</span> <span class="token string">'正常'</span><span class="token punctuation">,</span> <span class="token string">'说'</span><span class="token punctuation">,</span> <span class="token string">'测量'</span><span class="token punctuation">,</span> <span class="token string">'缸'</span><span class="token punctuation">,</span> <span class="token string">'压'</span><span class="token punctuation">,</span> <span class="token string">'缸'</span><span class="token punctuation">,</span> <span class="token string">'压'</span><span class="token punctuation">,</span> <span class="token string">'正常'</span><span class="token punctuation">,</span> <span class="token string">'没有'</span><span class="token punctuation">,</span> <span class="token string">'问题'</span><span class="token punctuation">,</span> <span class="token string">'点击'</span><span class="token punctuation">,</span> <span class="token string">'头像'</span><span class="token punctuation">,</span> <span class="token string">'关注'</span><span class="token punctuation">,</span> <span class="token string">'问题'</span><span class="token punctuation">,</span> <span class="token string">'随时'</span><span class="token punctuation">,</span> <span class="token string">'询问'</span><span class="token punctuation">,</span> <span class="token string">'一定'</span><span class="token punctuation">,</span> <span class="token string">'真诚'</span><span class="token punctuation">,</span> <span class="token string">'用心'</span><span class="token punctuation">,</span> <span class="token string">'解决'</span><span class="token punctuation">,</span> <span class="token string">'师傅'</span><span class="token punctuation">,</span> <span class="token string">'，'</span><span class="token punctuation">,</span> <span class="token string">'谢谢'</span><span class="token punctuation">,</span> <span class="token string">'不用'</span><span class="token punctuation">,</span> <span class="token string">'客气'</span><span class="token punctuation">]</span>
res<span class="token operator">=</span> ！ 以前 出现 过该 故障 ？ 缸 压 有没有 测量 一下 ？ 没有 没测 缸 压 测量 一下 缸 压 看 一四缸 缸 压 是否 偏低 电脑 测 ， <span class="token number">14</span> 缸 缺火 点火 线圈 火花塞 喷油嘴 不用 干活 直接 二三 缸 倒 一下 跑 一段 测量 一下 故障 码 进行 排除 师傅 还 调 一下 喷油嘴 测 一下 缸 压 都 正常 发动机 电脑板 问题 影响 不大 缸 压 八个 以上 正常 说 测量 缸 压 缸 压 正常 没有 问题 点击 头像 关注 问题 随时 询问 一定 真诚 用心 解决 师傅 ， 谢谢 不用 客气
<span class="token operator">&lt;</span>torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>dataloader<span class="token punctuation">.</span>DataLoader object at <span class="token number">0x00000167C3F8DFC8</span><span class="token operator">></span>
<span class="token number">1294</span>
<span class="token operator">&lt;</span>torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>dataloader<span class="token punctuation">.</span>DataLoader object at <span class="token number">0x00000167C231BFC8</span><span class="token operator">></span>
<span class="token number">312</span>
</code></pre>
<ul>
<li><h5 id="第二步-实现模型中子层的函数layers-py"><a href="#第二步-实现模型中子层的函数layers-py" class="headerlink" title="第二步: 实现模型中子层的函数layers.py"></a>第二步: 实现模型中子层的函数layers.py</h5><ul>
<li>代码文件路径: /home/ec2-user/text_summary/seq2seq/src/layers.py</li>
</ul>
</li>
<li><p>为了完成模型中子层的构建, 我们需要分3个小步骤:</p>
</li>
<li><p>1: 实现编码器类Encoder.</p>
</li>
<li><p>2: 实现注意力类Attention.</p>
</li>
<li><p>3: 实现解码器类Decoder.</p>
</li>
<li><p>1: 实现编码器类Encoder.</p>
</li>
</ul>
<pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 导入工具包</span>
<span class="token keyword">import</span> torch
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional <span class="token keyword">as</span> F
<span class="token keyword">import</span> os
<span class="token keyword">import</span> sys
<span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd

<span class="token comment" spellcheck="true"># 设定项目的root路径, 方便后续的代码文件导入</span>
root_path <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>dirname<span class="token punctuation">(</span>os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>dirname<span class="token punctuation">(</span>os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>abspath<span class="token punctuation">(</span>__file__<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
sys<span class="token punctuation">.</span>path<span class="token punctuation">.</span>append<span class="token punctuation">(</span>root_path<span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># 导入项目相关的代码文件</span>
<span class="token keyword">from</span> utils<span class="token punctuation">.</span>config <span class="token keyword">import</span> <span class="token operator">*</span>
<span class="token keyword">from</span> utils<span class="token punctuation">.</span>word2vec_utils <span class="token keyword">import</span> get_vocab_from_model


<span class="token comment" spellcheck="true"># 构建编码器类</span>
<span class="token keyword">class</span> <span class="token class-name">Encoder</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> vocab_size<span class="token punctuation">,</span> embedding_dim<span class="token punctuation">,</span> enc_units<span class="token punctuation">,</span> batch_size<span class="token punctuation">)</span><span class="token punctuation">:</span>
        super<span class="token punctuation">(</span>Encoder<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>vocab_size <span class="token operator">=</span> vocab_size
        self<span class="token punctuation">.</span>embedding_dim <span class="token operator">=</span> embedding_dim
        self<span class="token punctuation">.</span>enc_units <span class="token operator">=</span> enc_units
        self<span class="token punctuation">.</span>batch_size <span class="token operator">=</span> batch_size

        <span class="token comment" spellcheck="true"># 第一层: 词嵌入层</span>
        self<span class="token punctuation">.</span>embedding <span class="token operator">=</span> nn<span class="token punctuation">.</span>Embedding<span class="token punctuation">(</span>vocab_size<span class="token punctuation">,</span> embedding_dim<span class="token punctuation">)</span>

        <span class="token comment" spellcheck="true"># 第二层: GRU层</span>
        self<span class="token punctuation">.</span>gru <span class="token operator">=</span> nn<span class="token punctuation">.</span>GRU<span class="token punctuation">(</span>input_size<span class="token operator">=</span>embedding_dim<span class="token punctuation">,</span> hidden_size<span class="token operator">=</span>enc_units<span class="token punctuation">,</span> num_layers<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> batch_first<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">,</span> h0<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment" spellcheck="true"># x.shape: (batch_size, sequence_length)</span>
        <span class="token comment" spellcheck="true"># h0.shape: (num_layers, batch_size, enc_units)</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>embedding<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        output<span class="token punctuation">,</span> hn <span class="token operator">=</span> self<span class="token punctuation">.</span>gru<span class="token punctuation">(</span>x<span class="token punctuation">,</span> h0<span class="token punctuation">)</span>
        <span class="token keyword">return</span> output<span class="token punctuation">,</span> hn<span class="token punctuation">.</span>transpose<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">initialize_hidden_state</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment" spellcheck="true"># hidden state张量形状: (num_layers, batch_size, enc_units)</span>
        <span class="token keyword">return</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>batch_size<span class="token punctuation">,</span> self<span class="token punctuation">.</span>enc_units<span class="token punctuation">)</span>

<span class="token keyword">class</span> <span class="token class-name">Attention</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> enc_units<span class="token punctuation">,</span> dec_units<span class="token punctuation">,</span> attn_units<span class="token punctuation">)</span><span class="token punctuation">:</span>
        super<span class="token punctuation">(</span>Attention<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>enc_units <span class="token operator">=</span> enc_units
        self<span class="token punctuation">.</span>dec_units <span class="token operator">=</span> dec_units
        self<span class="token punctuation">.</span>attn_units <span class="token operator">=</span> attn_units

        <span class="token comment" spellcheck="true"># 计算注意力的三次矩阵乘法, 对应着3个全连接层.</span>
        self<span class="token punctuation">.</span>w1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>enc_units<span class="token punctuation">,</span> attn_units<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>w2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>dec_units<span class="token punctuation">,</span> attn_units<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>v <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>attn_units<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> query<span class="token punctuation">,</span> value<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment" spellcheck="true"># query为上次的decoder隐藏层，shape: (batch_size, dec_units)</span>
        <span class="token comment" spellcheck="true"># values为编码器的编码结果enc_output，shape: (batch_size, enc_seq_len, enc_units)</span>
        <span class="token comment" spellcheck="true"># 在应用self.V之前，张量的形状是(batch_size, enc_seq_len, attention_units)</span>
        <span class="token comment" spellcheck="true"># 得到score的shape: (batch_size, seq_len, 1)</span>
        score <span class="token operator">=</span> self<span class="token punctuation">.</span>v<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>tanh<span class="token punctuation">(</span>self<span class="token punctuation">.</span>w1<span class="token punctuation">(</span>value<span class="token punctuation">)</span> <span class="token operator">+</span> self<span class="token punctuation">.</span>w2<span class="token punctuation">(</span>query<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

        <span class="token comment" spellcheck="true"># 注意力权重，是score经过softmax，但是要作用在第一个轴上(seq_len的轴)</span>
        attention_weights <span class="token operator">=</span> F<span class="token punctuation">.</span>softmax<span class="token punctuation">(</span>score<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>

        <span class="token comment" spellcheck="true"># (batch_size, enc_seq_len, 1) * (batch_size, enc_seq_len, enc_units)</span>
        <span class="token comment" spellcheck="true"># 广播, encoder unit的每个位置都对应相乘</span>
        context_vector <span class="token operator">=</span> attention_weights <span class="token operator">*</span> value
        <span class="token comment" spellcheck="true"># 在最大长度enc_seq_len这一维度上求和</span>
        context_vector <span class="token operator">=</span> torch<span class="token punctuation">.</span>sum<span class="token punctuation">(</span>context_vector<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
        <span class="token comment" spellcheck="true"># context_vector求和之后的shape: (batch_size, enc_units)</span>

        <span class="token keyword">return</span> context_vector<span class="token punctuation">,</span> attention_weights
</code></pre>
<h5 id="打印-4"><a href="#打印-4" class="headerlink" title="打印"></a>打印</h5><pre class=" language-python"><code class="language-python">torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">32217</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre>
<ul>
<li><h5 id="第三步-实现模型类的函数model-py"><a href="#第三步-实现模型类的函数model-py" class="headerlink" title="第三步: 实现模型类的函数model.py"></a>第三步: 实现模型类的函数model.py</h5><ul>
<li>代码文件路径: /home/ec2-user/text_summary/seq2seq/src/model.py</li>
</ul>
</li>
</ul>
<pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> os
<span class="token keyword">import</span> sys
<span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd
<span class="token comment" spellcheck="true"># 设定项目的root路径, 方便后续代码文件的导入</span>
root_path <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>dirname<span class="token punctuation">(</span>os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>dirname<span class="token punctuation">(</span>os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>abspath<span class="token punctuation">(</span>__file__<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
sys<span class="token punctuation">.</span>path<span class="token punctuation">.</span>append<span class="token punctuation">(</span>root_path<span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># 导入工具包和项目相关的代码文件</span>
<span class="token keyword">import</span> torch
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn
<span class="token keyword">from</span> src<span class="token punctuation">.</span>layers <span class="token keyword">import</span> Encoder<span class="token punctuation">,</span> Attention<span class="token punctuation">,</span> Decoder
<span class="token keyword">from</span> utils<span class="token punctuation">.</span>config <span class="token keyword">import</span> <span class="token operator">*</span>
<span class="token keyword">from</span> utils<span class="token punctuation">.</span>word2vec_utils <span class="token keyword">import</span> get_vocab_from_model


<span class="token comment" spellcheck="true"># 构建完整的seq2seq模型</span>
<span class="token keyword">class</span> <span class="token class-name">Seq2Seq</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> params<span class="token punctuation">)</span><span class="token punctuation">:</span>
        super<span class="token punctuation">(</span>Seq2Seq<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>params <span class="token operator">=</span> params

        <span class="token comment" spellcheck="true"># 第一层: 编码器层</span>
        self<span class="token punctuation">.</span>encoder <span class="token operator">=</span> Encoder<span class="token punctuation">(</span>params<span class="token punctuation">[</span><span class="token string">'vocab_size'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> params<span class="token punctuation">[</span><span class="token string">'embed_size'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                               params<span class="token punctuation">[</span><span class="token string">'enc_units'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> params<span class="token punctuation">[</span><span class="token string">'batch_size'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

        <span class="token comment" spellcheck="true"># 第二层: 注意力机制层</span>
        self<span class="token punctuation">.</span>attention <span class="token operator">=</span> Attention<span class="token punctuation">(</span>params<span class="token punctuation">[</span><span class="token string">'enc_units'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> params<span class="token punctuation">[</span><span class="token string">'dec_units'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> params<span class="token punctuation">[</span><span class="token string">'attn_units'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

        <span class="token comment" spellcheck="true"># 第三层: 解码器层</span>
        self<span class="token punctuation">.</span>decoder <span class="token operator">=</span> Decoder<span class="token punctuation">(</span>params<span class="token punctuation">[</span><span class="token string">'vocab_size'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> params<span class="token punctuation">[</span><span class="token string">'embed_size'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                               params<span class="token punctuation">[</span><span class="token string">'dec_units'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> params<span class="token punctuation">[</span><span class="token string">'batch_size'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true"># 实质上是在调用解码器,因为需要注意力机制,直接封装到forward中. 要调用编码器直接encoder()即可</span>
    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> dec_input<span class="token punctuation">,</span> dec_hidden<span class="token punctuation">,</span> enc_output<span class="token punctuation">,</span> dec_target<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment" spellcheck="true"># 这里的dec_input实质是(batch_size, 1)大小的&lt;START></span>
        predictions <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>

        <span class="token comment" spellcheck="true"># 拿编码器的输出和最终隐含层向量来计算</span>
        context_vector<span class="token punctuation">,</span> attention_weights <span class="token operator">=</span> self<span class="token punctuation">.</span>attention<span class="token punctuation">(</span>dec_hidden<span class="token punctuation">,</span> enc_output<span class="token punctuation">)</span>

        <span class="token comment" spellcheck="true"># 循环解码</span>
        <span class="token keyword">for</span> t <span class="token keyword">in</span> range<span class="token punctuation">(</span>dec_target<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token comment" spellcheck="true"># dec_input (batch_size, 1); dec_hidden (batch_size, hidden_units)</span>
            pred<span class="token punctuation">,</span> dec_hidden <span class="token operator">=</span> self<span class="token punctuation">.</span>decoder<span class="token punctuation">(</span>dec_input<span class="token punctuation">,</span> context_vector<span class="token punctuation">)</span>

            context_vector<span class="token punctuation">,</span> attention_weights <span class="token operator">=</span> self<span class="token punctuation">.</span>attention<span class="token punctuation">(</span>dec_hidden<span class="token punctuation">,</span> enc_output<span class="token punctuation">)</span>

            <span class="token comment" spellcheck="true"># 使用teacher forcing, 并扩展维度到三维张量</span>
            dec_input <span class="token operator">=</span> dec_target<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> t<span class="token punctuation">]</span><span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>

            predictions<span class="token punctuation">.</span>append<span class="token punctuation">(</span>pred<span class="token punctuation">)</span>

        <span class="token keyword">return</span> torch<span class="token punctuation">.</span>stack<span class="token punctuation">(</span>predictions<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> dec_hidden
<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">'__main__'</span><span class="token punctuation">:</span>
    <span class="token comment" spellcheck="true"># word_to_id, id_to_word = get_vocab_from_model(vocab_path, reverse_vocab_path)</span>
    word_to_id <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">""</span><span class="token punctuation">)</span>
    vocab_size <span class="token operator">=</span> len<span class="token punctuation">(</span>word_to_id<span class="token punctuation">)</span>
    batch_size <span class="token operator">=</span> <span class="token number">64</span>
    input_seq_len <span class="token operator">=</span> <span class="token number">300</span>

    <span class="token comment" spellcheck="true"># 模拟测试参数</span>
    params <span class="token operator">=</span> <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;"vocab_size": vocab_size, "embed_size": 500, "enc_units": 512,</span>
              <span class="token string">"attn_units"</span><span class="token punctuation">:</span> <span class="token number">20</span><span class="token punctuation">,</span> <span class="token string">"dec_units"</span><span class="token punctuation">:</span> <span class="token number">512</span><span class="token punctuation">,</span><span class="token string">"batch_size"</span><span class="token punctuation">:</span> batch_size<span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#125;</span>

    <span class="token comment" spellcheck="true"># 实例化类对象</span>
    model <span class="token operator">=</span> Seq2Seq<span class="token punctuation">(</span>params<span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true"># 初始化测试输入数据</span>
    sample_input_batch <span class="token operator">=</span> torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token punctuation">(</span>batch_size<span class="token punctuation">,</span> input_seq_len<span class="token punctuation">)</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>long<span class="token punctuation">)</span>
    sample_hidden <span class="token operator">=</span> model<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>initialize_hidden_state<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true"># 调用Encoder进行编码</span>
    sample_output<span class="token punctuation">,</span> sample_hidden <span class="token operator">=</span> model<span class="token punctuation">.</span>encoder<span class="token punctuation">(</span>sample_input_batch<span class="token punctuation">,</span> sample_hidden<span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true"># 打印输出张量维度</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Encoder output shape: (batch_size, enc_seq_len, enc_units) &amp;#123;&amp;#125;'</span><span class="token punctuation">.</span>format<span class="token punctuation">(</span>sample_output<span class="token punctuation">.</span>shape<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Encoder Hidden state shape: (batch_size, enc_units) &amp;#123;&amp;#125;'</span><span class="token punctuation">.</span>format<span class="token punctuation">(</span>sample_hidden<span class="token punctuation">.</span>shape<span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true"># 调用Attention进行注意力张量</span>
    context_vector<span class="token punctuation">,</span> attention_weights <span class="token operator">=</span> model<span class="token punctuation">.</span>attention<span class="token punctuation">(</span>sample_hidden<span class="token punctuation">,</span> sample_output<span class="token punctuation">)</span>

    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Attention context_vector shape: (batch_size, enc_units) &amp;#123;&amp;#125;"</span><span class="token punctuation">.</span>format<span class="token punctuation">(</span>context_vector<span class="token punctuation">.</span>shape<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Attention weights shape: (batch_size, sequence_length, 1) &amp;#123;&amp;#125;"</span><span class="token punctuation">.</span>format<span class="token punctuation">(</span>attention_weights<span class="token punctuation">.</span>shape<span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true"># 调用Decoder进行解码</span>
    dec_input <span class="token operator">=</span> torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token punctuation">(</span>batch_size<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>long<span class="token punctuation">)</span>
    sample_decoder_output<span class="token punctuation">,</span> _<span class="token punctuation">,</span> <span class="token operator">=</span> model<span class="token punctuation">.</span>decoder<span class="token punctuation">(</span>dec_input<span class="token punctuation">,</span> context_vector<span class="token punctuation">)</span>

    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Decoder output shape: (batch_size, vocab_size) &amp;#123;&amp;#125;'</span><span class="token punctuation">.</span>format<span class="token punctuation">(</span>sample_decoder_output<span class="token punctuation">.</span>shape<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token comment" spellcheck="true"># 这里仅测试一步，没有用到dec_seq_len</span>
</code></pre>
<h6 id="打印-5"><a href="#打印-5" class="headerlink" title="打印"></a>打印</h6><pre class=" language-python"><code class="language-python">Encoder output shape<span class="token punctuation">:</span> <span class="token punctuation">(</span>batch_size<span class="token punctuation">,</span> enc_seq_len<span class="token punctuation">,</span> enc_units<span class="token punctuation">)</span> torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">300</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
Encoder Hidden state shape<span class="token punctuation">:</span> <span class="token punctuation">(</span>batch_size<span class="token punctuation">,</span> enc_units<span class="token punctuation">)</span> torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
Attention context_vector shape<span class="token punctuation">:</span> <span class="token punctuation">(</span>batch_size<span class="token punctuation">,</span> enc_units<span class="token punctuation">)</span> torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
Attention weights shape<span class="token punctuation">:</span> <span class="token punctuation">(</span>batch_size<span class="token punctuation">,</span> sequence_length<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span> torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">300</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
Decoder output shape<span class="token punctuation">:</span> <span class="token punctuation">(</span>batch_size<span class="token punctuation">,</span> vocab_size<span class="token punctuation">)</span> torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">32216</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

Process finished <span class="token keyword">with</span> exit code <span class="token number">0</span>
</code></pre>
<h4 id="训练和测试函数的实现"><a href="#训练和测试函数的实现" class="headerlink" title="训练和测试函数的实现"></a>训练和测试函数的实现</h4><ul>
<li>构建完成模型类后, 我们要分别实现训练函数和测试函数:<ul>
<li>第一步: 编写训练辅助函数train_helper.py</li>
<li>第二步: 编写训练主函数train.py</li>
<li>第三步: 编写测试辅助函数test_helper.py</li>
<li>第四步: 编写测试主函数test.py</li>
</ul>
</li>
</ul>
<hr>
<ul>
<li>第一步: 编写训练辅助函数train_helper.py<ul>
<li>代码文件路径: /home/ec2-user/text_summary/seq2seq/src/train_helper.py </li>
</ul>
</li>
</ul>

                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        Author:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/about" rel="external nofollow noreferrer">小龙</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        Link:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://xiaoyvlongoing.github.io/2020/02/10/%E6%96%87%E6%9C%AC%E6%91%98%E8%A6%81%E9%A1%B9%E7%9B%AE/">https://xiaoyvlongoing.github.io/2020/02/10/%E6%96%87%E6%9C%AC%E6%91%98%E8%A6%81%E9%A1%B9%E7%9B%AE/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        Reprint policy:
                    </i>
                </span>
                <span class="reprint-info">
                    All articles in this blog are used except for special statements
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    reprint policy. If reproduced, please indicate source
                    <a href="/about" target="_blank">小龙</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>Copied successfully, please follow the reprint policy of this article</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">more</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/tags/%E6%96%87%E6%9C%AC%E6%91%98%E8%A6%81/">
                                    <span class="chip bg-color">文本摘要</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
                <style>
    #reward {
        margin: 40px 0;
        text-align: center;
    }

    #reward .reward-link {
        font-size: 1.4rem;
        line-height: 38px;
    }

    #reward .btn-floating:hover {
        box-shadow: 0 6px 12px rgba(0, 0, 0, 0.2), 0 5px 15px rgba(0, 0, 0, 0.2);
    }

    #rewardModal {
        width: 320px;
        height: 350px;
    }

    #rewardModal .reward-title {
        margin: 15px auto;
        padding-bottom: 5px;
    }

    #rewardModal .modal-content {
        padding: 10px;
    }

    #rewardModal .close {
        position: absolute;
        right: 15px;
        top: 15px;
        color: rgba(0, 0, 0, 0.5);
        font-size: 1.3rem;
        line-height: 20px;
        cursor: pointer;
    }

    #rewardModal .close:hover {
        color: #ef5350;
        transform: scale(1.3);
        -moz-transform:scale(1.3);
        -webkit-transform:scale(1.3);
        -o-transform:scale(1.3);
    }

    #rewardModal .reward-tabs {
        margin: 0 auto;
        width: 210px;
    }

    .reward-tabs .tabs {
        height: 38px;
        margin: 10px auto;
        padding-left: 0;
    }

    .reward-content ul {
        padding-left: 0 !important;
    }

    .reward-tabs .tabs .tab {
        height: 38px;
        line-height: 38px;
    }

    .reward-tabs .tab a {
        color: #fff;
        background-color: #ccc;
    }

    .reward-tabs .tab a:hover {
        background-color: #ccc;
        color: #fff;
    }

    .reward-tabs .wechat-tab .active {
        color: #fff !important;
        background-color: #22AB38 !important;
    }

    .reward-tabs .alipay-tab .active {
        color: #fff !important;
        background-color: #019FE8 !important;
    }

    .reward-tabs .reward-img {
        width: 210px;
        height: 210px;
    }
</style>

<div id="reward">
    <a href="#rewardModal" class="reward-link modal-trigger btn-floating btn-medium waves-effect waves-light red">赏</a>

    <!-- Modal Structure -->
    <div id="rewardModal" class="modal">
        <div class="modal-content">
            <a class="close modal-close"><i class="fas fa-times"></i></a>
            <h4 class="reward-title">你的赏识是我前进的动力</h4>
            <div class="reward-content">
                <div class="reward-tabs">
                    <ul class="tabs row">
                        <li class="tab col s6 alipay-tab waves-effect waves-light"><a href="#alipay">支付宝</a></li>
                        <li class="tab col s6 wechat-tab waves-effect waves-light"><a href="#wechat">微 信</a></li>
                    </ul>
                    <div id="alipay">
                        <img src="/medias/reward/alipay.jpg" class="reward-img" alt="支付宝打赏二维码">
                    </div>
                    <div id="wechat">
                        <img src="/medias/reward/wechat.png" class="reward-img" alt="微信打赏二维码">
                    </div>
                </div>
            </div>
        </div>
    </div>
</div>

<script>
    $(function () {
        $('.tabs').tabs();
    });
</script>

            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;Previous</div>
            <div class="card">
                <a href="/2020/02/10/%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8BTC/">
                    <div class="card-image">
                        
                        
                        <img src="/medias/featureimages/8.jpg" class="responsive-img" alt="网络编程">
                        
                        <span class="card-title">网络编程</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2020-02-10
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/python%E9%AB%98%E7%BA%A7/" class="post-category">
                                    python高级
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/python%E9%AB%98%E7%BA%A7/">
                        <span class="chip bg-color">python高级</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                Current&nbsp;<i class="far fa-dot-circle"></i>
            </div>
            <div class="card">
                <a href="/2020/02/10/%E6%96%87%E6%9C%AC%E6%91%98%E8%A6%81%E9%A1%B9%E7%9B%AE/">
                    <div class="card-image">
                        
                        
                        <img src="/medias/featureimages/3.jpg" class="responsive-img" alt="文本摘要项目">
                        
                        <span class="card-title">文本摘要项目</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2020-02-10
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/NLP/" class="post-category">
                                    NLP
                                </a>
                            
                            
                        </span>
                    </div>
                </div>

                
                <div class="card-action article-tags">
                    
                    <a href="/tags/%E6%96%87%E6%9C%AC%E6%91%98%E8%A6%81/">
                        <span class="chip bg-color">文本摘要</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/libs/codeBlock/codeBlockFuction.js"></script>

<!-- 代码语言 -->

<script type="text/javascript" src="/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="/libs/codeBlock/codeShrink.js"></script>


    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;TOC</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // modify the toc link href to support Chinese.
        let i = 0;
        let tocHeading = 'toc-heading-';
        $('#toc-content a').each(function () {
            $(this).attr('href', '#' + tocHeading + (++i));
        });

        // modify the heading title id to support Chinese.
        i = 0;
        $('#articleContent').children('h2, h3, h4').each(function () {
            $(this).attr('id', tocHeading + (++i));
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>

    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/libs/aplayer/APlayer.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/meting@2/dist/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 0px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2020-2021</span>
            
            <span id="year">2020</span>
            <a href="/about" target="_blank">小龙</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;Total Words:&nbsp;<span
                        class="white-color">36.2k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;Total visits:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;Total visitors:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- 运行天数提醒. -->
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:1458562363@qq.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>







    <a href="tencent://AddContact/?fromId=50&fromSubId=1&subcmd=all&uin=1458562363" class="tooltipped" target="_blank" data-tooltip="QQ联系我: 1458562363" data-position="top" data-delay="50">
        <i class="fab fa-qq"></i>
    </a>







    <a href="/atom.xml" class="tooltipped" target="_blank" data-tooltip="RSS 订阅" data-position="top" data-delay="50">
        <i class="fas fa-rss"></i>
    </a>

</div>
    </div>
</footer>

<div class="progress-bar"></div>

    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;Search</span>
            <input type="search" id="searchInput" name="s" placeholder="Please enter a search keyword"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/libs/materialize/materialize.min.js"></script>
    <script src="/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/libs/aos/aos.js"></script>
    <script src="/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/js/matery.js"></script>

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--腾讯兔小巢-->
    
    

    
    
    <script type="text/javascript" size="150" alpha='0.6'
        zIndex="-1" src="/libs/background/ribbon-refresh.min.js" async="async"></script>
    

    
    <script type="text/javascript" src="/libs/background/ribbon-dynamic.js" async="async"></script>
    

    
    <script src="/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>
